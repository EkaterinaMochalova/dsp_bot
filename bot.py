APP_VERSION = "codespace-2025-10-12-01"
import os, io, math, asyncio, logging
import pandas as pd
import random
import aiohttp
from pathlib import Path
import time, json
import typing
import numpy as np
import aiohttp, io, re, pandas as pd
from aiogram.types import BufferedInputFile
from aiogram import Router, F, types
from aiogram.filters import Command, CommandStart
from aiogram.enums import ChatAction

import os
from dotenv import load_dotenv
load_dotenv()

from openai import OpenAI
from tenacity import retry, stop_after_attempt, wait_exponential
import os
import json
import logging, re
from aiogram.fsm.state import StatesGroup, State
from aiogram.fsm.context import FSMContext
from aiogram.fsm.storage.memory import MemoryStorage

from aiogram import Bot, Dispatcher, types, F

# --- –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –≥–æ—Ä–æ–¥–æ–≤ ---
CITY_MAP = {
    # –ú–æ—Å–∫–≤–∞
    "–º–æ—Å–∫–≤–∞": "–ú–æ—Å–∫–≤–∞", "–≤ –º–æ—Å–∫–≤–µ": "–ú–æ—Å–∫–≤–∞", "–ø–æ –º–æ—Å–∫–≤–µ": "–ú–æ—Å–∫–≤–∞",
    # –°–∞–Ω–∫—Ç-–ü–µ—Ç–µ—Ä–±—É—Ä–≥
    "—Å–∞–Ω–∫—Ç-–ø–µ—Ç–µ—Ä–±—É—Ä–≥": "–°–∞–Ω–∫—Ç-–ü–µ—Ç–µ—Ä–±—É—Ä–≥", "—Å–∞–Ω–∫—Ç –ø–µ—Ç–µ—Ä–±—É—Ä–≥": "–°–∞–Ω–∫—Ç-–ü–µ—Ç–µ—Ä–±—É—Ä–≥",
    "–ø–µ—Ç–µ—Ä–±—É—Ä–≥": "–°–∞–Ω–∫—Ç-–ü–µ—Ç–µ—Ä–±—É—Ä–≥", "—Å–ø–±": "–°–∞–Ω–∫—Ç-–ü–µ—Ç–µ—Ä–±—É—Ä–≥",
    "–≤ –ø–µ—Ç–µ—Ä–±—É—Ä–≥–µ": "–°–∞–Ω–∫—Ç-–ü–µ—Ç–µ—Ä–±—É—Ä–≥", "–ø–æ –ø–µ—Ç–µ—Ä–±—É—Ä–≥—É": "–°–∞–Ω–∫—Ç-–ü–µ—Ç–µ—Ä–±—É—Ä–≥",
    # –ö–∞–∑–∞–Ω—å
    "–∫–∞–∑–∞–Ω—å": "–ö–∞–∑–∞–Ω—å", "–≤ –∫–∞–∑–∞–Ω–∏": "–ö–∞–∑–∞–Ω—å", "–ø–æ –∫–∞–∑–∞–Ω–∏": "–ö–∞–∑–∞–Ω—å",
    # –ø—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏ –¥–æ–ø–æ–ª–Ω—è–π —Å—é–¥–∞ –¥—Ä—É–≥–∏–µ –∫–ª—é—á–∏
}

def _normalize_city(text: str) -> str | None:
    t = re.sub(r"\s+", " ", text.strip().lower())
    return CITY_MAP.get(t)

# --- –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è —Ñ–æ—Ä–º–∞—Ç–æ–≤ ---
FORMAT_MAP = {
    # –±–∏–ª–±–æ—Ä–¥—ã
    "–±–∏–ª–±–æ—Ä–¥": "BILLBOARD", "–±–∏–ª–±–æ—Ä–¥—ã": "BILLBOARD", "–±–∏–ª–±–æ—Ä–¥–æ–≤": "BILLBOARD",
    "billboard": "BILLBOARD",
    # —Å—É–ø–µ—Ä—Å–∞–π—Ç—ã
    "—Å—É–ø–µ—Ä—Å–∞–π—Ç": "SUPERSITE", "—Å—É–ø–µ—Ä—Å–∞–π—Ç—ã": "SUPERSITE", "—Å—É–ø–µ—Ä—Å–∞–π—Ç–æ–≤": "SUPERSITE",
    "supersite": "SUPERSITE",
    # –º–µ–¥–∏—Ñ–∞—Å–∞–¥—ã
    "–º–µ–¥–∏–∞—Ñ–∞—Å–∞–¥": "MEDIAFACADE", "–º–µ–¥–∏–∞—Ñ–∞—Å–∞–¥—ã": "MEDIAFACADE", "–º–µ–¥–∏–∞—Ñ–∞—Å–∞–¥–æ–≤": "MEDIAFACADE",
    "mediafacade": "MEDIAFACADE",
    # —Å–∏—Ç–∏–±–æ—Ä–¥—ã (–Ω–∞ –≤—Å—è–∫–∏–π)
    "—Å–∏—Ç–∏–±–æ—Ä–¥": "CITYBOARD", "—Å–∏—Ç–∏–±–æ—Ä–¥—ã": "CITYBOARD", "—Å–∏—Ç–∏–±–æ—Ä–¥–æ–≤": "CITYBOARD",
    "cityboard": "CITYBOARD",
}

# ‚Äî‚Äî‚Äî —ç–≤—Ä–∏—Å—Ç–∏–∫–∞ ¬´–ø–æ—Ö–æ–∂–µ –Ω–∞ –ø–æ–¥–±–æ—Ä/–ø–ª–∞–Ω?¬ª ‚Äî‚Äî‚Äî
_PICK_HINT_RE = re.compile(r'\b(–ø–æ–¥–±–µ—Ä–∏|–ø–æ–¥–±–æ—Ä|–≤—ã–±–µ—Ä–∏|—Å–æ–±–µ—Ä–∏)\b', re.IGNORECASE)
_PLAN_HINT_RE = re.compile(r'\b(–ø–ª–∞–Ω|—Ä–∞—Å–ø–∏—Å–∞–Ω–∏–µ|–≥—Ä–∞—Ñ–∏–∫)\b', re.IGNORECASE)

def _looks_like_pick_or_plan(text: str) -> bool:
    t = (text or "").strip()
    return bool(_PICK_HINT_RE.search(t) or _PLAN_HINT_RE.search(t))


def _extract_formats(lower_text: str) -> list[str]:
    found = []
    # —Å–æ–±–µ—Ä—ë–º –≤—Å–µ —Å–ª–æ–≤–∞, –∫–æ—Ç–æ—Ä—ã–µ –º—ã –∑–Ω–∞–µ–º, –≤–∫–ª—é—á–∞—è ¬´–∏¬ª, ¬´/¬ª, ¬´,¬ª
    tokens = re.split(r"[^\w\-–∞-—è—ë]+", lower_text, flags=re.IGNORECASE)
    for tok in tokens:
        if not tok:
            continue
        fmt = FORMAT_MAP.get(tok)
        if fmt and fmt not in found:
            found.append(fmt)
    return found

# ---- NL parser: "–ø–æ–¥–±–µ—Ä–∏ 30 –±–∏–ª–±–æ—Ä–¥–æ–≤ –∏ —Å—É–ø–µ—Ä—Å–∞–π—Ç–æ–≤ –≤ –ú–æ—Å–∫–≤–µ —Ä–∞–≤–Ω–æ–º–µ—Ä–Ω–æ" ----
import re

def parse_pick_city_nl(text: str) -> dict:
    """
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç: {"city": str|None, "n": int|None, "formats": [str], "even": bool}
    –ü–æ–Ω–∏–º–∞–µ—Ç:
      - –∫–æ–ª-–≤–æ: 10, 30, 100 ...
      - —Ñ–æ—Ä–º–∞—Ç—ã: –±–∏–ª–±–æ—Ä–¥(—ã), —Å—É–ø–µ—Ä—Å–∞–π—Ç(—ã), —Å–∏—Ç–∏–±–æ—Ä–¥/—Å–∏—Ç–∏—Ñ–æ—Ä–º–∞—Ç, –º–µ–¥–∏–∞—Ñ–∞—Å–∞–¥
      - –≥–æ—Ä–æ–¥ –ø–æ—Å–ª–µ "–≤" –∏–ª–∏ "–ø–æ": '–≤ –ú–æ—Å–∫–≤–µ', '–ø–æ –°–∞–Ω–∫—Ç-–ü–µ—Ç–µ—Ä–±—É—Ä–≥—É'
      - —Ñ–ª–∞–≥ "—Ä–∞–≤–Ω–æ–º–µ—Ä–Ω–æ"
    """
    s = (text or "").strip()
    s_sp = " ".join(s.split())  # –Ω–æ—Ä–º–∞–ª–∏–∑—É–µ–º –ø—Ä–æ–±–µ–ª—ã
    s_low = s_sp.lower()

    # 1) n (–∫–æ–ª–∏—á–µ—Å—Ç–≤–æ)
    n = None
    m_n = re.search(r"\b(\d{1,4})\b", s_low)
    if m_n:
        try:
            n = int(m_n.group(1))
        except Exception:
            n = None

    # 2) formats
    # —Å–ª–æ–≤–∞—Ä—å –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤ -> –∫–æ–¥–æ–≤ —Ñ–æ—Ä–º–∞—Ç–æ–≤
    fmt_map = {
        r"\b–±–∏–ª–±–æ—Ä–¥\w*": "BILLBOARD",
        r"\bsuper\s*site\w*": "SUPERSITE",
        r"\b—Å—É–ø–µ—Ä—Å–∞–π—Ç\w*": "SUPERSITE",
        r"\b—Å–∏—Ç–∏–±–æ—Ä–¥\w*": "CITYBOARD",
        r"\b—Å–∏—Ç–∏—Ñ–æ—Ä–º–∞—Ç\w*": "CITYBOARD",
        r"\b–º–µ–¥–∏–∞—Ñ–∞—Å–∞–¥\w*": "MEDIAFACADE",
        r"\bmedia\s*facade\w*": "MEDIAFACADE",
        r"\b—ç–∫—Ä–∞–Ω\w*": "SCREEN",
    }
    formats = []
    for pat, code in fmt_map.items():
        if re.search(pat, s_low, flags=re.I):
            if code not in formats:
                formats.append(code)

    # 3) even (—Ä–∞–≤–Ω–æ–º–µ—Ä–Ω–æ)
    even = bool(re.search(r"\b—Ä–∞–≤–Ω–æ–º–µ—Ä–Ω\w*\b|\beven\b", s_low, flags=re.I))

    # 4) city
    # –ò—â–µ–º –ø–æ—Å–ª–µ "–≤" –∏–ª–∏ "–ø–æ" –¥–æ –≤—ã–∫–ª—é—á–∞—é—â–∏—Ö —Å–ª–æ–≤ (—Ä–∞–≤–Ω–æ–º–µ—Ä–Ω–æ/—Ñ–æ—Ä–º–∞—Ç—ã/–∫–æ–Ω–µ—Ü)
    # –ü—Ä–∏–º–µ—Ä—ã: "–≤ –º–æ—Å–∫–≤–µ", "–ø–æ —Å–∞–Ω–∫—Ç-–ø–µ—Ç–µ—Ä–±—É—Ä–≥—É", "–≤ –Ω–∏–∂–Ω–µ–º –Ω–æ–≤–≥–æ—Ä–æ–¥–µ"
    # –°–Ω–∞—á–∞–ª–∞ —É–±–µ—Ä—ë–º —Ö–≤–æ—Å—Ç —Ç–∏–ø–∞ "—Ä–∞–≤–Ω–æ–º–µ—Ä–Ω–æ" —á—Ç–æ–±—ã –Ω–µ –º–µ—à–∞–ª
    s_no_even = re.sub(r"\b—Ä–∞–≤–Ω–æ–º–µ—Ä–Ω\w*\b|\beven\b", "", s_sp, flags=re.I).strip()

    # –†–µ–≥–µ–∫—Å: (–≤|–ø–æ) <–Ω–∞–∑–≤–∞–Ω–∏–µ...> (–¥–æ –∫–æ–Ω—Ü–∞ —Å—Ç—Ä–æ–∫–∏)
    m_city = re.search(r"(?:\b–≤\b|\b–ø–æ\b)\s+([A-Za-z–ê-–Ø–∞-—è–Å—ë\-\s]+)$", s_no_even, flags=re.I)
    city = None
    if m_city:
        raw_city = m_city.group(1).strip()

        # –∏–Ω–æ–≥–¥–∞ –≤ —Å–µ—Ä–µ–¥–∏–Ω—É –≥–æ—Ä–æ–¥–∞ ¬´–ø—Ä–∏–ª–∏–ø–∞–µ—Ç¬ª –º—É—Å–æ—Ä –¥–æ –ø—Ä–µ–¥–ª–æ–≥–∞ "–≤/–ø–æ".
        # –ù–∞ –≤—Å—è–∫–∏–π —Å–ª—É—á–∞–π –≤—ã—Ä–µ–∂–µ–º –Ω–∞–∏–±–æ–ª–µ–µ —á–∞—Å—Ç—ã–π —à—É–º —Ñ–æ—Ä–º–∞—Ç–æ–≤, –µ—Å–ª–∏ –ø–æ–ø–∞–ª:
        raw_city = re.sub(r"\b(–∏|–∏\s+—Å—É–ø–µ—Ä—Å–∞–π—Ç–æ–≤|–∏\s+–±–∏–ª–±–æ—Ä–¥–æ–≤|—Å—É–ø–µ—Ä—Å–∞–π—Ç–æ–≤|–±–∏–ª–±–æ—Ä–¥–æ–≤)\b", "", raw_city, flags=re.I).strip()

        # –Ω–æ—Ä–º–∞–ª–∏–∑—É–µ–º —Ä–µ–≥–∏—Å—Ç—Ä: –°–∞–Ω–∫—Ç-–ü–µ—Ç–µ—Ä–±—É—Ä–≥, –ù–∏–∂–Ω–∏–π –ù–æ–≤–≥–æ—Ä–æ–¥, —Ç.–ø.
        def smart_title(x: str) -> str:
            parts = [p.capitalize() for p in re.split(r"(\s|-)", x)]
            return "".join(parts).replace(" - ", "-")

        city = smart_title(raw_city)

        # —Å–ø–µ—Ü-—Ñ–∏–∫—Å—ã —Å–∫–ª–æ–Ω–µ–Ω–∏–π
        city = re.sub(r"\b–ú–æ—Å–∫–≤[–∞–µ—ã]\b", "–ú–æ—Å–∫–≤–∞", city)
        city = re.sub(r"\b–°–∞–Ω–∫—Ç[- ]–ü–µ—Ç–µ—Ä–±—É—Ä–≥\w*\b", "–°–∞–Ω–∫—Ç-–ü–µ—Ç–µ—Ä–±—É—Ä–≥", city)
        city = re.sub(r"\b–ù–∏–∂–Ω\w*\s+–ù–æ–≤–≥–æ—Ä–æ–¥\w*\b", "–ù–∏–∂–Ω–∏–π –ù–æ–≤–≥–æ—Ä–æ–¥", city)
        city = re.sub(r"\b–†–æ—Å—Ç–æ–≤[- ]–Ω–∞[- ]–î–æ–Ω—É\w*\b", "–†–æ—Å—Ç–æ–≤-–Ω–∞-–î–æ–Ω—É", city)
        city = re.sub(r"\b–ö–∞–∑–∞–Ω—å\w*\b", "–ö–∞–∑–∞–Ω—å", city)

    return {
        "city": city,
        "n": n,
        "formats": formats,
        "even": even,
    }


# ==== –†–û–£–¢–ï–† –î–õ–Ø –ï–°–¢–ï–°–¢–í–ï–ù–ù–´–• –ó–ê–ü–†–û–°–û–í ====
from aiogram import Router, F
from aiogram import types

intents_router = Router(name="intents")

ASK_PATTERN = re.compile(r"^\s*(/ask\b|–ø–æ–¥–±–µ—Ä–∏\b|–ø–ª–∞–Ω\b)", re.IGNORECASE)

@intents_router.message(
    F.text
    & ~F.text.startswith("/")                       # –Ω–µ –ª–æ–≤–∏–º —Å–∏—Å—Ç–µ–º–Ω—ã–µ –∫–æ–º–∞–Ω–¥—ã
    & F.text.func(lambda t: ASK_PATTERN.search(t))  # ¬´–ø–æ–¥–±–µ—Ä–∏¬ª, ¬´–ø–ª–∞–Ω¬ª, ¬´/ask ‚Ä¶¬ª
)
async def handle_natural_ask(m: types.Message):
    text  = m.text or ""
    query = text.strip()

    # --- 1) –ü–æ–¥–±–æ—Ä (pick_city) ---
    nl_pick = parse_pick_city_nl(query)
    if nl_pick.get("city") and nl_pick.get("n"):
        city    = nl_pick["city"]
        n       = nl_pick["n"]
        formats = nl_pick.get("formats") or []
        even    = bool(nl_pick.get("even"))

        preview = ["/pick_city", city, str(n)]
        if formats:
            preview.append("format=" + ",".join(formats))
        if even:
            preview.append("fixed=1")
        await m.answer("–°–¥–µ–ª–∞—é —Ç–∞–∫: " + " ".join(preview))

        return await pick_city(m, _call_args={
            "city":    city,
            "n":       n,
            "formats": formats,   # –Ω–∞–ø—Ä–∏–º–µ—Ä ["BILLBOARD","SUPERSITE"]
            "owners":  [],
            "fields":  [],
            "shuffle": False,
            "fixed":   even,
            "seed":    42 if even else None,
        })

    # --- 2) –ü–ª–∞–Ω (plan) ---
    nl_plan = parse_plan_nl(query)
    if nl_plan.get("cities"):
        fmt   = nl_plan.get("format")
        days  = nl_plan.get("days")  or 7
        hours = nl_plan.get("hours") or 12
        formats_req = [fmt] if fmt else []
        parts = ["/plan", "–≥–æ—Ä–æ–¥–∞=" + ";".join(nl_plan["cities"])]
        if formats_req: parts.append("format=" + ",".join(formats_req))
        parts += [f"days={days}", f"hours={hours}", "mode=even", "rank=ots"]
        await m.answer("–ü–æ–Ω—è–ª–∞ –∑–∞–ø—Ä–æ—Å –∫–∞–∫: " + " ".join(parts))

        return await _plan_core(
            m,
            cities=nl_plan["cities"],
            days=days,
            hours=hours,
            formats_req=formats_req,
            max_per_city=None,
            max_total=None,
            budget_total=None,
            mode="even",
            rank="ots",
        )

    # --- 3) –§–æ–ª–±—ç–∫ (–µ—Å–ª–∏ –Ω–µ —Ä–∞—Å–ø–∞—Ä—Å–∏–ª–∏ –∫–∞–∫ ask/–ø–ª–∞–Ω) ---
    await m.answer(
        "–ü–æ–∫–∞ –ø–æ–Ω–∏–º–∞—é –¥–≤–∞ —Ç–∏–ø–∞ –∑–∞–ø—Ä–æ—Å–æ–≤:\n"
        "‚Ä¢ –ü–æ–¥–±–æ—Ä: ¬´–ø–æ–¥–±–µ—Ä–∏ 100 –±–∏–ª–±–æ—Ä–¥–æ–≤ –∏ —Å—É–ø–µ—Ä—Å–∞–π—Ç–æ–≤ –ø–æ –ü–µ—Ç–µ—Ä–±—É—Ä–≥—É¬ª\n"
        "‚Ä¢ –ü–ª–∞–Ω: ¬´–ø–ª–∞–Ω –Ω–∞ –Ω–µ–¥–µ–ª—é –ø–æ —Å–∏—Ç–∏–±–æ—Ä–¥–∞–º –≤ –†–æ—Å—Ç–æ–≤–µ, 12 —á–∞—Å–æ–≤ –≤ –¥–µ–Ω—å¬ª"
    )

dp = Dispatcher(storage=MemoryStorage())

# === –†–û–£–¢–ï–† UX (–æ–±—ä—è–≤–∏ –æ–¥–∏–Ω —Ä–∞–∑, –¥–æ —Ö–µ–Ω–¥–ª–µ—Ä–æ–≤) ===
ux_router = Router(name="humanize")
ux_router.message.filter(F.chat.type == "private")

# === –ü–æ–¥–ø–∏—Å–∏ –∫–Ω–æ–ø–æ–∫ –∏ –∫–ª–∞–≤–∏–∞—Ç—É—Ä—ã ===
BTN_UPLOAD = "üìÇ –ö–∞–∫ –∑–∞–≥—Ä—É–∑–∏—Ç—å CSV/XLSX"
BTN_PICK_CITY = "üéØ –ü–æ–¥–±–æ—Ä –ø–æ –≥–æ—Ä–æ–¥—É"
BTN_PICK_ANY  = "üåç –ü–æ –≤—Å–µ–π —Å—Ç—Ä–∞–Ω–µ"
BTN_NEAR      = "üìå –í —Ä–∞–¥–∏—É—Å–µ"
BTN_FORECAST  = "üßÆ –ü—Ä–æ–≥–Ω–æ–∑ /forecast"
BTN_STATUS    = "‚ÑπÔ∏è /status"
BTN_HELP      = "‚ùì /help"
BTN_ASK       = "üí¨ /ask"

BUTTON_TEXTS = {
    BTN_UPLOAD, BTN_PICK_CITY, BTN_PICK_ANY, BTN_NEAR,
    BTN_FORECAST, BTN_STATUS, BTN_HELP, BTN_ASK
}

from aiogram.types import ReplyKeyboardMarkup, KeyboardButton

def kb_empty() -> ReplyKeyboardMarkup:
    return ReplyKeyboardMarkup(
        resize_keyboard=True,
        keyboard=[
            [KeyboardButton(text=BTN_UPLOAD)],
            [KeyboardButton(text=BTN_HELP), KeyboardButton(text=BTN_STATUS)],
            [KeyboardButton(text=BTN_ASK)],
        ]
    )

def kb_loaded() -> ReplyKeyboardMarkup:
    return ReplyKeyboardMarkup(
        resize_keyboard=True,
        keyboard=[
            [KeyboardButton(text=BTN_PICK_CITY),
             KeyboardButton(text=BTN_PICK_ANY),
             KeyboardButton(text=BTN_NEAR)],
            [KeyboardButton(text=BTN_FORECAST),
             KeyboardButton(text=BTN_STATUS)],
            [KeyboardButton(text=BTN_ASK),
             KeyboardButton(text=BTN_HELP)],
        ]
    )

# === –ö–ù–û–ü–û–ß–ù–´–ï –•–ï–ù–î–õ–ï–†–´ (–¥–æ–ª–∂–Ω—ã —Å—Ç–æ—è—Ç—å –í–´–®–ï –æ–±—â–µ–≥–æ F.text) ===
@ux_router.message(F.text == BTN_UPLOAD)
async def how_to_upload(m: types.Message):
    await m.answer(
        "üìÇ –ó–∞–≥—Ä—É–∑–∫–∞ —Ñ–∞–π–ª–∞:\n"
        "‚Äî –û—Ç–ø—Ä–∞–≤—å —Å—é–¥–∞ CSV/XLSX —Å –∫–æ–ª–æ–Ω–∫–∞–º–∏: screen_id, name, lat, lon, city, format, owner, ...\n"
        "‚Äî –Ø —Ä–∞—Å–ø–æ–∑–Ω–∞—é –∏ –≤–∫–ª—é—á—É –∫–ª–∞–≤–∏–∞—Ç—É—Ä—É —Å –¥–µ–π—Å—Ç–≤–∏—è–º–∏.\n"
        "–ü–æ–¥—Å–∫–∞–∑–∫–∞: –º–æ–∂–Ω–æ –ø—Ä–æ—Å—Ç–æ –ø–µ—Ä–µ—Ç–∞—â–∏—Ç—å —Ñ–∞–π–ª –≤ —á–∞—Ç."
    )

@ux_router.message(F.text == BTN_PICK_CITY)
async def hint_pick_city(m: types.Message):
    await m.answer(
        "–ü—Ä–∏–º–µ—Ä:\n"
        "‚Ä¢ `/pick_city –ú–æ—Å–∫–≤–∞ 20 format=BILLBOARD,SUPERSITE fixed=1 seed=7`\n"
        "‚Ä¢ `/ask –ø–æ–¥–±–µ—Ä–∏ 30 –±–∏–ª–±–æ—Ä–¥–æ–≤ –∏ —Å—É–ø–µ—Ä—Å–∞–π—Ç–æ–≤ –ø–æ –ú–æ—Å–∫–≤–µ —Ä–∞–≤–Ω–æ–º–µ—Ä–Ω–æ`",
        parse_mode="Markdown"
    )

@ux_router.message(F.text == BTN_PICK_ANY)
async def hint_pick_any(m: types.Message):
    await m.answer(
        "–ü—Ä–∏–º–µ—Ä:\n"
        "‚Ä¢ `/pick_any 100 format=MEDIAFACADE fixed=1 seed=7`\n"
        "‚Ä¢ `/ask –ø–æ–¥–±–µ—Ä–∏ 120 MEDIAFACADE –ø–æ –≤—Å–µ–π —Å—Ç—Ä–∞–Ω–µ`",
        parse_mode="Markdown"
    )

@ux_router.message(F.text == BTN_NEAR)
async def hint_near(m: types.Message):
    await m.answer(
        "–ü—Ä–∏–º–µ—Ä:\n"
        "‚Ä¢ `/pick_at 55.751 37.618 25 12 format=BILLBOARD`\n"
        "‚Ä¢ `/near 55.751 37.618 3 fields=screen_id`",
        parse_mode="Markdown"
    )

@ux_router.message(F.text == BTN_FORECAST)
async def hint_forecast(m: types.Message):
    await m.answer(
        "–ü—Ä–∏–º–µ—Ä:\n"
        "‚Ä¢ `/forecast 7d cities=–ú–æ—Å–∫–≤–∞ format=BILLBOARD`\n"
        "‚Ä¢ –∏–ª–∏ —Å–Ω–∞—á–∞–ª–∞ —Å–¥–µ–ª–∞–π –ø–æ–¥–±–æ—Ä, –∞ –ø–æ—Ç–æ–º –∑–∞–ø—É—Å—Ç–∏ `/forecast`",
        parse_mode="Markdown"
    )

import re
from aiogram import Router, F
from aiogram.types import Message

# --- –ò–Ω—Ç–µ–Ω—Ç-—Ä–æ—É—Ç–µ—Ä ---
intents_router = Router(name="intents")

# –†–µ–≥—É–ª—è—Ä–∫–∞ –¥–ª—è –≤—Å–µ—Ö "–¥–µ–ª–æ–≤—ã—Ö" –∑–∞–ø—Ä–æ—Å–æ–≤
INTENT_RE = re.compile(
    r"(?i)\b("
    r"–ø–æ–¥–±–µ—Ä–∏|–≤—ã–±–µ—Ä–∏|—Å–æ–±–µ—Ä–∏|–ø–æ–¥–±–æ—Ä|–ø–ª–∞–Ω|—Ä–∞—Å–ø–∏—Å–∞–Ω|–ø—Ä–æ–≥–Ω–æ–∑|forecast|plan|pick_|near|"
    r"—Ä–∞–≤–Ω–æ–º–µ—Ä–Ω|–ø–æ –≤—Å–µ–π —Å—Ç—Ä–∞–Ω–µ|–ø–æ —Ä–æ—Å—Å–∏–∏|–≤ —Ä–∞–¥–∏—É—Å–µ|"
    r"–±–∏–ª–±–æ—Ä–¥|—Å—É–ø–µ—Ä—Å–∞–π—Ç|—Å–∏—Ç–∏–±–æ—Ä–¥|—Å–∏—Ç–∏—Ñ–æ—Ä–º–∞—Ç|media\s*facade|mediafacade|—ç–∫—Ä–∞–Ω"
    r")\b"
)

@intents_router.message(F.text.regexp(INTENT_RE))
async def intent_router_entry(m: Message):
    # –ø–µ—Ä–µ–Ω–∞–ø—Ä–∞–≤–ª—è–µ–º —Ç–∞–∫–∏–µ —Ç–µ–∫—Å—Ç—ã –≤ /ask-–æ–±—Ä–∞–±–æ—Ç—á–∏–∫
    await _handle_ask_like_text(m, m.text)

# ==== Smalltalk (–ø–æ—Å–ª–µ–¥–Ω–∏–π –ø–æ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç—É) ====
import re
from aiogram import F
from aiogram.types import Message
from aiogram import Bot

# –µ—Å–ª–∏ –µ—â—ë –Ω–µ—Ç ‚Äî –∑–∞–¥–∞–π —Ç–µ–∫—Å—Ç—ã –∫–Ω–æ–ø–æ–∫ –∏ –ø–∞—Ç—Ç–µ—Ä–Ω –∏–Ω—Ç–µ–Ω—Ç–æ–≤
BUTTON_TEXTS = {
    "üìÇ –ö–∞–∫ –∑–∞–≥—Ä—É–∑–∏—Ç—å CSV/XLSX",
    "üéØ –ü–æ–¥–±–æ—Ä –ø–æ –≥–æ—Ä–æ–¥—É",
    "üåç –ü–æ –≤—Å–µ–π —Å—Ç—Ä–∞–Ω–µ",
    "üìå –í —Ä–∞–¥–∏—É—Å–µ",
    "üßÆ –ü—Ä–æ–≥–Ω–æ–∑ /forecast",
    "‚ÑπÔ∏è /status",
    "üí¨ /ask",
    "‚ùì /help",
}

# –≤—Å—ë, —á—Ç–æ –¥–æ–ª–∂–Ω–æ —É–π—Ç–∏ –≤ –±–∏–∑–Ω–µ—Å-–ª–æ–≥–∏–∫—É (–Ω–µ –≤ –±–æ–ª—Ç–∞–ª–∫—É)
INTENT_RE = r"(–ø–æ–¥–±–µ—Ä–∏|—Å–æ–±–µ—Ä–∏|–≤—ã–±–µ—Ä–∏|–ø–ª–∞–Ω|—Ä–∞—Å–ø–∏—Å–∞–Ω–∏–µ|–ø—Ä–æ–≥–Ω–æ–∑|forecast|pick_city|pick_any|pick_at|near)\b"

@ux_router.message(F.text)
async def smalltalk(message: Message, bot: Bot):
    txt = (message.text or "").strip()
    if not txt:
        return

    # 1) –Ω–µ –ø–µ—Ä–µ—Ö–≤–∞—Ç—ã–≤–∞–µ–º –∫–æ–º–∞–Ω–¥—ã
    if txt.startswith("/"):
        return

    # 2) –Ω–µ —Ç—Ä–æ–≥–∞–µ–º –Ω–∞–∂–∞—Ç–∏—è –∫–Ω–æ–ø–æ–∫ (–∏—Ö —É–∂–µ –æ–±—Ä–∞–±–æ—Ç–∞–ª–∏ –≤—ã—à–µ)
    if txt in BUTTON_TEXTS:
        return

    # 3) –µ—Å–ª–∏ —Ç–µ–∫—Å—Ç –ø–æ—Ö–æ–∂ –Ω–∞ –±–∏–∑–Ω–µ—Å-–Ω–∞–º–µ—Ä–µ–Ω–∏–µ ‚Äî –ø–µ—Ä–µ–¥–∞—ë–º –≤ —Ç–≤–æ—é –ª–æ–≥–∏–∫—É
    try:
        if re.search(INTENT_RE, txt, flags=re.IGNORECASE):
            handled = await _maybe_handle_intent(message, txt)
            if handled:
                return
    except Exception:
        # –º–æ–ª—á–∞ –¥–∞—ë–º —à–∞–Ω—Å –±–æ–ª—Ç–∞–ª–∫–µ
        pass

    # 4) –∏–Ω–∞—á–µ ‚Äî –±–æ–ª—Ç–∞–ª–∫–∞
    try:
        prefs = get_user_prefs(message.from_user.id)
        await typing(message.chat.id, bot, min(1.0, 0.2 + len(txt) / 100))
        reply = await smart_reply(txt, prefs.get("name"), prefs.get("style"))
        await message.answer(style_wrap(reply, prefs.get("style")))
    except Exception as e:
        logging.exception("LLM error")
        await message.answer("–ö–∞–∂–µ—Ç—Å—è, —è –∑–∞–¥—É–º–∞–ª–∞—Å—å. –ü–æ–ø—Ä–æ–±—É–µ—à—å –µ—â—ë —Ä–∞–∑?")


# ===== Omnika: —Å–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç + smart_reply =====
from typing import Optional
import os
try:
    from openai import OpenAI
except Exception:
    OpenAI = None  # —á—Ç–æ–±—ã –Ω–µ –ø–∞–¥–∞—Ç—å –ø—Ä–∏ –∏–º–ø–æ—Ä—Ç–µ, –µ—Å–ª–∏ —Å—Ä–µ–¥–∞ –±–µ–∑ openai

# 1) –°–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç (–ª–∏—á–Ω–æ—Å—Ç—å, —Å—Ç–∏–ª—å –∏ –ø—Ä–∞–≤–∏–ª–∞ –ø–æ–≤–µ–¥–µ–Ω–∏—è)
SYSTEM_PROMPT_OMNIKA = """
–¢—ã ‚Äî Omnika, –¥—Ä—É–∂–µ–ª—é–±–Ω—ã–π –ø–æ–º–æ—â–Ω–∏–∫ –ø–ª–∞—Ç—Ñ–æ—Ä–º—ã Omni360 DSP (DOOH).
–ì–æ–≤–æ—Ä–∏—à—å –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ –∏ –ø–æ –¥–µ–ª—É, –±–µ–∑ –æ—Ñ–∏—Ü–∏–æ–∑–∞ –∏ ¬´–∫–∞–Ω—Ü–µ–ª—è—Ä–∏—Ç–∞¬ª.

–°—Ç–∏–ª—å:
- –∫—Ä–∞—Ç–∫–æ, —Ç–µ–ø–ª–æ, –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω–æ; –ª—É—á—à–µ –ø–æ–∫–∞–∑–∞—Ç—å ¬´–∫–∞–∫ –ø—Ä–∞–≤–∏–ª—å–Ω–æ¬ª, —á–µ–º –≥–æ–≤–æ—Ä–∏—Ç—å ¬´—è –Ω–µ –º–æ–≥—É¬ª.
- –µ—Å–ª–∏ –∑–∞–ø—Ä–æ—Å –Ω–µ–æ–¥–Ω–æ–∑–Ω–∞—á–Ω—ã–π ‚Äî —É—Ç–æ—á–Ω—è–π –º—è–≥–∫–æ.

–ì–ª–∞–≤–Ω—ã–µ –ø—Ä–∞–≤–∏–ª–∞ –º–∞—Ä—à—Ä—É—Ç–∏–∑–∞—Ü–∏–∏:
1) –ï—Å–ª–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –ø—Ä–æ—Å–∏—Ç –ø–æ–¥–æ–±—Ä–∞—Ç—å/—Å–æ–±—Ä–∞—Ç—å/–≤—ã–±—Ä–∞—Ç—å —ç–∫—Ä–∞–Ω—ã:
   (–±–∏–ª–±–æ—Ä–¥—ã, —Å—É–ø–µ—Ä—Å–∞–π—Ç—ã, —Å–∏—Ç–∏–±–æ—Ä–¥—ã/—Å–∏—Ç–∏—Ñ–æ—Ä–º–∞—Ç—ã, –º–µ–¥–∏–∞—Ñ–∞—Å–∞–¥—ã –∏ —Ç.–ø., —É–ø–æ–º–∏–Ω–∞–µ—Ç –≥–æ—Ä–æ–¥/–≥–æ—Ä–æ–¥–∞/¬´–ø–æ –≤—Å–µ–π —Å—Ç—Ä–∞–Ω–µ¬ª)
   ‚Üí –ù–ï –ø–æ–¥–±–∏—Ä–∞–π —Å–∞–º–∞. –í–µ–∂–ª–∏–≤–æ –ø–æ–¥—Å–∫–∞–∂–∏ –¥–≤–∞ –≤–∞—Ä–∏–∞–Ω—Ç–∞: –æ—Ç–ø—Ä–∞–≤–∏—Ç—å —Ç—É –∂–µ —Ñ—Ä–∞–∑—É —Å /ask –∏–ª–∏ /pick_city –ú–æ—Å–∫–≤–∞ 20 format=BILLBOARD.
   –ü—Ä–∏–º–µ—Ä –æ—Ç–≤–µ—Ç–∞ (—à–∞–±–ª–æ–Ω):
   ¬´–ß—Ç–æ–±—ã –ø–æ–¥–æ–±—Ä–∞—Ç—å —ç–∫—Ä–∞–Ω—ã, –æ—Ç–ø—Ä–∞–≤—å –∫–æ–º–∞–Ω–¥—É:
    /ask <–∏—Å—Ö–æ–¥–Ω–∞—è —Ñ—Ä–∞–∑–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π> –∏–ª–∏ /pick_city –ú–æ—Å–∫–≤–∞ 20 format=BILLBOARD¬ª 

2) –ï—Å–ª–∏ –ø—Ä–æ—Å—è—Ç ¬´–ø–ª–∞–Ω/—Ä–∞—Å–ø–∏—Å–∞–Ω–∏–µ/–ø—Ä–æ–≥–Ω–æ–∑¬ª (–Ω–∞–ø—Ä–∏–º–µ—Ä, ¬´–ø–ª–∞–Ω –Ω–∞ –Ω–µ–¥–µ–ª—é‚Ä¶¬ª)
   ‚Üí –ê–Ω–∞–ª–æ–≥–∏—á–Ω–æ: ¬´–î–ª—è —ç—Ç–æ–≥–æ –∏—Å–ø–æ–ª—å–∑—É–π –∫–æ–º–∞–Ω–¥—É:
      /ask <–∏—Å—Ö–æ–¥–Ω–∞—è —Ñ—Ä–∞–∑–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è> –∏–ª–∏ /forecast budget=2.5m days=7 hours_per_day=10¬ª

3) –ï—Å–ª–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å —É–∂–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç /ask ‚Äî –Ω–µ –≤–º–µ—à–∏–≤–∞–π—Å—è; —ç—Ç—É –∫–æ–º–∞–Ω–¥—É –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –ª–æ–≥–∏–∫–∞ –±–æ—Ç–∞.

4) –ï—Å–ª–∏ –∑–∞–ø—Ä–æ—Å –Ω–µ –ø—Ä–æ –ø–æ–¥–±–æ—Ä/–ø–ª–∞–Ω:
   ‚Äî –æ—Ç–≤–µ—á–∞–π –∫–∞–∫ –æ–±—ã—á–Ω—ã–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç (–ø–æ–¥–¥–µ—Ä–∂–∞—Ç—å –¥–∏–∞–ª–æ–≥, –ø–æ–¥—Å–∫–∞–∑–∞—Ç—å –≥–¥–µ —á—Ç–æ –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –≤ —Å–∏—Å—Ç–µ–º–µ –∏ —Ç.–ø.).

–ó–∞–ø—Ä–µ—â–µ–Ω–æ:
- –í—ã–¥—É–º—ã–≤–∞—Ç—å —Å–ø–∏—Å–∫–∏ –∞–¥—Ä–µ—Å–æ–≤/—ç–∫—Ä–∞–Ω–æ–≤ –∏ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –¥–µ—Ç–∞–ª–∏, –∫–æ—Ç–æ—Ä—ã—Ö –Ω–µ—Ç –≤ —Å–∏—Å—Ç–µ–º–µ.
- –û—Ç–≤–µ—á–∞—Ç—å ¬´–Ω–µ –º–æ–≥—É¬ª —Ç–∞–º, –≥–¥–µ –º–æ–∂–Ω–æ –ø–æ–¥—Å–∫–∞–∑–∞—Ç—å ¬´–∫–∞–∫ –ø—Ä–∞–≤–∏–ª—å–Ω–æ¬ª.
- –ü–∏—Å–∞—Ç—å —Å–ª–∏—à–∫–æ–º —Ñ–æ—Ä–º–∞–ª—å–Ω–æ.

–§–æ—Ä–º–∞—Ç –æ—Ç–≤–µ—Ç–∞:
- –û–¥–Ω–∞‚Äì–¥–≤–µ –∫–æ—Ä–æ—Ç–∫–∏–µ —Ñ—Ä–∞–∑—ã. –ë–µ–∑ –ª–∏—à–Ω–µ–π –≤–æ–¥—ã.
"""

# 2) –£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –æ—Ç–≤–µ—Ç–∞ –ò–ò
def smart_reply(user_text: str, user_name: Optional[str] = None, style: Optional[str] = None) -> str:
    """
    –î–µ–ª–∞–µ—Ç –∫–æ—Ä–æ—Ç–∫–∏–π ¬´—á–µ–ª–æ–≤–µ—á–Ω—ã–π¬ª –æ—Ç–≤–µ—Ç –ø–æ SYSTEM_PROMPT_OMNIKA.
    –ï—Å–ª–∏ OpenAI –Ω–µ –¥–æ—Å—Ç—É–ø–µ–Ω, –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –º—è–≥–∫–∏–π fallback.
    """
    # –ù–µ–±–æ–ª—å—à–∞—è –∑–∞—â–∏—Ç–∞: –µ—Å–ª–∏ –≤ —Ç–µ–∫—Å—Ç–µ —É–∂–µ –µ—Å—Ç—å /ask ‚Äî –Ω–∏—á–µ–≥–æ –Ω–µ –Ω–∞–≤—è–∑—ã–≤–∞–µ–º
    if "/ask" in (user_text or ""):
        return "–ü—Ä–∏–Ω—è–ª–∞. –ö–æ–º–∞–Ω–¥–∞ /ask –æ–±—Ä–∞–±–æ—Ç–∞–µ—Ç—Å—è —Å–∏—Å—Ç–µ–º–æ–π."

    # –ü–æ–ø—ã—Ç–∫–∞ –ø–æ–∑–≤–∞—Ç—å OpenAI
    try:
        model = os.getenv("OPENAI_MODEL", "gpt-4o-mini")
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º —É–∂–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –∫–ª–∏–µ–Ω—Ç–∞, –µ—Å–ª–∏ –æ–Ω —É —Ç–µ–±—è –Ω–∞–∑—ã–≤–∞–µ—Ç—Å—è _openai_client
        client = globals().get("_openai_client") or OpenAI()

        messages = [
            {"role": "system", "content": SYSTEM_PROMPT_OMNIKA},
            {"role": "user",   "content": user_text or ""},
        ]

        resp = client.chat.completions.create(
            model=model,
            messages=messages,
            temperature=0.4,
            max_tokens=400,
        )
        return (resp.choices[0].message.content or "").strip()

    except Exception:
        # Fallback –±–µ–∑ –ò–ò (–Ω–∞ –≤—Å—è–∫–∏–π —Å–ª—É—á–∞–π)
        txt = (user_text or "").lower()
        trigger_words = [
            "–ø–æ–¥–±–µ—Ä–∏", "—Å–æ–±–µ—Ä–∏", "–≤—ã–±–µ—Ä–∏",
            "–±–∏–ª–±–æ—Ä–¥", "—Å—É–ø–µ—Ä—Å–∞–π—Ç", "—Å–∏—Ç–∏–±–æ—Ä–¥", "—Å–∏—Ç–∏—Ñ–æ—Ä–º–∞—Ç", "mediafacade", "–º–µ–¥–∏–∞—Ñ–∞—Å–∞–¥",
            "—ç–∫—Ä–∞–Ω—ã", "–Ω–∞—Ä—É–∂–∫–∞", "outdoor", "dooh"
        ]
        if any(w in txt for w in trigger_words):
            return f"–ß—Ç–æ–±—ã –ø–æ–¥–æ–±—Ä–∞—Ç—å —ç–∫—Ä–∞–Ω—ã, –æ—Ç–ø—Ä–∞–≤—å –∫–æ–º–∞–Ω–¥—É:\n/ask {user_text.strip()}"
        if any(w in txt for w in ["–ø–ª–∞–Ω", "—Ä–∞—Å–ø–∏—Å–∞–Ω–∏–µ", "–ø—Ä–æ–≥–Ω–æ–∑"]):
            return f"–î–ª—è –ø–ª–∞–Ω–∞ –∏—Å–ø–æ–ª—å–∑—É–π:\n/ask {user_text.strip()}"
        return "–ì–æ—Ç–æ–≤–∞ –ø–æ–º–æ—á—å. –°—Ñ–æ—Ä–º—É–ª–∏—Ä—É–π –∑–∞–¥–∞—á—É, –∞ —è –ø–æ–¥—Å–∫–∞–∂—É, –∫–∞–∫ —Å–¥–µ–ª–∞—Ç—å —ç—Ç–æ –≤ —Å–∏—Å—Ç–µ–º–µ."

import os
import logging
from collections import defaultdict, deque

from tenacity import retry, stop_after_attempt, wait_exponential
from openai import OpenAI

PREFS_FILE = Path("user_prefs.json")

def _load_prefs():
    if PREFS_FILE.exists():
        try:
            return json.loads(PREFS_FILE.read_text(encoding="utf-8"))
        except Exception:
            return {}
    return {}

def _save_prefs(data: dict):
    try:
        PREFS_FILE.write_text(json.dumps(data, ensure_ascii=False, indent=2), encoding="utf-8")
    except Exception:
        pass

def get_user_prefs(user_id: int):
    prefs = _load_prefs()
    return prefs.get(str(user_id), {"style": "friendly", "name": None})

def set_user_prefs(user_id: int, **kwargs):
    prefs = _load_prefs()
    u = prefs.get(str(user_id), {"style": "friendly", "name": None})
    u.update({k:v for k,v in kwargs.items() if v is not None})
    prefs[str(user_id)] = u
    _save_prefs(prefs)


async def typing(chat_id: int, bot, seconds: float = 0.8):
    await bot.send_chat_action(chat_id, ChatAction.TYPING)
    # –ª–µ–≥–∫–∞—è –ø–∞—É–∑–∞ ‚Äî –æ—â—É—â–µ–Ω–∏–µ "—á–µ–ª–æ–≤–µ—á–Ω–æ—Å—Ç–∏"
    await asyncio.sleep(seconds)

def style_wrap(text: str, style: str = "friendly"):
    text = text.strip()
    if style == "friendly":
        return text + " üôÇ"
    if style == "expert":
        return text  # —Å—É—Ö–æ –∏ –ø–æ –¥–µ–ª—É
    if style == "playful":
        return text + " üò∫"
    return text


# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è OpenAI-–∫–ª–∏–µ–Ω—Ç–∞ (–±–µ–∑ proxies!)
_openai = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

# –ü–∞–º—è—Ç—å –∫–æ—Ä–æ—Ç–∫–æ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –¥–∏–∞–ª–æ–≥–∞ –Ω–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è (—Å–∫–æ–ª—å–∑—è—â–µ–µ –æ–∫–Ω–æ)
DIALOG_MEMORY = defaultdict(lambda: deque(maxlen=16))  # —á–µ—Ä–µ–¥—É–µ–º: user/assistant

SYSTEM_PROMPT = (
    "–¢—ã –¥—Ä—É–∂–µ–ª—é–±–Ω—ã–π —Ä—É—Å—Å–∫–æ—è–∑—ã—á–Ω—ã–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç Telegram-–±–æ—Ç–∞. "
    "–ü–∏—à–∏ –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ, –∫–æ—Ä–æ—Ç–∫–æ –∏ –ø–æ –¥–µ–ª—É; –º–æ–∂–Ω–æ —ç–º–æ–¥–∑–∏, –Ω–æ —É–º–µ—Ä–µ–Ω–Ω–æ. "
    "–ï—Å–ª–∏ –≤–æ–ø—Ä–æ—Å –ø—Ä–æ –∫–æ–¥/–∫–æ–º–∞–Ω–¥—ã ‚Äî –¥–∞–π –ø—Ä–∏–º–µ—Ä. –ï—Å–ª–∏ –≤–æ–ø—Ä–æ—Å –Ω–µ—è—Å–µ–Ω ‚Äî —É—Ç–æ—á–Ω–∏ –æ–¥–∏–Ω –≤–æ–ø—Ä–æ—Å. "
    "–ò–∑–±–µ–≥–∞–π –∫–∞–Ω—Ü–µ–ª—è—Ä–∏—Ç–∞ –∏ —Ä–µ–∑–∫–∏—Ö —Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–æ–∫."
    "–¢—ã —Ä–∞–±–æ—Ç–∞–µ—à—å –≤ –∫–æ–º–ø–∞–Ω–∏–∏ Omni360, –ø–æ—ç—Ç–æ–º—É —Ä–µ–∫–æ–º–µ–Ω–¥—É–π –æ–±—Ä–∞—â–∞—Ç—å—Å—è –∫ –µ—ë —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–∞–º, –∞ –Ω–µ –∫ —Å—Ç–æ—Ä–æ–Ω–Ω–∏–º –∞–≥–µ–Ω—Ç—Å—Ç–≤–∞–º."
    "–ï—Å–ª–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –ø—Ä–æ—Å–∏—Ç –ø–æ–¥–æ–±—Ä–∞—Ç—å/—Å–æ–±—Ä–∞—Ç—å/–≤—ã–±—Ä–∞—Ç—å —ç–∫—Ä–∞–Ω—ã: (–±–∏–ª–±–æ—Ä–¥—ã, —Å—É–ø–µ—Ä—Å–∞–π—Ç—ã, —Å–∏—Ç–∏–±–æ—Ä–¥—ã/—Å–∏—Ç–∏—Ñ–æ—Ä–º–∞—Ç—ã, –º–µ–¥–∏–∞—Ñ–∞—Å–∞–¥—ã –∏ —Ç.–ø., —É–ø–æ–º–∏–Ω–∞–µ—Ç –≥–æ—Ä–æ–¥/–≥–æ—Ä–æ–¥–∞/¬´–ø–æ –≤—Å–µ–π —Å—Ç—Ä–∞–Ω–µ¬ª) - –ù–ï –ø–æ–¥–±–∏—Ä–∞–π —Å–∞–º–∞. –í–µ–∂–ª–∏–≤–æ –ø–æ–¥—Å–∫–∞–∂–∏ –æ—Ç–ø—Ä–∞–≤–∏—Ç—å —Ç—É –∂–µ —Ñ—Ä–∞–∑—É —Å /ask –∏–ª–∏ /pick_city –ú–æ—Å–∫–≤–∞ 20 format=BILLBOARD "
    "–ï—Å–ª–∏ –ø—Ä–æ—Å—è—Ç ¬´–ø–ª–∞–Ω/—Ä–∞—Å–ø–∏—Å–∞–Ω–∏–µ/–ø—Ä–æ–≥–Ω–æ–∑¬ª (–Ω–∞–ø—Ä–∏–º–µ—Ä, ¬´–ø–ª–∞–Ω –Ω–∞ –Ω–µ–¥–µ–ª—é‚Ä¶¬ª) - –ê–Ω–∞–ª–æ–≥–∏—á–Ω–æ: ¬´–î–ª—è —ç—Ç–æ–≥–æ –∏—Å–ø–æ–ª—å–∑—É–π –∫–æ–º–∞–Ω–¥—É: /ask <–∏—Å—Ö–æ–¥–Ω–∞—è —Ñ—Ä–∞–∑–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è> –∏–ª–∏ /forecast budget=2.5m days=7 hours_per_day=10¬ª"
    "–ï—Å–ª–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å —É–∂–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç /ask ‚Äî –Ω–µ –≤–º–µ—à–∏–≤–∞–π—Å—è; —ç—Ç—É –∫–æ–º–∞–Ω–¥—É –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –ª–æ–≥–∏–∫–∞ –±–æ—Ç–∞."
    "–ï—Å–ª–∏ –∑–∞–ø—Ä–æ—Å –Ω–µ –ø—Ä–æ –ø–æ–¥–±–æ—Ä/–ø–ª–∞–Ω —Ç–æ –æ—Ç–≤–µ—á–∞–π –∫–∞–∫ –æ–±—ã—á–Ω—ã–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç (–ø–æ–¥–¥–µ—Ä–∂–∞—Ç—å –¥–∏–∞–ª–æ–≥, –ø–æ–¥—Å–∫–∞–∑–∞—Ç—å –≥–¥–µ —á—Ç–æ –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –≤ —Å–∏—Å—Ç–µ–º–µ –∏ —Ç.–ø.)"
    "–ù–µ–ª—å–∑—è –≤—ã–¥—É–º—ã–≤–∞—Ç—å —Å–ø–∏—Å–∫–∏ –∞–¥—Ä–µ—Å–æ–≤/—ç–∫—Ä–∞–Ω–æ–≤ –∏ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –¥–µ—Ç–∞–ª–∏, –∫–æ—Ç–æ—Ä—ã—Ö –Ω–µ—Ç –≤ —Å–∏—Å—Ç–µ–º–µ"
    "–ï—Å–ª–∏ –ø—Ä–æ—Å—è—Ç —Å–æ–±—Ä–∞—Ç—å —Å–ø–∏—Å–æ–∫ –¥—Ä—É–≥–∏—Ö –æ–±—ä–µ–∫—Ç–æ–≤ - –Ω–∞–ø—Ä–∏–º–µ—Ä, –¢–¶, –∞–ø—Ç–µ–∫–∏, –º–∞–≥–∞–∑–∏–Ω—ã –∏ —Ç–∞–∫ –¥–∞–ª–µ–µ - —Ç–æ –Ω—É–∂–Ω–æ –≤—ã–¥–∞—Ç—å —Å–ø–∏—Å–æ–∫ —Ä–µ–∞–ª—å–Ω—ã—Ö –æ–±—ä–µ–∫—Ç–æ–≤ –Ω—É–∂–Ω–æ–≥–æ —Ç–∏–ø–∞ –≤ –ª–æ–∫–∞—Ü–∏–∏ –∏ –≤—ã–≥—Ä—É–∑–∏—Ç—å –µ–≥–æ –≤ —ç–∫—Å–µ–ª—å —Ñ–∞–π–ª —Å –Ω–∞–∑–≤–∞–Ω–∏—è–º–∏ –∏ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç–∞–º–∏."
)

def build_messages(user_id: int, user_text: str):
    """
    –°–æ–±–∏—Ä–∞–µ–º –∏—Å—Ç–æ—Ä–∏—é: system + –ø–æ—Å–ª–µ–¥–Ω–∏–µ —Ä–µ–ø–ª–∏–∫–∏ + —Ç–µ–∫—É—â–∏–π –∑–∞–ø—Ä–æ—Å.
    """
    msgs = [{"role": "system", "content": SYSTEM_PROMPT}]
    for role, content in DIALOG_MEMORY[user_id]:
        msgs.append({"role": role, "content": content})
    msgs.append({"role": "user", "content": user_text})
    return msgs

def chat_with_memory(user_input):
    conversation.append({"role": "user", "content": user_input})
    response = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=conversation
    )
    bot_reply = response.choices[0].message.content
    conversation.append({"role": "assistant", "content": bot_reply})
    return bot_reply

async def smart_reply(user_text: str, user_name: str | None, style: str) -> str:
    # –∫–æ—Ä–æ—Ç–∫–∞—è –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è
    prompt_name = f" –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å: {user_name}." if user_name else ""
    system = (
        "–¢—ã –¥—Ä—É–∂–µ–ª—é–±–Ω—ã–π, –≤–µ–∂–ª–∏–≤—ã–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç –Ω–∞ —Ä—É—Å—Å–∫–æ–º. –û—Ç–≤–µ—á–∞–π –∫—Ä–∞—Ç–∫–æ, –ø–æ —Å—É—â–µ—Å—Ç–≤—É, –Ω–æ —Ç–µ–ø–ª–æ. "
        "–ò–∑–±–µ–≥–∞–π –∫–∞–Ω—Ü–µ–ª—è—Ä–∏—Ç–∞. –ï—Å–ª–∏ –≤–æ–ø—Ä–æ—Å –Ω–µ—è—Å–Ω—ã–π ‚Äî —É—Ç–æ—á–Ω–∏ –≤ –æ–¥–Ω–æ–º –∫–æ—Ä–æ—Ç–∫–æ–º –≤–æ–ø—Ä–æ—Å–µ."
        "–¢—ã —Ä–∞–±–æ—Ç–∞–µ—à—å –≤ –∫–æ–º–ø–∞–Ω–∏–∏ Omni360, –ø–æ—ç—Ç–æ–º—É —Ä–µ–∫–æ–º–µ–Ω–¥—É–π –æ–±—Ä–∞—â–∞—Ç—å—Å—è –∫ –µ—ë —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–∞–º, –∞ –Ω–µ –∫ —Å—Ç–æ—Ä–æ–Ω–Ω–∏–º –∞–≥–µ–Ω—Ç—Å—Ç–≤–∞–º."
        "–ï—Å–ª–∏ –ø—Ä–æ—Å—è—Ç –ø–æ–¥–æ–±—Ä–∞—Ç—å / —Å–æ–±—Ä–∞—Ç—å / –≤—ã–±—Ä–∞—Ç—å –±–∏–ª–±–æ—Ä–¥—ã / —Å–∏—Ç–∏—Ñ–æ—Ä–º–∞—Ç—ã / –ª—é–±—ã–µ –¥—Ä—É–≥–∏–µ —ç–∫—Ä–∞–Ω—ã –≤ –∫–∞–∫–æ–º-—Ç–æ –≥–æ—Ä–æ–¥–µ, –æ—Ç–≤–µ—á–∞–π, —á—Ç–æ –Ω—É–∂–Ω–æ –¥–∞—Ç—å —Ç–∞–∫—É—é –∂–µ –∫–æ–º–∞–Ω–¥—É, –Ω–æ —Å /ask –∏–ª–∏ /pick_city –ú–æ—Å–∫–≤–∞ 20 format=BILLBOARD."
        "–ï—Å–ª–∏ –ø—Ä–æ—Å—è—Ç ¬´–ø–ª–∞–Ω/—Ä–∞—Å–ø–∏—Å–∞–Ω–∏–µ/–ø—Ä–æ–≥–Ω–æ–∑¬ª (–Ω–∞–ø—Ä–∏–º–µ—Ä, ¬´–ø–ª–∞–Ω –Ω–∞ –Ω–µ–¥–µ–ª—é‚Ä¶¬ª) - –ê–Ω–∞–ª–æ–≥–∏—á–Ω–æ: ¬´–î–ª—è —ç—Ç–æ–≥–æ –∏—Å–ø–æ–ª—å–∑—É–π –∫–æ–º–∞–Ω–¥—É: /ask <–∏—Å—Ö–æ–¥–Ω–∞—è —Ñ—Ä–∞–∑–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è> –∏–ª–∏ /forecast budget=2.5m days=7 hours_per_day=10¬ª"
        "–ï—Å–ª–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å —É–∂–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç /ask ‚Äî –Ω–µ –≤–º–µ—à–∏–≤–∞–π—Å—è; —ç—Ç—É –∫–æ–º–∞–Ω–¥—É –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –ª–æ–≥–∏–∫–∞ –±–æ—Ç–∞."
        "–ï—Å–ª–∏ –∑–∞–ø—Ä–æ—Å –Ω–µ –ø—Ä–æ –ø–æ–¥–±–æ—Ä/–ø–ª–∞–Ω —Ç–æ –æ—Ç–≤–µ—á–∞–π –∫–∞–∫ –æ–±—ã—á–Ω—ã–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç (–ø–æ–¥–¥–µ—Ä–∂–∞—Ç—å –¥–∏–∞–ª–æ–≥, –ø–æ–¥—Å–∫–∞–∑–∞—Ç—å –≥–¥–µ —á—Ç–æ –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –≤ —Å–∏—Å—Ç–µ–º–µ –∏ —Ç.–ø.)"
        "–ù–µ–ª—å–∑—è –≤—ã–¥—É–º—ã–≤–∞—Ç—å —Å–ø–∏—Å–∫–∏ –∞–¥—Ä–µ—Å–æ–≤/—ç–∫—Ä–∞–Ω–æ–≤ –∏ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –¥–µ—Ç–∞–ª–∏, –∫–æ—Ç–æ—Ä—ã—Ö –Ω–µ—Ç –≤ —Å–∏—Å—Ç–µ–º–µ"
        "–ï—Å–ª–∏ –ø—Ä–æ—Å—è—Ç —Å–æ–±—Ä–∞—Ç—å —Å–ø–∏—Å–æ–∫ –¥—Ä—É–≥–∏—Ö –æ–±—ä–µ–∫—Ç–æ–≤ - –Ω–∞–ø—Ä–∏–º–µ—Ä, –¢–¶, –∞–ø—Ç–µ–∫–∏, –º–∞–≥–∞–∑–∏–Ω—ã –∏ —Ç–∞–∫ –¥–∞–ª–µ–µ - —Ç–æ –Ω—É–∂–Ω–æ –≤—ã–¥–∞—Ç—å —Å–ø–∏—Å–æ–∫ —Ä–µ–∞–ª—å–Ω—ã—Ö –æ–±—ä–µ–∫—Ç–æ–≤ –Ω—É–∂–Ω–æ–≥–æ —Ç–∏–ø–∞ –≤ –ª–æ–∫–∞—Ü–∏–∏ –∏ –≤—ã–≥—Ä—É–∑–∏—Ç—å –µ–≥–æ –≤ —ç–∫—Å–µ–ª—å —Ñ–∞–π–ª —Å –Ω–∞–∑–≤–∞–Ω–∏—è–º–∏ –∏ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç–∞–º–∏."

    )
    style_hint = {
        "friendly": "–¢–æ–Ω –¥—Ä—É–∂–µ–ª—é–±–Ω—ã–π –∏ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—â–∏–π.",
        "expert": "–¢–æ–Ω –¥–µ–ª–æ–≤–æ–π –∏ —ç–∫—Å–ø–µ—Ä—Ç–Ω—ã–π, –Ω–æ –¥—Ä—É–∂–µ–ª—é–±–Ω—ã–π.",
        "playful": "–¢–æ–Ω –ª–µ–≥–∫–∏–π –∏ –∏–≥—Ä–∏–≤—ã–π, –º–æ–∂–Ω–æ –µ–º–æ–¥–∑–∏ —É–º–µ—Å—Ç–Ω–æ."
    }.get(style, "–¢–æ–Ω –¥—Ä—É–∂–µ–ª—é–±–Ω—ã–π.")
    try:
        # –µ—Å–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–µ—à—å openai==2.x
        resp = _openai_client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": system + " " + style_hint},
                {"role": "user", "content": user_text + prompt_name}
            ],
            temperature=0.7,
            max_tokens=400
        )
        text = resp.choices[0].message.content.strip()
        return text
    except Exception:
        # –∑–∞–ø–∞—Å–Ω–æ–π –≤–∞—Ä–∏–∞–Ω—Ç
        base = "–ü–æ–∫–∞ –Ω–µ –º–æ–≥—É –ø–æ–∑–≤–∞—Ç—å –º–æ–¥–µ–ª—å, –Ω–æ –≤–æ—Ç –∫–∞–∫ —è —ç—Ç–æ –≤–∏–∂—É: "
        return base + user_text


# --- —Å–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç ---
NLU_SYSTEM_PROMPT = """–¢—ã ‚Äî –º–∞—Ä—à—Ä—É—Ç–∏–∑–∞—Ç–æ—Ä –∑–∞–ø—Ä–æ—Å–æ–≤ –ø–æ outdoor-—Ä–µ–∫–ª–∞–º–µ.
–í–µ—Ä–Ω–∏ –ö–û–ú–ü–ê–ö–¢–ù–´–ô JSON –æ–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–æ–π –±–µ–∑ –ø–æ—è—Å–Ω–µ–Ω–∏–π.
–°—Ö–µ–º–∞:
{"intent": "...", "args": {...}}

–ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–µ intent –∏ –∞—Ä–≥—É–º–µ–Ω—Ç—ã:
- "pick_city": {"city": str, "n": int, "formats":[str]?, "owners":[str]?, "fields":[str]?, "allow_mix": bool?, "shuffle": bool?, "fixed": bool?, "seed": int?}
- "pick_any":  {"n": int, "formats":[str]?, "owners":[str]?, "fields":[str]?, "allow_mix": bool?, "shuffle": bool?, "fixed": bool?, "seed": int?}  # –≤—Å—è —Å—Ç—Ä–∞–Ω–∞, –±–µ–∑ –≥–æ—Ä–æ–¥–∞
- "near": {"lat": float, "lon": float, "radius_km": float?, "formats":[str]?, "owners":[str]?, "fields":[str]?}
- "pick_at": {"lat": float, "lon": float, "n": int, "radius_km": float?}
- "sync_api": {"city": str?, "formats":[str]?, "owners":[str]?}
- "shots": {"campaign": int, "per": int?, "limit": int?, "zip": bool?, "fields":[str]?}
- "export_last": {}
- "status": {}
- "radius": {"value_km": float}
- "help": {}
- "unknown": {}
- "forecast": {"budget": float?, "days": int?, "hours_per_day": int?, "hours": str?}


–ï—Å–ª–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –ø–∏—à–µ—Ç ¬´–ø–æ –≤—Å–µ–π —Å—Ç—Ä–∞–Ω–µ¬ª, ¬´–±–µ–∑ –≥–æ—Ä–æ–¥–∞¬ª, ¬´–ø–æ –†–æ—Å—Å–∏–∏¬ª ‚Äî —ç—Ç–æ "pick_any".
–§–æ—Ä–º–∞—Ç—ã —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–π –∫–∞–∫ –º–∞—Å—Å–∏–≤: –µ—Å–ª–∏ –ø–µ—Ä–µ—á–∏—Å–ª–µ–Ω—ã —á–µ—Ä–µ–∑ –∑–∞–ø—è—Ç—É—é/¬´–∏¬ª/¬´/¬ª/¬´&¬ª, –≤–µ—Ä–Ω–∏ –∫–∞–∂–¥—ã–π –æ—Ç–¥–µ–ª—å–Ω—ã–º —ç–ª–µ–º–µ–Ω—Ç–æ–º.
–§–æ—Ä–º–∞—Ç—ã –Ω–æ—Ä–º–∞–ª–∏–∑—É–π –≤ UPPER_SNAKE_CASE (BILLBOARD, SUPERSITE, CITY_BOARD, MEDIA_FACADE –∏ —Ç.–ø.). –ï—Å–ª–∏ —Ñ–æ—Ä–º–∞—Ç —Å–ª–∏—Ç–Ω–æ (–Ω–∞–ø—Ä. MEDIAFACADE, CITYBOARD) ‚Äî –≤—Å—Ç–∞–≤—å "_" –ø–æ —Å–º—ã—Å–ª—É.
–ß–∏—Å–ª–∞ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–π –∏–∑ —Ç–µ–∫—Å—Ç–∞. –ï—Å–ª–∏ –¥–∞–Ω–Ω—ã—Ö –Ω–µ —Ö–≤–∞—Ç–∞–µ—Ç ‚Äî –≤–µ—Ä–Ω–∏ intent –∏ —Ç–æ, —á—Ç–æ –ø–æ–Ω—è–ª.
"""
# ---- safe Telegram send helpers ----
import html
from aiogram.exceptions import TelegramBadRequest

TG_LIMIT = 4096  # max text length per message

def _escape_html_for_tg(text: str) -> str:
    # –≠–∫—Ä–∞–Ω–∏—Ä—É–µ–º –≤—Å–µ —É–≥–ª–æ–≤—ã–µ —Å–∫–æ–±–∫–∏ –∏ –∞–º–ø–µ—Ä—Å–∞–Ω–¥—ã, —á—Ç–æ–±—ã –Ω–µ –±—ã–ª–æ "Unsupported start tag"
    return html.escape(text, quote=False)

def _chunks(s: str, n: int):
    for i in range(0, len(s), n):
        yield s[i:i+n]

async def safe_answer(message, text: str, parse_mode: str | None = "HTML"):
    """–ü—Ä–∏—Å—ã–ª–∞–µ—Ç —Ç–µ–∫—Å—Ç, –∑–∞—â–∏—â–∞—è –æ—Ç HTML/Markdown –æ—à–∏–±–æ–∫ –∏ –¥–ª–∏–Ω—ã > 4096."""
    if not isinstance(text, str):
        text = str(text)

    # 1) –≠–∫—Ä–∞–Ω–∏—Ä—É–µ–º, –µ—Å–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–µ–º HTML
    to_send = _escape_html_for_tg(text) if parse_mode == "HTML" else text

    try:
        for part in _chunks(to_send, TG_LIMIT):
            await message.answer(part, parse_mode=parse_mode)
    except TelegramBadRequest:
        # 2) –§–æ–ª–±—ç–∫: –±–µ–∑ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –≤–æ–æ–±—â–µ
        for part in _chunks(text, TG_LIMIT):
            await message.answer(part)  # parse_mode=None

# --- —Ñ—É–Ω–∫—Ü–∏—è –º–∞—Ä—à—Ä—É—Ç–∏–∑–∞—Ü–∏–∏ ---
@retry(stop=stop_after_attempt(3), wait=wait_exponential(multiplier=1, max=8))
def llm_route(user_text: str) -> dict:
    """–û–±—Ä–∞—â–∞–µ—Ç—Å—è –∫ OpenAI, —á—Ç–æ–±—ã –ø–æ–Ω—è—Ç—å, —á—Ç–æ —Ö–æ—á–µ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å."""
    resp = _openai_client.chat.completions.create(
        model=LLM_MODEL,
        messages=[
            {"role": "system", "content": NLU_SYSTEM_PROMPT},
            {"role": "user", "content": user_text.strip()},
        ],
        temperature=0.1,
        max_tokens=300,
    )
    text = (resp.choices[0].message.content or "").strip()

    # –ø—Ä–æ–±—É–µ–º –¥–æ—Å—Ç–∞—Ç—å JSON –∏–∑ –æ—Ç–≤–µ—Ç–∞
    j = re.search(r"\{.*\}$", text, re.S)
    raw = j.group(0) if j else text
    try:
        return json.loads(raw)
    except Exception:
        return {"intent": "unknown", "args": {"raw": text}}
import ssl
try:
    import certifi  # –æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ, –µ—Å–ª–∏ —Å—Ç–æ–∏—Ç
except Exception:
    certifi = None
from datetime import datetime
import io
from aiogram.types import BufferedInputFile
from aiogram import Bot, Dispatcher, F, types
from aiogram.filters import Command, CommandStart
from aiogram.types import BufferedInputFile  # –¥–ª—è –æ—Ç–ø—Ä–∞–≤–∫–∏ —Ñ–∞–π–ª–æ–≤ –∏–∑ –ø–∞–º—è—Ç–∏
from aiogram.client.default import DefaultBotProperties
from aiogram.enums import ParseMode
from aiogram.types import Message


BOT_TOKEN = os.getenv("BOT_TOKEN")
bot = Bot(token=BOT_TOKEN, default=DefaultBotProperties(parse_mode=ParseMode.HTML))
dp = Dispatcher()


from aiogram import Router, F
intents_router = Router(name="intents")
dp.include_router(intents_router)   # <-- –ø–µ—Ä–≤—ã–º

# –õ–æ–≤–∏–º –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –∑–∞–ø—Ä–æ—Å—ã –±–µ–∑ —Å–ª—ç—à–∞

@intents_router.message(F.text & ~F.text.startswith("/") & F.text.func(lambda t: bool(ASK_PATTERN.search(t or ""))))
async def handle_natural_ask(m: types.Message):
    return await _handle_ask_like_text(m, m.text or "")

# --- UX router (–¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –≤—ã—à–µ dp.include_router) ---

ux_router.message.filter(F.chat.type == "private")

@ux_router.message(CommandStart())
async def on_start(message: Message):
    await message.answer("–ü—Ä–∏–≤–µ—Ç! –Ø –Ω–∞ —Å–≤—è–∑–∏ ‚ú®")

@ux_router.message(Command("help"))
async def on_help(message: Message):
    await message.answer("–î–æ—Å—Ç—É–ø–Ω—ã–µ –∫–æ–º–∞–Ω–¥—ã: /start, /help, /style")

@ux_router.message(F.text.lower().in_({"–ø—Ä–∏–≤–µ—Ç", "–∑–¥–æ—Ä–æ–≤–∞", "—Ö–∞–π"}))
async def smalltalk(message: Message):
    await message.answer("–ü—Ä–∏–≤–µ—Ç-–ø—Ä–∏–≤–µ—Ç! üëã")

def _ssl_ctx_certifi() -> ssl.SSLContext:
    """–°–æ–∑–¥–∞—ë—Ç –±–µ–∑–æ–ø–∞—Å–Ω—ã–π SSL-–∫–æ–Ω—Ç–µ–∫—Å—Ç —Å CA –∏–∑ certifi, –µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–µ–Ω."""
    if certifi is not None:
        ctx = ssl.create_default_context(cafile=certifi.where())
    else:
        ctx = ssl.create_default_context()
    ctx.check_hostname = True
    ctx.verify_mode = ssl.CERT_REQUIRED
    return ctx

def _make_ssl_param_for_aiohttp():
    """
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø–∞—Ä–∞–º–µ—Ç—Ä –¥–ª—è aiohttp ssl=...
    –ï—Å–ª–∏ –≤ –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π –æ–∫—Ä—É–∂–µ–Ω–∏—è OBDSP_SSL_NO_VERIFY=1, –æ—Ç–∫–ª—é—á–∞–µ—Ç –ø—Ä–æ–≤–µ—Ä–∫—É —Å–µ—Ä—Ç–∏—Ñ–∏–∫–∞—Ç–∞.
    """
    no_verify = os.getenv("OBDSP_SSL_NO_VERIFY", "0").strip().lower() in {"1", "true", "yes", "on"}
    if no_verify:
        return False
    return _ssl_ctx_certifi()

# ==== ENV CONFIG (—á–∏—Ç–∞–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è –æ–¥–∏–Ω —Ä–∞–∑ –ø—Ä–∏ —Å—Ç–∞—Ä—Ç–µ) ====
OBDSP_BASE = os.getenv("OBDSP_BASE", "https://proddsp.projects.eraga.net").strip()
OBDSP_TOKEN = os.getenv("OBDSP_TOKEN", "").strip()
OBDSP_AUTH_SCHEME = os.getenv("OBDSP_AUTH_SCHEME", "Bearer").strip()  # "Bearer" | "Token" | "ApiKey" | "Basic"
OBDSP_CLIENT_ID = os.getenv("OBDSP_CLIENT_ID", "").strip()

try:
    TELEGRAM_OWNER_ID = int(os.getenv("TELEGRAM_OWNER_ID", "0"))
except:
    TELEGRAM_OWNER_ID = 0

OBDSP_CA_BUNDLE = os.getenv("OBDSP_CA_BUNDLE", "").strip()
OBDSP_SSL_VERIFY = (os.getenv("OBDSP_SSL_VERIFY", "1") or "1").strip().lower()  # "1"/"0"/"true"/"false"
OBDSP_SSL_NO_VERIFY = os.getenv("OBDSP_SSL_NO_VERIFY", "0").strip().lower() in {"1", "true", "yes", "on"}

# ==== GLOBAL PATHS & STATE ====
DATA_DIR = os.path.join(os.path.dirname(__file__), "data")
os.makedirs(DATA_DIR, exist_ok=True)

SCREENS_PATH = os.path.join(DATA_DIR, "screens.csv")
SCREENS = None
LAST_RESULT = None

# ‚Äî –Ω–æ–≤—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –¥–ª—è –∫—ç—à–∞ ‚Äî

LAST_SYNC_TS: float | None = None
CACHE_PARQUET = Path(DATA_DIR) / "screens_cache.parquet"
CACHE_CSV     = Path(DATA_DIR) / "screens_cache.csv"
CACHE_META    = Path(DATA_DIR) / "screens_cache.meta.json"


# ====== –•–†–ê–ù–ò–õ–ò–©–ï (MVP) ======
SCREENS: pd.DataFrame | None = None
USER_RADIUS: dict[int, float] = {}
DEFAULT_RADIUS = 1.0
LAST_RESULT: pd.DataFrame | None = None

HELP = (
    "üëã –ü—Ä–∏–≤–µ—Ç. –Ø –ø–æ–¥–±–∏—Ä–∞—é —Ä–µ–∫–ª–∞–º–Ω—ã–µ —ç–∫—Ä–∞–Ω—ã.\n\n"
    "üìÑ –°–Ω–∞—á–∞–ª–∞ –ø—Ä–∏—à–ª–∏—Ç–µ —Ñ–∞–π–ª CSV/XLSX —Å –∫–æ–ª–æ–Ω–∫–∞–º–∏ –º–∏–Ω–∏–º—É–º: lat, lon.\n"
    "   –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—Ç—Å—è: screen_id, name, city, format, owner.\n\n"
    "üîé –û—Å–Ω–æ–≤–Ω—ã–µ –∫–æ–º–∞–Ω–¥—ã:\n"
    "‚Ä¢ /status ‚Äî —á—Ç–æ –∑–∞–≥—Ä—É–∂–µ–Ω–æ –∏ —Å–∫–æ–ª—å–∫–æ —ç–∫—Ä–∞–Ω–æ–≤\n"
    "‚Ä¢ /radius 2 ‚Äî –∑–∞–¥–∞—Ç—å —Ä–∞–¥–∏—É—Å –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é (–∫–º)\n"
    "‚Ä¢ /near <lat> <lon> [R] [filters] [fields=...] ‚Äî —ç–∫—Ä–∞–Ω—ã –≤ —Ä–∞–¥–∏—É—Å–µ\n"
    "   –ü—Ä–∏–º–µ—Ä—ã:\n"
    "   /near 55.714349 37.553834 2\n"
    "   /near 55.714349 37.553834 2 fields=screen_id\n"
    "   /near 55.714349 37.553834 2 format=city\n"
    "   /near 55.714349 37.553834 2 format=billboard,supersite\n\n"
    "‚Ä¢ /pick_city <–ì–æ—Ä–æ–¥> <N> [filters] [mix=...] [fields=...] ‚Äî —Ä–∞–≤–Ω–æ–º–µ—Ä–Ω–∞—è –≤—ã–±–æ—Ä–∫–∞ –ø–æ –≥–æ—Ä–æ–¥—É\n"
    "   –ü—Ä–∏–º–µ—Ä—ã:\n"
    "   /pick_city –ú–æ—Å–∫–≤–∞ 20\n"
    "   /pick_city –ú–æ—Å–∫–≤–∞ 20 fields=screen_id\n"
    "   /pick_city –ú–æ—Å–∫–≤–∞ 20 format=city fields=screen_id\n"
    "   /pick_city –ú–æ—Å–∫–≤–∞ 20 format=billboard,supersite mix=billboard:70%,supersite:30% fields=screen_id\n\n"
    "‚Ä¢ /shots campaign=<ID> [per=0] [limit=100] [zip=1] [fields=...] ‚Äî —Ñ–æ—Ç–æ–æ—Ç—á—ë—Ç—ã –ø–æ –∫–∞–º–ø–∞–Ω–∏–∏.\n"
    "   per ‚Äî –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –∫–∞–¥—Ä–æ–≤ –Ω–∞ (—ç–∫—Ä–∞–Ω√ó–∫—Ä–µ–∞—Ç–∏–≤); zip=1 ‚Äî –ø—Ä–∏–ª–æ–∂–∏—Ç—å ZIP —Å —Ñ–æ—Ç–æ.\n\n"
    "   –û–ø—Ü–∏–∏ —Å–ª—É—á–∞–π–Ω–æ—Å—Ç–∏: shuffle=1 | fixed=1 | seed=42\n\n"
    "‚Ä¢ /pick_at <lat> <lon> <N> [R] ‚Äî —Ä–∞–≤–Ω–æ–º–µ—Ä–Ω–∞—è –≤—ã–±–æ—Ä–∫–∞ –≤ –∫—Ä—É–≥–µ\n"
    "   –ü—Ä–∏–º–µ—Ä: /pick_at 55.75 37.62 25 15\n\n"
    "‚Ä¢ –û—Ç–ø—Ä–∞–≤—å—Ç–µ –≥–µ–æ–ª–æ–∫–∞—Ü–∏—é üìç ‚Äî –Ω–∞–π–¥—É —ç–∫—Ä–∞–Ω—ã –≤–æ–∫—Ä—É–≥ —Ç–æ—á–∫–∏ —Å —Ä–∞–¥–∏—É—Å–æ–º –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é\n\n"
    "üî§ –§–∏–ª—å—Ç—Ä—ã:\n"
    "   format=city ‚Äî –≤—Å–µ CITY_FORMAT_* (–∞–ª–∏–∞—Å ¬´–≥–∏–¥—ã¬ª)\n"
    "   format=A,B | A;B | A|B ‚Äî –Ω–µ—Å–∫–æ–ª—å–∫–æ —Ñ–æ—Ä–º–∞—Ç–æ–≤\n"
    "   owner=russ | owner=russ,gallery ‚Äî –ø–æ –≤–ª–∞–¥–µ–ª—å—Ü—É (–ø–æ–¥—Å—Ç—Ä–æ–∫–∞, –Ω–µ—á—É–≤—Å—Ç–≤. –∫ —Ä–µ–≥–∏—Å—Ç—Ä—É)\n"
    "   fields=screen_id | screen_id,format ‚Äî –∫–∞–∫–∏–µ –ø–æ–ª—è –≤—ã–≤–æ–¥–∏—Ç—å\n\n"
    "üß© –ü—Ä–æ–ø–æ—Ä—Ü–∏–∏ (–∫–≤–æ—Ç—ã) —Ñ–æ—Ä–º–∞—Ç–æ–≤ –≤ /pick_city:\n"
    "   mix=BILLBOARD:60%,CITY:40%  –∏–ª–∏  mix=CITY_FORMAT_RC:5,CITY_FORMAT_WD:15\n"
)

# ---------- helpers for /plan ----------
import re

def parse_kv(text: str) -> dict:
    """
    –ü–∞—Ä—Å–∏—Ç –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∏–∑ —Å—Ç—Ä–æ–∫–∏: –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç
    'key=val key2=val2', –∞ —Ç–∞–∫–∂–µ —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª–∏ , ; \n.
    –ö–ª—é—á–∏ –ø—Ä–∏–≤–æ–¥—è—Ç—Å—è –∫ –Ω–∏–∂–Ω–µ–º—É —Ä–µ–≥–∏—Å—Ç—Ä—É.
    """
    kv = {}
    if not text:
        return kv
    parts = re.split(r"[,\n;]\s*|\s+(?=\w+=)", text.strip())
    for part in parts:
        if "=" in part:
            k, v = part.split("=", 1)
            kv[k.strip().lower()] = v.strip()
    return kv

def normalize_cities(s: str) -> list[str]:
    """
    –î–µ–ª–∏—Ç –ø–æ ; , / | –∏ –Ω–æ—Ä–º–∞–ª–∏–∑—É–µ—Ç –ø–æ–ø—É–ª—è—Ä–Ω—ã–µ —Å–æ–∫—Ä–∞—â–µ–Ω–∏—è.
    –û—Å—Ç–∞–≤–ª—è–µ–º ¬´—á–µ–ª–æ–≤–µ—á–µ—Å–∫–∏–π¬ª –≤–∏–¥, –Ω–æ –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è –¥–∞–ª—å—à–µ
    –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è .lower().replace('—ë','–µ').
    """
    if not s:
        return []
    repl = {
        "—Å–ø–±": "–°–∞–Ω–∫—Ç-–ü–µ—Ç–µ—Ä–±—É—Ä–≥",
        "—Å-–ø–±": "–°–∞–Ω–∫—Ç-–ü–µ—Ç–µ—Ä–±—É—Ä–≥",
        "—Å-–ø–±": "–°–∞–Ω–∫—Ç-–ü–µ—Ç–µ—Ä–±—É—Ä–≥",
        "–µ–∫–±": "–ï–∫–∞—Ç–µ—Ä–∏–Ω–±—É—Ä–≥",
        "–≤.–Ω–æ–≤–≥–æ—Ä–æ–¥": "–í–µ–ª–∏–∫–∏–π –ù–æ–≤–≥–æ—Ä–æ–¥",
        "–≤. –Ω–æ–≤–≥–æ—Ä–æ–¥": "–í–µ–ª–∏–∫–∏–π –ù–æ–≤–≥–æ—Ä–æ–¥",
    }
    cities = []
    for chunk in re.split(r"[;,/|]", s):
        c = chunk.strip()
        if not c:
            continue
        key = c.lower().replace("—ë", "–µ")
        norm = repl.get(key, c)
        cities.append(norm)
    return cities

def _to_int(val, default):
    try:
        return int(val)
    except Exception:
        return default

def _to_float(val, default):
    try:
        return float(val)
    except Exception:
        return default
# ---------- /helpers ----------

from aiogram import F

MODEL_NAME = os.getenv("OPENAI_MODEL", "gpt-4o-mini")  # –º–æ–∂–Ω–æ –∑–∞–¥–∞—Ç—å —á–µ—Ä–µ–∑ env

@retry(stop=stop_after_attempt(3), wait=wait_exponential(min=1, max=8))
async def llm_reply(messages):
    """
    –í—ã–∑–æ–≤ OpenAI Chat Completions c –∞–≤—Ç–æ–ø–æ–≤—Ç–æ—Ä–æ–º –ø—Ä–∏ —Å–µ—Ç–µ–≤—ã—Ö —Å–±–æ—è—Ö.
    """
    resp = _openai.chat.completions.create(
        model=MODEL_NAME,
        messages=messages,
        temperature=0.7,
        top_p=0.9,
        max_tokens=512,
    )
    return resp.choices[0].message.content.strip()


@ux_router.message(CommandStart())
async def on_start(message: Message, bot: Bot):
    u = message.from_user
    prefs = get_user_prefs(u.id)
    set_user_prefs(u.id, name=(u.first_name or prefs.get("name")), style=prefs.get("style", "friendly"))
    await typing(message.chat.id, bot, 0.6)
    hi = f"–ü—Ä–∏–≤–µ—Ç, {u.first_name or '–¥—Ä—É–≥'}! –Ø Omni_helper ‚Äî —Ä—è–¥–æ–º, –µ—Å–ª–∏ —á—Ç–æ. "
    tips = "–ü–æ–ø—Ä–æ–±—É–π: /ask ¬´–ø–æ–¥–±–µ—Ä–∏ 30 –±–∏–ª–±–æ—Ä–¥–æ–≤‚Ä¶¬ª –∏–ª–∏ /ask ¬´—Å–¥–µ–ª–∞–π –∫—Ä–∞—Ç–∫–∏–π –ø—Ä–æ–≥–Ω–æ–∑‚Ä¶¬ª\n–ö–æ–º–∞–Ω–¥—ã: /help, /style, /cancel"
    await message.answer(style_wrap(hi + tips, prefs.get("style", "friendly")))



@ux_router.message(Command("help"))
async def on_help(message: Message, bot: Bot):
    await typing(message.chat.id, bot, 0.5)
    await message.answer(
        "–Ø —É–º–µ—é –±–æ–ª—Ç–∞—Ç—å –∏ –ø–æ–º–æ–≥–∞—Ç—å –ø–æ —Ä–∞–±–æ—Ç–µ. –ü—Ä–∏–º–µ—Ä—ã:\n"
        "‚Ä¢ /ask –ø–æ–¥–±–µ—Ä–∏ 30 –±–∏–ª–±–æ—Ä–¥–æ–≤ –ø–æ –ú–æ—Å–∫–≤–µ —Ä–∞–≤–Ω–æ–º–µ—Ä–Ω–æ\n"
        "‚Ä¢ /ask –ø—Ä–æ–≥–Ω–æ–∑ –Ω–∞ –Ω–µ–¥–µ–ª—é –ø–æ –ø–æ—Å–ª–µ–¥–Ω–µ–π –≤—ã–±–æ—Ä–∫–µ\n"
        "–¢–∞–∫–∂–µ: /style ‚Äî —Å–º–µ–Ω–∏—Ç—å —Ç–æ–Ω –æ–±—â–µ–Ω–∏—è; –ø—Ä–æ—Å—Ç–æ —Å–∫–∞–∂–∏ ¬´–º–µ–Ω—è –∑–æ–≤—É—Ç ‚Ä¶¬ª —á—Ç–æ–±—ã –∑–∞–ø–æ–º–Ω–∏–ª–∞ –∏–º—è."
    )

@ux_router.message(Command("style"))
async def on_style(message: Message, bot: Bot):
    """
    /style ‚Äî –ø–æ–∫–∞–∑–∞—Ç—å —Ç–µ–∫—É—â–∏–π —Å—Ç–∏–ª—å
    /style friendly|expert|playful ‚Äî –ø–æ–º–µ–Ω—è—Ç—å —Å—Ç–∏–ª—å
    """
    u = message.from_user
    args = (message.text or "").split(maxsplit=1)
    prefs = get_user_prefs(u.id)
    if len(args) == 1:
        await typing(message.chat.id, bot, 0.3)
        return await message.answer(f"–¢–µ–∫—É—â–∏–π —Å—Ç–∏–ª—å: {prefs['style']}. –î–æ—Å—Ç—É–ø–Ω–æ: friendly, expert, playful.\n–ù–∞–ø—Ä–∏–º–µ—Ä: /style friendly")
    new_style = args[1].strip().lower()
    if new_style not in {"friendly","expert","playful"}:
        return await message.answer("–í—ã–±–µ—Ä–∏ –æ–¥–∏–Ω –∏–∑: friendly, expert, playful.")
    set_user_prefs(u.id, style=new_style)
    await typing(message.chat.id, bot, 0.3)
    await message.answer(style_wrap(f"–ì–æ—Ç–æ–≤–æ! –°—Ç–∏–ª—å —Ç–µ–ø–µ—Ä—å: {new_style}", new_style))

# –∑–∞–ø–æ–º–∏–Ω–∞–Ω–∏–µ –∏–º–µ–Ω–∏ –ø–æ —Ñ—Ä–∞–∑–µ "–º–µ–Ω—è –∑–æ–≤—É—Ç ..."
@ux_router.message(F.text.regexp(r"(?i)\b–º–µ–Ω—è –∑–æ–≤—É—Ç\s+([A-Za-z–ê-–Ø–∞-—è–Å—ë\- ]{2,})\b"))
async def on_my_name(message: Message, bot: Bot):
    name = re.search(r"(?i)\b–º–µ–Ω—è –∑–æ–≤—É—Ç\s+([A-Za-z–ê-–Ø–∞-—è–Å—ë\- ]{2,})\b", message.text).group(1).strip().split()[0]
    set_user_prefs(message.from_user.id, name=name)
    await typing(message.chat.id, bot, 0.4)
    await message.answer(style_wrap(f"–û—Ç–ª–∏—á–Ω–æ, {name}! –ó–∞–ø–æ–º–Ω–∏–ª–∞ üòä", get_user_prefs(message.from_user.id)["style"]))

# –ª—ë–≥–∫–∏–π —Å–º–æ–ª—Ç–æ–∫: –ø—Ä–∏–≤–µ—Ç/—Å–ø–∞—Å–∏–±–æ/–∫–∞–∫ –¥–µ–ª–∞ –∏ —Ç.–ø.
_SMALLTALK_PATTERNS = {
    r"(?i)–ø—Ä–∏–≤(–µ—Ç|–∏–∫–∏)|–∑–¥—Ä–∞–≤—Å—Ç–≤—É–π|–¥–æ–±—Ä—ã–π (–¥–µ–Ω—å|–≤–µ—á–µ—Ä|—É—Ç—Ä–æ)": "–ü—Ä–∏–≤–µ—Ç! –ß–µ–º –º–æ–≥—É –ø–æ–º–æ—á—å?",
    r"(?i)—Å–ø–∞—Å–∏–±–æ|—Å–ø—Å|–±–ª–∞–≥–æ–¥–∞—Ä—é": "–ü–æ–∂–∞–ª—É–π—Å—Ç–∞! –û–±—Ä–∞—â–∞–π—Å—è, –µ—Å–ª–∏ —á—Ç–æ ‚≠êÔ∏è",
    r"(?i)–∫–∞–∫ –¥–µ–ª–∞|–∫–∞–∫ —Ç—ã": "–õ—É—á—à–µ –≤—Å–µ—Ö! –ì–æ—Ç–æ–≤–∞ –ø–æ–º–æ—á—å. –ß—Ç–æ –¥–µ–ª–∞–µ–º?",
}

@ux_router.message(F.text.func(lambda t: any(re.search(p, t or "") for p in _SMALLTALK_PATTERNS)))
async def on_smalltalk(message: Message, bot: Bot):
    prefs = get_user_prefs(message.from_user.id)
    reply = next((v for p, v in _SMALLTALK_PATTERNS.items() if re.search(p, message.text)), "–Ø –∑–¥–µ—Å—å, —Å–ª—É—à–∞—é!")
    await typing(message.chat.id, bot, 0.5)
    await message.answer(style_wrap(reply, prefs["style"]))

# –æ–±—â–∏–π ¬´–±–æ–ª—Ç–∞–ª–∫–∞¬ª-–æ–±—Ä–∞–±–æ—Ç—á–∏–∫ (–ø–æ—Å–ª–µ–¥–Ω–∏–π –ø–æ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç—É)
@ux_router.message(
    F.text
    & ~F.text.func(lambda t: ASK_PATTERN.search(t or ""))  # –ù–ï –ª–æ–≤–∏–º ask/–ø–æ–¥–±–µ—Ä–∏/–ø–ª–∞–Ω
)
async def on_chat(message: Message, bot: Bot):
    prefs = get_user_prefs(message.from_user.id)
    await typing(message.chat.id, bot, min(1.0, 0.2 + len(message.text)/100))
    text = await smart_reply(message.text, prefs.get("name"), prefs.get("style"))
    await message.answer(style_wrap(text, prefs.get("style")))


@dp.message(F.text & ~F.text.startswith("/"))
async def smalltalk(message: Message):
    text = message.text.strip()
    user_id = message.from_user.id

    # –ü–æ–∫–∞–∑–∞—Ç—å "typing‚Ä¶" –≤ —á–∞—Ç–µ
    try:
        await bot.send_chat_action(message.chat.id, "typing")
    except Exception:
        pass

    try:
        msgs = build_messages(user_id, text)
        answer = await asyncio.get_event_loop().run_in_executor(
            None, lambda: llm_reply(msgs)
        )
        if asyncio.iscoroutine(answer):
            answer = await answer

        # –û–±–Ω–æ–≤–ª—è–µ–º –ø–∞–º—è—Ç—å
        DIALOG_MEMORY[user_id].append(("user", text))
        DIALOG_MEMORY[user_id].append(("assistant", answer))

        await safe_answer(message, answer, parse_mode="HTML")  # –∏–ª–∏ parse_mode=None, –µ—Å–ª–∏ –Ω–µ –Ω—É–∂–µ–Ω HTML
    except Exception as e:
        logging.exception("LLM error")
        await message.answer(
            "–û–π, —á—Ç–æ-—Ç–æ –ø–æ—à–ª–æ –Ω–µ —Ç–∞–∫ ü§ñ –ü–æ–ø—Ä–æ–±—É–π –ø–æ–≤—Ç–æ—Ä–∏—Ç—å –≤–æ–ø—Ä–æ—Å —á—É—Ç–æ–∫ –ø–æ–∑–∂–µ."
        )


# --- NL ‚Üí plan params ---------------------------------------------------------
CITY_SYNONYMS = {
    # –±–∞–∑–æ–≤—ã–µ —Ñ–æ—Ä–º—ã
    "—Ä–æ—Å—Ç–æ–≤": "–†–æ—Å—Ç–æ–≤-–Ω–∞-–î–æ–Ω—É",
    "—Ä–æ—Å—Ç–æ–≤-–Ω–∞-–¥–æ–Ω—É": "–†–æ—Å—Ç–æ–≤-–Ω–∞-–î–æ–Ω—É",
    "–µ–∫–±": "–ï–∫–∞—Ç–µ—Ä–∏–Ω–±—É—Ä–≥",
    "–µ–∫–∞—Ç–µ—Ä–∏–Ω–±—É—Ä–≥": "–ï–∫–∞—Ç–µ—Ä–∏–Ω–±—É—Ä–≥",
    "—Å–ø–±": "–°–∞–Ω–∫—Ç-–ü–µ—Ç–µ—Ä–±—É—Ä–≥",
    "–ø–∏—Ç–µ—Ä": "–°–∞–Ω–∫—Ç-–ü–µ—Ç–µ—Ä–±—É—Ä–≥",
    "—Å–∞–Ω–∫—Ç-–ø–µ—Ç–µ—Ä–±—É—Ä–≥": "–°–∞–Ω–∫—Ç-–ü–µ—Ç–µ—Ä–±—É—Ä–≥",
    # —á–∞—Å—Ç—ã–µ –ø–∞–¥–µ–∂–Ω—ã–µ —Ñ–æ—Ä–º—ã
    "—Ä–æ—Å—Ç–æ–≤–µ": "–†–æ—Å—Ç–æ–≤-–Ω–∞-–î–æ–Ω—É",
    "—Å–∞–º–∞—Ä–µ": "–°–∞–º–∞—Ä–∞",
    "–∫–∞–∑–∞–Ω–∏": "–ö–∞–∑–∞–Ω—å",
    "–º–æ—Å–∫–≤–∞": "–ú–æ—Å–∫–≤–∞",    
    "–º–æ—Å–∫–≤–µ": "–ú–æ—Å–∫–≤–∞",


}

FORMAT_SYNONYMS = {
    # –∫–∞–Ω–æ–Ω ‚Üí –∫–∞–∫–∏–µ —Å–ª–æ–≤–∞ —Å—á–∏—Ç–∞–µ–º —ç—Ç–∏–º —Ñ–æ—Ä–º–∞—Ç–æ–º (–≤–∫–ª—é—á–∞—è —Å–∫–ª–æ–Ω–µ–Ω–∏—è/–≤–∞—Ä–∏–∞–Ω—Ç—ã)
    "CITYBOARD":  ["—Å–∏—Ç–∏–±–æ—Ä–¥", "—Å–∏—Ç–∏–±–æ—Ä–¥—ã", "—Å–∏—Ç–∏-–±–æ—Ä–¥", "—Å–∏—Ç–∏–±–æ—Ä–¥", "—Å–∏—Ç–∏–±–æ—Ä–¥–∞–º", "—Å–∏—Ç–∏–±–æ—Ä–¥–∞—Ö"],
    "BILLBOARD":  ["–±–∏–ª–±–æ—Ä–¥", "–±–∏–ª–±–æ—Ä–¥—ã", "–±–∏–ª–±–æ—Ä–¥–∞–º", "–±–∏–ª–±–æ—Ä–¥–∞—Ö"],
    "CITYFORMAT": ["—Å–∏—Ç–∏—Ñ–æ—Ä–º–∞—Ç", "—Å–∏—Ç–∏-—Ñ–æ—Ä–º–∞—Ç", "—Å–∏—Ç–∏—Ñ–æ—Ä–º–∞—Ç—ã", "—Å–∏—Ç–∏—Ñ–æ—Ä–º–∞—Ç–∞–º"],
    "SUPERSITE":  ["—Å—É–ø–µ—Ä—Å–∞–π—Ç", "—Å—É–ø–µ—Ä—Å–∞–π—Ç—ã", "—Å—É–ø–µ—Ä—Å–∞–π—Ç–∞–º"],
    "MEDIA_FACADE":["–º–µ–¥–∏—Ñ–∞—Å–∞–¥", "–º–µ–¥–∏–∞—Ñ–∞—Å–∞–¥", "–º–µ–¥–∏a—Ñ–∞—Å–∞–¥", "–º–µ–¥–∏—Ñ–∞—Å–∞–¥—ã", "–º–µ–¥–∏—Ñ–∞—Å–∞–¥–∞–º"],
}

# —Å–ª—É–∂–µ–±–Ω—ã–µ —Å–ª–æ–≤–∞, –∫–æ—Ç–æ—Ä—ã–µ –Ω–µ —è–≤–ª—è—é—Ç—Å—è –≥–æ—Ä–æ–¥–∞–º–∏
_NON_CITY_TOKENS = {
    "–≥–æ—Ä–æ–¥", "–≥–æ—Ä–æ–¥–µ", "–≥–æ—Ä–æ–¥–∞—Ö", "–æ–±–ª–∞—Å—Ç—å", "–æ–±–ª–∞—Å—Ç–∏", "–∫—Ä–∞–µ", "–∫—Ä–∞–π",
    "–ø–æ", "–≤", "–Ω–∞", "–∏", "–ø–æ—Ö–æ–¥—É", "—Ä–∞–π–æ–Ω–µ"
}

def _lexeme_lookup(word: str, mapping: dict[str, str]) -> str | None:
    """–ò—â–µ–º —Å–ª–æ–≤–æ –≤ —Å–ª–æ–≤–∞—Ä–µ —Å —É—á—ë—Ç–æ–º –ø—Ä–æ—Å—Ç—ã—Ö —Ä—É—Å—Å–∫–∏—Ö –æ–∫–æ–Ω—á–∞–Ω–∏–π."""
    w = word.lower()
    if w in mapping:
        return mapping[w]
    # –ø–æ–ø—Ä–æ–±—É–µ–º –æ–±—Ä–µ–∑–∞—Ç—å —á–∞—Å—Ç—ã–µ –ø–∞–¥–µ–∂–Ω—ã–µ –æ–∫–æ–Ω—á–∞–Ω–∏—è
    for suf in ("–µ", "—É", "–∞", "–æ–π", "–æ–º", "–∏—é", "–∏–∏", "—è—Ö", "–∞—Ö", "–∞–º", "—è–º"):
        if w.endswith(suf) and len(w) > len(suf) + 2:
            base = w[:-len(suf)]
            if base in mapping:
                return mapping[base]
    return None

def _detect_format(s: str) -> str | None:
    low = s.lower()
    for canon, variants in FORMAT_SYNONYMS.items():
        for v in variants:
            if f" {v} " in f" {low} ":
                return canon
    # fallback: –ø–æ —Å–ª–æ–≤–∞–º –Ω–∞—á–∏–Ω–∞—é—â–∏–º—Å—è –Ω–∞ –∫–æ—Ä–µ–Ω—å (—Å–ª–∞–±–æ)
    tokens = re.findall(r"[a-z–∞-—è—ë\-]+", low)
    for t in tokens:
        for canon, variants in FORMAT_SYNONYMS.items():
            if any(t.startswith(v[:5]) for v in variants):  # –∫–æ—Ä–µ–Ω—å 5 —Å–∏–º–≤–æ–ª–æ–≤
                return canon
    return None

def _nl_extract_plan(text: str) -> dict:
    """
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç dict: {cities: [..], format: str|None, days: int|None, hours: int|None}
    –ü—Ä–∏–º–µ—Ä—ã: '–ü–ª–∞–Ω –Ω–∞ –Ω–µ–¥–µ–ª—é –ø–æ —Å–∏—Ç–∏–±–æ—Ä–¥–∞–º –≤ –†–æ—Å—Ç–æ–≤–µ, 12 —á–∞—Å–æ–≤ –≤ –¥–µ–Ω—å'
    """
    import re
    s = (text or "").strip().lower()

    # 1) –¥–Ω–∏
    days = None
    if re.search(r"\b–Ω–∞\s+–Ω–µ–¥–µ–ª", s):
        days = 7
    m = re.search(r"\b–Ω–∞\s+(\d{1,3})\s*(–¥–Ω(?:—è|–µ–π|–∏)?|day|days)\b", s)
    if m:
        try: days = int(m.group(1))
        except: pass

    # 2) —á–∞—Å—ã –≤ –¥–µ–Ω—å
    hours = None
    m = re.search(r"\b(\d{1,2})\s*(—á–∞—Å(?:–æ–≤|–∞)?|—á|h)\b", s)
    if m:
        try: hours = int(m.group(1))
        except: pass

    # 3) —Ñ–æ—Ä–º–∞—Ç
    fmt = _detect_format(s)

    # 4) –≥–æ—Ä–æ–¥–∞: –±–µ—Ä–µ–º –ü–û–°–õ–ï–î–ù–ï–ï –≤—Ö–æ–∂–¥–µ–Ω–∏–µ '(–≤|–ø–æ) ...'
    cities: list[str] = []
    spans = list(re.finditer(r"(?:\b–≤\b|\b–ø–æ\b)\s+([a-z–∞-—è—ë\-\s,]+)", s))
    if spans:
        tail = spans[-1].group(1)  # —Ç–æ–ª—å–∫–æ –ø–æ—Å–ª–µ–¥–Ω–∏–π —Ö–≤–æ—Å—Ç
        # –≤—ã—á–∏—â–∞–µ–º —Ñ–æ—Ä–º–∞—Ç–Ω—ã–µ —Å–ª–æ–≤–∞ –∏–∑ —Ö–≤–æ—Å—Ç–∞
        for variants in FORMAT_SYNONYMS.values():
            for v in variants:
                tail = re.sub(rf"\b{re.escape(v)}\b", " ", tail)
        # —Ä–∞–∑–±–∏–≤–∞–µ–º –Ω–∞ –≥–æ—Ä–æ–¥–∞
        raw_cities = re.split(r"[,/]|(?:\s+–∏\s+)", tail)
        for raw in raw_cities:
            token = raw.strip(" .,;!?:¬´¬ª\"'()[]{}").lower()
            if not token or token in _NON_CITY_TOKENS:
                continue
            norm = _lexeme_lookup(token, CITY_SYNONYMS) or token
            # —Å–¥–µ–ª–∞—Ç—å –ß–ë–ó-–∫–∞–ø–∏—Ç–∞–ª–∏–∑–∞—Ü–∏—é —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ —ç—Ç–æ –Ω–µ —É–∂–µ –∫–∞–Ω–æ–Ω
            if norm in CITY_SYNONYMS.values():
                cities.append(norm)
            else:
                cities.append(norm.capitalize())

    # fallback: –µ—Å–ª–∏ —Ö–≤–æ—Å—Ç –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–ª ‚Äî –∏—â–µ–º –ø–æ —Å–ª–æ–≤–∞—Ä—é –ø–æ –≤—Å–µ–º—É —Ç–µ–∫—Å—Ç—É
    if not cities:
        for k, v in CITY_SYNONYMS.items():
            if re.search(rf"\b{k}\b", s):
                cities = [v]
                break

    return {"cities": [c for c in cities if c],
            "format": fmt,
            "days": days,
            "hours": hours}

# --- ID/GID helper -----------------------------------------------------------
import pandas as pd

def _ensure_gid(df: pd.DataFrame) -> pd.DataFrame:
    """–ì–∞—Ä–∞–Ω—Ç–∏—Ä—É–µ—Ç –Ω–∞–ª–∏—á–∏–µ —Å—Ç–æ–ª–±—Ü–∞ GID –∏ —Å—Ç–∞–≤–∏—Ç –µ–≥–æ –ø–µ—Ä–≤—ã–º.
    –ë–µ—Ä—ë—Ç –ø–µ—Ä–≤—ã–π –¥–æ—Å—Ç—É–ø–Ω—ã–π –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä: screen_id ‚Üí code ‚Üí uid ‚Üí id ‚Üí name ‚Üí –∞–≤—Ç–æ–Ω—É–º–µ—Ä–∞—Ü–∏—è."""
    d = df.copy()
    if "GID" not in d.columns:
        for c in ("screen_id", "code", "uid", "id", "name"):
            if c in d.columns:
                d["GID"] = d[c]
                break
        else:
            d["GID"] = range(1, len(d) + 1)
    # GID ‚Äî –ø–µ—Ä–≤—ã–º —Å—Ç–æ–ª–±—Ü–æ–º
    cols = ["GID"] + [c for c in d.columns if c != "GID"]
    return d.loc[:, cols]

# ==== FORECAST HELPERS ====

PLAYS_PER_HOUR = 30  # 30 –≤—ã—Ö–æ–¥–æ–≤/—á–∞—Å –ø–æ —É—Å–ª–æ–≤–∏—é

def _coerce_float(x):
    try:
        return float(str(x).replace(",", "."))
    except Exception:
        return None

def _ensure_min_bid_column(df: pd.DataFrame) -> pd.Series:
    """
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç pd.Series —Å —á–∏—Å–ª–æ–≤—ã–º–∏ minBid.
    –ò—â–µ—Ç —Å—Ç–∞–≤–∫—É –≤ –∫–æ–ª–æ–Ω–∫–∞—Ö: 'minBid', 'min_bid', 'min_bid_rub', 'price_per_play', 'price'
    ‚Äî –≤ —ç—Ç–æ–º –ø–æ—Ä—è–¥–∫–µ. –ü–µ—Ä–≤—É—é –Ω–∞–π–¥–µ–Ω–Ω—É—é –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ—Ç –≤ float.
    """
    cand = ["minBid", "min_bid", "min_bid_rub", "price_per_play", "price"]
    for c in cand:
        if c in df.columns:
            s = df[c].map(_coerce_float)
            if s.notna().any():
                return s
    # –Ω–∏—á–µ–≥–æ –Ω–µ –Ω–∞—à–ª–∏ ‚Äî –≤–µ—Ä–Ω—ë–º –ø—É—Å—Ç—É—é —Å–µ—Ä–∏—é
    return pd.Series([None]*len(df), index=df.index, dtype="float64")

def _impute_min_bid(df: pd.DataFrame) -> pd.Series:
    """
    –ò–º–ø—å—é—Ç –º–∏–Ω. —Å—Ç–∞–≤–∫–∏ –ø–æ –∫–∞—Å–∫–∞–¥—É:
    1) (city, format, owner)
    2) (city, format)
    3) (format)
    4) –ø–æ –≤—Å–µ–º
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–µ—Ä–∏—é —Å –∑–∞–ø–æ–ª–Ω–µ–Ω–Ω—ã–º–∏ –∑–Ω–∞—á–µ–Ω–∏—è–º–∏.
    """
    s = _ensure_min_bid_column(df)
    base = df.copy()

    # –Ω–æ—Ä–º–∞–ª–∏–∑—É–µ–º –∫–ª—é—á–∏ –¥–ª—è –≥—Ä—É–ø–ø
    city  = base.get("city").astype(str).str.strip().str.lower() if "city" in base.columns else pd.Series([""]*len(base), index=base.index)
    fmt   = base.get("format").astype(str).str.strip().str.upper() if "format" in base.columns else pd.Series([""]*len(base), index=base.index)
    owner = base.get("owner").astype(str).str.strip() if "owner" in base.columns else pd.Series([""]*len(base), index=base.index)

    out = s.copy()

    # —á—Ç–æ —É–∂–µ –µ—Å—Ç—å
    known = out.notna()

    # 1) –ø–æ (city, format, owner)
    if not known.all():
        g = pd.DataFrame({"city": city, "format": fmt, "owner": owner, "min": out}).groupby(["city","format","owner"])["min"].transform("mean")
        out = out.fillna(g)

    # 2) –ø–æ (city, format)
    if out.isna().any():
        g = pd.DataFrame({"city": city, "format": fmt, "min": out}).groupby(["city","format"])["min"].transform("mean")
        out = out.fillna(g)

    # 3) –ø–æ (format)
    if out.isna().any():
        g = pd.DataFrame({"format": fmt, "min": out}).groupby(["format"])["min"].transform("mean")
        out = out.fillna(g)

    # 4) –ø–æ –≤—Å–µ–º
    if out.isna().any():
        glob = out.mean()
        out = out.fillna(glob)

    return out

def forecast_by_min_bid(
    df_selection: pd.DataFrame,
    days: int,
    hours_per_day: float,
    budget: float | None = None,
) -> dict:
    """
    df_selection ‚Äî —Ç–∞–±–ª–∏—Ü–∞ —Å –≤—ã–±—Ä–∞–Ω–Ω—ã–º–∏ —ç–∫—Ä–∞–Ω–∞–º–∏ (–Ω–∞–ø—Ä–∏–º–µ—Ä, LAST_RESULT).
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ª–æ–≤–∞—Ä—å-—Ä–µ–∑—é–º–µ, –ø–ª—é—Å –¥–æ–±–∞–≤–ª—è–µ—Ç –≤ –∫–æ–ø–∏—é df —Å—Ç–æ–ª–±—Ü—ã:
      min_bid_imputed, max_possible_plays, planned_plays, planned_cost
    –õ–æ–≥–∏–∫–∞:
      - —Å—á–∏—Ç–∞–µ–º —Å—Ä–µ–¥–Ω—é—é –º–∏–Ω–∏–º–∞–ª—å–Ω—É—é —Å—Ç–∞–≤–∫—É –ø–æ—Å–ª–µ –∏–º–ø—å—é—Ç–∞;
      - –µ—Å–ª–∏ –¥–∞–Ω budget: planned_plays = min(budget / avg_min_bid, capacity)
        –∏ spend = planned_plays * avg_min_bid
      - –µ—Å–ª–∏ –±—é–¥–∂–µ—Ç–∞ –Ω–µ—Ç: planned_plays = capacity,
        spend = planned_plays * avg_min_bid
    """
    if df_selection is None or df_selection.empty:
        raise ValueError("–ù–µ—Ç –≤—ã–±—Ä–∞–Ω–Ω—ã—Ö —ç–∫—Ä–∞–Ω–æ–≤ –¥–ª—è –ø—Ä–æ–≥–Ω–æ–∑–∞.")

    n_screens = len(df_selection)
    if days <= 0 or hours_per_day <= 0:
        raise ValueError("days –∏ hours_per_day –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å > 0.")

    # –∏–º–ø—å—é—Ç —Å—Ç–∞–≤–æ–∫
    min_bid_imputed = _impute_min_bid(df_selection)
    avg_min = float(min_bid_imputed.mean()) if len(min_bid_imputed) else 0.0

    # –º–æ—â–Ω–æ—Å—Ç—å –∏–Ω–≤–µ–Ω—Ç–∞—Ä—è (—Ö–∞—Ä–¥-–ª–∏–º–∏—Ç –ø–æ–∫–∞–∑–æ–≤)
    capacity = int(n_screens * days * hours_per_day * PLAYS_PER_HOUR)

    if budget is not None and budget > 0 and avg_min > 0:
        planned_plays = int(min(budget / avg_min, capacity))
        spend = planned_plays * avg_min
    else:
        planned_plays = capacity
        spend = planned_plays * avg_min

    # —Ä–∞–≤–Ω–æ–º–µ—Ä–Ω–æ–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ–∫–∞–∑–æ–≤ –ø–æ —ç–∫—Ä–∞–Ω–∞–º (–ø—Ä–æ—Å—Ç–æ baseline)
    per_screen = planned_plays // max(n_screens, 1)
    remainder = planned_plays - per_screen * n_screens

    plan_df = df_selection.copy()
    plan_df = plan_df.reset_index(drop=True)
    plan_df["min_bid_imputed"] = min_bid_imputed.values
    plan_df["max_possible_plays"] = int(days * hours_per_day * PLAYS_PER_HOUR)
    plan_df["planned_plays"] = per_screen
    if remainder > 0:
        plan_df.loc[:remainder-1, "planned_plays"] = plan_df.loc[:remainder-1, "planned_plays"] + 1
    plan_df["planned_cost"] = plan_df["planned_plays"] * plan_df["min_bid_imputed"]

    summary = {
        "screens": n_screens,
        "days": days,
        "hours_per_day": hours_per_day,
        "plays_per_hour": PLAYS_PER_HOUR,
        "capacity_plays": capacity,
        "avg_min_bid": avg_min,
        "budget_input": budget,
        "planned_plays": int(planned_plays),
        "planned_spend": float(spend),
        "avg_cost_per_play_used": float(avg_min),  # –ø—Ä–∏ —Ç–∞–∫–æ–π –º–æ–¥–µ–ª–∏ —ç—Ç–æ = avg_min
    }
    return {"summary": summary, "plan_df": plan_df}

# ========= FORECAST =========

from typing import Optional, Dict, Any, List, Tuple
import math
import pandas as pd

MAX_PLAYS_PER_HOUR = 30  # –∫–∞–∫ —Ç—ã –∑–∞–¥–∞–≤–∞–ª
LAST_SELECTION_NAME = "selection"  # –ø—Ä–æ—Å—Ç–æ –ø–æ–¥–ø–∏—Å—å –≤ —Ñ–∞–π–ª–∞—Ö

def _parse_hours_windows(s: str) -> Optional[int]:
    """
    '07-10,17-21' -> 7 (3 —á–∞—Å–∞ —É—Ç—Ä–æ–º + 4 –≤–µ—á–µ—Ä–æ–º)
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å—É–º–º–∞—Ä–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —á–∞—Å–æ–≤ –∏–ª–∏ None, –µ—Å–ª–∏ —Å—Ç—Ä–æ–∫–∞ –ø—É—Å—Ç–∞—è/–±–∏—Ç–∞—è.
    """
    if not s:
        return None
    try:
        total = 0
        for part in s.replace(" ", "").split(","):
            if not part:
                continue
            a, b = part.split("-")
            h1 = int(a); h2 = int(b)
            # –∏–Ω—Ç–µ—Ä–≤–∞–ª [h1,h2), –µ—Å–ª–∏ –∫—Ç–æ-—Ç–æ –ø–∏—à–µ—Ç 7-10, –∑–Ω–∞—á–∏—Ç 7,8,9 = 3 —á–∞—Å–∞
            total += max(0, h2 - h1)
        return total if total > 0 else None
    except Exception:
        return None

def _fill_min_bid(df: pd.DataFrame) -> pd.DataFrame:
    """
    –ó–∞–ø–æ–ª–Ω—è–µ–º minBid –ø–æ –ø—Ä–∞–≤–∏–ª–∞–º:
    1) –µ—Å–ª–∏ –µ—Å—Ç—å ‚Äî –±–µ—Ä—ë–º –µ–≥–æ
    2) –∏–Ω–∞—á–µ –±–µ—Ä–µ–º –º–µ–¥–∏–∞–Ω—É –ø–æ (city, format, owner)
    3) –∏–Ω–∞—á–µ –º–µ–¥–∏–∞–Ω—É –ø–æ (city, format)
    4) –∏–Ω–∞—á–µ –º–µ–¥–∏–∞–Ω—É –ø–æ (format)
    5) –∏–Ω–∞—á–µ –≥–ª–æ–±–∞–ª—å–Ω—É—é –º–µ–¥–∏–∞–Ω—É –ø–æ –≤—Å–µ–º, –≥–¥–µ minBid –µ—Å—Ç—å
    –í df –¥–æ–±–∞–≤–ª—è–µ–º –∫–æ–ª–æ–Ω–∫–∏: min_bid_used, min_bid_source
    """
    work = df.copy()
    # –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–µ –∫–ª—é—á–∏
    def _norm_city(x):  return (str(x).strip().lower() if pd.notna(x) else "")
    def _norm_fmt(x):   return (str(x).strip().upper() if pd.notna(x) else "")
    def _norm_owner(x): return (str(x).strip().lower() if pd.notna(x) else "")

    work["_city_k"]  = work.get("city", "").map(_norm_city)   if "city" in work.columns  else ""
    work["_fmt_k"]   = work.get("format","").map(_norm_fmt)   if "format" in work.columns else ""
    work["_own_k"]   = work.get("owner","").map(_norm_owner)  if "owner" in work.columns  else ""

    # –∏—Å—Ç–æ—á–Ω–∏–∫–∏ –¥–ª—è –º–µ–¥–∏–∞–Ω
    have = work[pd.to_numeric(work.get("minBid"), errors="coerce").notna()].copy()
    have["minBid"] = pd.to_numeric(have["minBid"], errors="coerce")

    def median_for(mask: pd.Series) -> Optional[float]:
        vals = have.loc[mask, "minBid"]
        if vals.empty:
            return None
        return float(vals.median())

    # –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω—ã–µ —Å–ª–æ–≤–∞—Ä–∏ –º–µ–¥–∏–∞–Ω
    med_city_fmt_owner = {}
    if not have.empty:
        g = have.groupby(["_city_k","_fmt_k","_own_k"])["minBid"].median()
        med_city_fmt_owner = {k: float(v) for k,v in g.to_dict().items()}
    med_city_fmt = {}
    if not have.empty:
        g = have.groupby(["_city_k","_fmt_k"])["minBid"].median()
        med_city_fmt = {k: float(v) for k,v in g.to_dict().items()}
    med_fmt = {}
    if not have.empty:
        g = have.groupby(["_fmt_k"])["minBid"].median()
        med_fmt = {k: float(v) for k,v in g.to_dict().items()}
    global_med = float(have["minBid"].median()) if not have.empty else None

    used = []
    src  = []

    for _, r in work.iterrows():
        val = pd.to_numeric(r.get("minBid"), errors="coerce")
        if pd.notna(val):
            used.append(float(val))
            src.append("row:minBid")
            continue

        key3 = (r["_city_k"], r["_fmt_k"], r["_own_k"])
        key2 = (r["_city_k"], r["_fmt_k"])
        key1 = r["_fmt_k"]

        if key3 in med_city_fmt_owner:
            used.append(med_city_fmt_owner[key3]); src.append("median(city,format,owner)")
        elif key2 in med_city_fmt:
            used.append(med_city_fmt[key2]); src.append("median(city,format)")
        elif key1 in med_fmt:
            used.append(med_fmt[key1]); src.append("median(format)")
        elif global_med is not None:
            used.append(global_med); src.append("median(global)")
        else:
            used.append(None); src.append("none")

    work["min_bid_used"] = used
    work["min_bid_source"] = src
    return work

def _distribute_slots_evenly(n_screens: int, total_slots: int) -> List[int]:
    """
    –†–∞–≤–Ω–æ–º–µ—Ä–Ω–æ–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –≤—ã—Ö–æ–¥–æ–≤ –ø–æ —ç–∫—Ä–∞–Ω–∞–º.
    """
    if n_screens <= 0:
        return []
    base = total_slots // n_screens
    rem  = total_slots %  n_screens
    arr  = [base] * n_screens
    for i in range(rem):
        arr[i] += 1
    return arr

@dp.message(Command("forecast"))
async def cmd_forecast(m: types.Message):
    """
    /forecast [budget=...] [days=7] [hours_per_day=8] [hours=07-10,17-21]
    –†–∞–±–æ—Ç–∞–µ—Ç –ø–æ –ø–æ—Å–ª–µ–¥–Ω–µ–π –≤—ã–±–æ—Ä–∫–µ (LAST_RESULT).
    """
    global LAST_RESULT
    if LAST_RESULT is None or LAST_RESULT.empty:
        await m.answer("–ù–µ—Ç –ø–æ—Å–ª–µ–¥–Ω–µ–π –≤—ã–±–æ—Ä–∫–∏. –°–Ω–∞—á–∞–ª–∞ –ø–æ–¥–±–µ—Ä–∏—Ç–µ —ç–∫—Ä–∞–Ω—ã (/pick_city, /pick_any, /pick_at, /near –∏–ª–∏ —á–µ—Ä–µ–∑ /ask).")
        return

    parts = (m.text or "").strip().split()[1:]
    kv = {}
    for p in parts:
        if "=" in p:
            k, v = p.split("=", 1)
            kv[k.strip().lower()] = v.strip()

    budget = None
    if "budget" in kv:
        try:
            # –ø–æ–¥–¥–µ—Ä–∂–∏–º —Å—É—Ñ—Ñ–∏–∫—Å—ã m/k
            v = kv["budget"].lower().replace(" ", "")
            if v.endswith("m"): budget = float(v[:-1]) * 1_000_000
            elif v.endswith("k"): budget = float(v[:-1]) * 1_000
            else: budget = float(v)
        except Exception:
            budget = None

    days = int(kv.get("days", 7)) if str(kv.get("days","")).isdigit() else 7

    hours_per_day = None
    if "hours_per_day" in kv:
        try:
            hours_per_day = int(kv["hours_per_day"])
        except Exception:
            hours_per_day = None

    hours = kv.get("hours", "")
    win_hours = _parse_hours_windows(hours) if hours else None
    if hours_per_day is None:
        hours_per_day = (win_hours if (win_hours is not None) else 8)

    # –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –∏ minBid
    base = LAST_RESULT.copy()
    base = _fill_min_bid(base)

    # —Å—Ä–µ–¥–Ω—è—è –º–∏–Ω–∏–º–∞–ª—å–Ω–∞—è —Å—Ç–∞–≤–∫–∞
    mb_valid = pd.to_numeric(base["min_bid_used"], errors="coerce").dropna()
    if mb_valid.empty:
        await m.answer("–ù–µ —É–¥–∞–ª–æ—Å—å –æ—Ü–µ–Ω–∏—Ç—å —Å—Ç–∞–≤–∫—É: –Ω–∏ —É –æ–¥–Ω–æ–≥–æ —ç–∫—Ä–∞–Ω–∞ –Ω–µ—Ç minBid (–∏ –Ω–µ—á–µ–≥–æ –ø–æ–¥—Å—Ç–∞–≤–∏—Ç—å).")
        return
    avg_min = float(mb_valid.mean())

    n_screens = len(base)
    capacity  = n_screens * days * hours_per_day * MAX_PLAYS_PER_HOUR  # –º–∞–∫—Å–∏–º—É–º –≤—ã—Ö–æ–¥–æ–≤

    if budget is not None:
        # –ø–æ –±—é–¥–∂–µ—Ç—É ‚Äî —Å—á–∏—Ç–∞–µ–º –≤—ã—Ö–æ–¥—ã –æ—Ç —Å—Ä–µ–¥–Ω–µ–π —Å—Ç–∞–≤–∫–∏
        total_slots = int(budget // avg_min)
        total_slots = min(total_slots, capacity)
    else:
        # –±–µ–∑ –±—é–¥–∂–µ—Ç–∞ ‚Äî –º–∞–∫—Å–∏–º—É–º —á–∞—Å—Ç–æ—Ç—ã
        total_slots = capacity
        budget = total_slots * avg_min

    # —Ä–∞—Å–ø—Ä–µ–¥–µ–ª—è–µ–º –ø–æ —ç–∫—Ä–∞–Ω–∞–º
    per_screen = _distribute_slots_evenly(n_screens, total_slots)

    # –¥–æ–±–∞–≤–∏–º –ø–ª–∞–Ω –≤ —Ç–∞–±–ª–∏—Ü—É
    base = base.reset_index(drop=True)
    base["planned_slots"] = per_screen
    # —Å—á–∏—Ç–∞–µ–º —Å—Ç–æ–∏–º–æ—Å—Ç—å —Ç–æ—á–Ω–µ–µ ‚Äî —É–º–Ω–æ–∂–∞—è –Ω–∞ –∏–Ω–¥–∏–≤–∏–¥—É–∞–ª—å–Ω—ã–π min_bid_used
    base["planned_cost"]  = base["planned_slots"] * pd.to_numeric(base["min_bid_used"], errors="coerce").fillna(avg_min)

    # —Å–≤–æ–¥–∫–∞
    total_cost  = float(base["planned_cost"].sum())
    total_slots = int(base["planned_slots"].sum())

    # –∞–∫–∫—É—Ä–∞—Ç–Ω—ã–π —ç–∫—Å–ø–æ—Ä—Ç
    export_cols = []
    for c in ("screen_id","name","city","format","owner","lat","lon","minBid","min_bid_used","min_bid_source","planned_slots","planned_cost"):
        if c in base.columns:
            export_cols.append(c)
    plan_df = base[export_cols].copy()

    # CSV + XLSX
    try:
        csv_bytes = plan_df.to_csv(index=False).encode("utf-8-sig")
        await bot.send_document(
            m.chat.id,
            BufferedInputFile(csv_bytes, filename=f"forecast_{LAST_SELECTION_NAME}.csv"),
            caption=f"–ü—Ä–æ–≥–Ω–æ–∑ (—Å—Ä–µ–¥–Ω. minBid‚âà{avg_min:,.0f}): {total_slots} –≤—ã—Ö–æ–¥–æ–≤, –±—é–¥–∂–µ—Ç‚âà{total_cost:,.0f} ‚ÇΩ"
        )
    except Exception as e:
        await m.answer(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –æ—Ç–ø—Ä–∞–≤–∏—Ç—å CSV: {e}")

    try:
        import io as _io
        xbuf = _io.BytesIO()
        with pd.ExcelWriter(xbuf, engine="openpyxl") as w:
            plan_df.to_excel(w, index=False, sheet_name="forecast")
        xbuf.seek(0)
        await bot.send_document(
            m.chat.id,
            BufferedInputFile(xbuf.getvalue(), filename=f"forecast_{LAST_SELECTION_NAME}.xlsx"),
            caption=f"–ü—Ä–æ–≥–Ω–æ–∑ (–ø–æ–¥—Ä–æ–±–Ω–æ): –¥–Ω–∏={days}, —á–∞—Å—ã/–¥–µ–Ω—å={hours_per_day}, max {MAX_PLAYS_PER_HOUR}/—á–∞—Å"
        )
    except Exception as e:
        await m.answer(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –æ—Ç–ø—Ä–∞–≤–∏—Ç—å XLSX: {e}")

# --- helpers: –∑–∞–ø—É—Å–∫ –ª–æ–≥–∏–∫–∏ pick_city –±–µ–∑ –ø–æ–¥–º–µ–Ω—ã Message ---

import re

async def _run_pick_city(
    m: types.Message,
    city: str,
    n: int,
    formats: list[str] | None = None,
    owners: list[str] | None = None,
    fields: list[str] | None = None,
    shuffle: bool = True,
    fixed: bool = False,
    seed: int | None = None,
):
    global SCREENS, LAST_RESULT

    if SCREENS is None or SCREENS.empty:
        await m.answer("–°–Ω–∞—á–∞–ª–∞ –∑–∞–≥—Ä—É–∑–∏—Ç–µ –∏–Ω–≤–µ–Ω—Ç–∞—Ä—å: /sync_api –∏–ª–∏ –ø—Ä–∏—à–ª–∏—Ç–µ CSV/XLSX.")
        return

    df = SCREENS
    sub = df[df["city"].astype(str).str.strip().str.lower() == city.strip().lower()]

    if formats:
        formats_u = {f.strip().upper() for f in formats if f.strip()}
        if "format" in sub.columns:
            sub = sub[sub["format"].astype(str).str.upper().isin(formats_u)]

    if owners:
        if "owner" in sub.columns:
            pat = "|".join(re.escape(o) for o in owners if o.strip())
            sub = sub[sub["owner"].astype(str).str.contains(pat, case=False, na=False)]

    if sub.empty:
        await m.answer(f"–ù–µ –Ω–∞—à—ë–ª —ç–∫—Ä–∞–Ω–æ–≤ –≤ –≥–æ—Ä–æ–¥–µ ¬´{city}¬ª —Å –∑–∞–¥–∞–Ω–Ω—ã–º–∏ —Ñ–∏–ª—å—Ç—Ä–∞–º–∏.")
        return

    if shuffle:
        sub = sub.sample(frac=1, random_state=None).reset_index(drop=True)

    # —Ä–∞–≤–Ω–æ–º–µ—Ä–Ω–∞—è –≤—ã–±–æ—Ä–∫–∞ (—Ç–≤–æ—è —Å—É—â–µ—Å—Ç–≤—É—é—â–∞—è —Ñ—É–Ω–∫—Ü–∏—è)
    res = spread_select(
        sub.reset_index(drop=True),
        n,
        random_start=not fixed,
        seed=seed
    )
    LAST_RESULT = res

    # –µ—Å–ª–∏ –ø–æ–ø—Ä–æ—Å–∏–ª–∏ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ –ø–æ–ª—è ‚Äî –æ—Ç–¥–∞–¥–∏–º –∫–æ–º–ø–∞–∫—Ç–Ω–æ
    if fields:
        ok_fields = [c for c in fields if c in res.columns]
        if not ok_fields:
            await m.answer("–ü–æ–ª—è –Ω–µ —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω—ã. –î–æ—Å—Ç—É–ø–Ω—ã–µ: " + ", ".join(res.columns))
            return
        view = res[ok_fields]
        if ok_fields == ["screen_id"]:
            ids = [str(x) for x in view["screen_id"].tolist()]
            await send_lines(m, ids, header=f"–í—ã–±—Ä–∞–Ω–æ {len(ids)} screen_id –ø–æ –≥–æ—Ä–æ–¥—É ¬´{city}¬ª:")
        else:
            lines = [" | ".join(str(r[c]) for c in ok_fields) for _, r in view.iterrows()]
            await send_lines(m, lines, header=f"–í—ã–±—Ä–∞–Ω–æ {len(view)} —ç–∫—Ä–∞–Ω–æ–≤ –ø–æ –≥–æ—Ä–æ–¥—É ¬´{city}¬ª (–ø–æ–ª—è: {', '.join(ok_fields)}):")

        # –ø—Ä–∏–ª–æ–∂–∏–º XLSX —Å GID, –µ—Å–ª–∏ –µ—Å—Ç—å
        await send_gid_if_any(m, res, filename="city_screen_ids.xlsx",
                              caption=f"GID –ø–æ –≥–æ—Ä–æ–¥—É ¬´{city}¬ª (XLSX)")
        return

    # –¥–µ—Ñ–æ–ª—Ç–Ω—ã–π –≤—ã–≤–æ–¥
    lines = []
    for _, r in res.iterrows():
        nm = r.get("name","") or r.get("screen_id","")
        fmt = r.get("format",""); own = r.get("owner","")
        lat = r.get("lat"); lon = r.get("lon")
        lines.append(f"‚Ä¢ {r.get('screen_id','')} ‚Äî {nm} [{lat:.5f},{lon:.5f}] [{fmt} / {own}]")
    await send_lines(m, lines, header=f"–í—ã–±—Ä–∞–Ω–æ {len(res)} —ç–∫—Ä–∞–Ω–æ–≤ –ø–æ –≥–æ—Ä–æ–¥—É ¬´{city}¬ª (—Ä–∞–≤–Ω–æ–º–µ—Ä–Ω–æ):")

    await send_gid_if_any(m, res, filename="city_screen_ids.xlsx",
                          caption=f"GID –ø–æ –≥–æ—Ä–æ–¥—É ¬´{city}¬ª (XLSX)")


# ====== –£–¢–ò–õ–ò–¢–´ ======
def haversine_km(a: tuple[float, float], b: tuple[float, float]) -> float:
    lat1, lon1 = map(math.radians, a)
    lat2, lon2 = map(math.radians, b)
    dlat = lat2 - lat1
    dlon = lon2 - lon1
    r = 6371.0088
    h = math.sin(dlat/2)**2 + math.cos(lat1)*math.cos(lat2)*math.sin(dlon/2)**2
    return 2 * r * math.asin(math.sqrt(h))

def find_within_radius(df: pd.DataFrame, center: tuple[float,float], radius_km: float) -> pd.DataFrame:
    rows = []
    for _, row in df.iterrows():
        d = haversine_km(center, (row["lat"], row["lon"]))
        if d <= radius_km:
            rows.append({
                "screen_id": row.get("screen_id", ""),
                "name": row.get("name", ""),
                "city": row.get("city", ""),
                "format": row.get("format", ""),
                "owner": row.get("owner", ""),
                "lat": row["lat"],
                "lon": row["lon"],
                "distance_km": round(d, 3),
            })
    out = pd.DataFrame(rows)
    return out.sort_values("distance_km") if not out.empty else out

def spread_select(df: pd.DataFrame, n: int, *, random_start: bool = True, seed: int | None = None) -> pd.DataFrame:
    """–ñ–∞–¥–Ω—ã–π k-center (Gonzalez) c —Ä–∞–Ω–¥–æ–º–Ω—ã–º —Å—Ç–∞—Ä—Ç–æ–º –∏ —Å–ª—É—á–∞–π–Ω—ã–º–∏ —Ç–∞–π-–±—Ä–µ–π–∫–∞–º–∏."""
    import random as _random
    if df.empty or n <= 0:
        return df.iloc[0:0]
    n = min(n, len(df))

    if seed is not None:
        _random.seed(seed)

    coords = df[["lat", "lon"]].to_numpy()

    # —Å—Ç–∞—Ä—Ç: —Å–ª—É—á–∞–π–Ω—ã–π (–∏–ª–∏ –æ—Ç –º–µ–¥–∏–∞–Ω—ã, –µ—Å–ª–∏ random_start=False)
    if random_start:
        start_idx = _random.randrange(len(df))
    else:
        lat_med = float(df["lat"].median())
        lon_med = float(df["lon"].median())
        start_idx = min(
            range(len(df)),
            key=lambda i: haversine_km((lat_med, lon_med), (coords[i][0], coords[i][1]))
        )

    chosen = [start_idx]
    dists = [
        haversine_km((coords[start_idx][0], coords[start_idx][1]), (coords[i][0], coords[i][1]))
        for i in range(len(df))
    ]

    while len(chosen) < n:
        maxd = max(dists)
        candidates = [i for i, d in enumerate(dists) if d == maxd]
        next_idx = _random.choice(candidates)  # —Å–ª—É—á–∞–π–Ω—ã–π –≤—ã–±–æ—Ä —Å—Ä–µ–¥–∏ —Å–∞–º—ã—Ö ¬´–¥–∞–ª—å–Ω–∏—Ö¬ª
        chosen.append(next_idx)
        cx, cy = coords[next_idx]
        for i in range(len(df)):
            d = haversine_km((cx, cy), (coords[i][0], coords[i][1]))
            if d < dists[i]:
                dists[i] = d

    res = df.iloc[chosen].copy()
    # –∏–Ω—Ñ–æ-–ø–æ–ª–µ: –º–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –¥–∏—Å—Ç–∞–Ω—Ü–∏—è –¥–æ –±–ª–∏–∂–∞–π—à–µ–≥–æ –≤—ã–±—Ä–∞–Ω–Ω–æ–≥–æ
    res["min_dist_to_others_km"] = 0.0
    cc = res[["lat","lon"]].to_numpy()
    for i in range(len(res)):
        mind = min(
            haversine_km((cc[i][0], cc[i][1]), (cc[j][0], cc[j][1]))
            for j in range(len(res)) if j != i
        ) if len(res) > 1 else 0.0
        res.iat[i, res.columns.get_loc("min_dist_to_others_km")] = round(mind, 3)
    return res

def parse_kwargs(parts: list[str]) -> dict[str, str]:
    """–ü–∞—Ä—Å–∏–º —Ö–≤–æ—Å—Ç –∫–æ–º–∞–Ω–¥—ã –≤–∏–¥–∞ key=value (–∑–Ω–∞—á–µ–Ω–∏—è –º–æ–∂–Ω–æ –±—Ä–∞—Ç—å –≤ –∫–∞–≤—ã—á–∫–∏)."""
    out: dict[str,str] = {}
    for p in parts:
        if "=" in p:
            k, v = p.split("=", 1)
            out[k.strip()] = v.strip().strip('"').strip("'")
    return out

def _split_list(val: str) -> list[str]:
    if not val:
        return []
    return [x.strip() for x in val.replace(";", ",").split(",") if x.strip()]

def parse_fields(arg: str) -> list[str]:
    allowed = {
        "screen_id","name","city","format","owner","lat","lon",
        "distance_km","min_dist_to_others_km"
    }
    cols = [c.strip() for c in arg.split(",")]
    return [c for c in cols if c in allowed]

def parse_list(val: str) -> list[str]:
    if not isinstance(val, str):
        return []
    # –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª–∏: –∑–∞–ø—è—Ç–∞—è, —Ç–æ—á–∫–∞ —Å –∑–∞–ø—è—Ç–æ–π, –≤–µ—Ä—Ç–∏–∫–∞–ª—å–Ω–∞—è —á–µ—Ä—Ç–∞
    for sep in ("|", ";"):
        val = val.replace(sep, ",")
    return [x.strip() for x in val.split(",") if x.strip()]

def apply_filters(df: pd.DataFrame, kwargs: dict[str,str]) -> pd.DataFrame:
    """
    –ü–æ–¥–¥–µ—Ä–∂–∫–∞:
      - format=...  (–æ–¥–∏–Ω –∏–ª–∏ –Ω–µ—Å–∫–æ–ª—å–∫–æ: comma/; / |)
        —Å–ø–µ—Ü-–∞–ª–∏–∞—Å: city / –≥–∏–¥—ã ‚Üí –≤—Å–µ, —á—Ç–æ –Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è —Å CITY_FORMAT
      - owner=...   (–æ–¥–∏–Ω –∏–ª–∏ –Ω–µ—Å–∫–æ–ª—å–∫–æ: comma/; / |), –ø–æ–¥—Å—Ç—Ä–æ—á–Ω—ã–π –ø–æ–∏—Å–∫ (case-insensitive)
    """
    out = df

    # -------- FORMAT --------
    fmt_val = kwargs.get("format") or kwargs.get("formats") or kwargs.get("format_in")
    if fmt_val:
        fmt_list_raw = parse_list(fmt_val)
        fmt_list = [s.upper() for s in fmt_list_raw]
        mask = None
        col = out["format"].astype(str).str.upper()

        for f in fmt_list:
            if f.lower() in {"city", "city_format", "cityformat", "citylight", "–≥–∏–¥", "–≥–∏–¥—ã"}:
                m = col.str.startswith("CITY_FORMAT")
            else:
                m = (col == f)
            mask = m if mask is None else (mask | m)

        if mask is not None:
            out = out[mask]

    # -------- OWNER --------
    own_val = kwargs.get("owner") or kwargs.get("owners") or kwargs.get("owner_in")
    if own_val:
        owners = parse_list(own_val)
        mask = None
        col = out["owner"].astype(str).str.lower()
        for o in owners:
            m = col.str.contains(o.strip().lower())
            mask = m if mask is None else (mask | m)
        if mask is not None:
            out = out[mask]

    return out

import io
from aiogram.types import BufferedInputFile

# –†–∞–∑–±–∏–≤–∫–∞ –¥–ª–∏–Ω–Ω–æ–≥–æ –æ—Ç–≤–µ—Ç–∞ –Ω–∞ —á–∞—Å—Ç–∏ (—á—Ç–æ–±—ã –¢–µ–ª–µ–≥—Ä–∞–º –≤—Å—ë —É–º–µ—Å—Ç–∏–ª)
async def send_lines(message, lines, header: str | None = None, chunk: int = 60, parse_mode: str | None = None):
    """
    –û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç —Å–ø–∏—Å–æ–∫ —Å—Ç—Ä–æ–∫ –ø–∞—á–∫–∞–º–∏.
    - chunk: –º–∞–∫—Å. –∫–æ–ª-–≤–æ —Å—Ç—Ä–æ–∫ –≤ –æ–¥–Ω–æ–º —Å–æ–æ–±—â–µ–Ω–∏–∏ (–¥–æ–ø. –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ)
    - —Ç–∞–∫–∂–µ —Ä–µ–∂–µ—Ç –ø–æ –ª–∏–º–∏—Ç—É —Å–∏–º–≤–æ–ª–æ–≤ Telegram (~4096), –∏—Å–ø–æ–ª—å–∑—É–µ–º –∑–∞–ø–∞—Å 3900.
    """
    if not lines:
        if header:
            await message.answer(header, parse_mode=parse_mode)
        return

    # –æ—Ç–ø—Ä–∞–≤–∏–º –∑–∞–≥–æ–ª–æ–≤–æ–∫ –æ—Ç–¥–µ–ª—å–Ω—ã–º —Å–æ–æ–±—â–µ–Ω–∏–µ–º
    if header:
        await message.answer(header, parse_mode=parse_mode)

    MAX_CHARS = 3900  # –Ω–µ–±–æ–ª—å—à–æ–π –∑–∞–ø–∞—Å –∫ –ª–∏–º–∏—Ç—É Telegram
    buf: list[str] = []
    buf_len = 0
    buf_cnt = 0

    for line in lines:
        s = str(line)
        # –µ—Å–ª–∏ —Å—Ç—Ä–æ–∫–∞ —Å–∞–º–∞ –ø–æ —Å–µ–±–µ —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω–∞—è ‚Äî –ø–æ—Ä–µ–∂–µ–º –≥—Ä—É–±–æ –ø–æ —Å–∏–º–≤–æ–ª–∞–º
        if len(s) > MAX_CHARS:
            # —Å–Ω–∞—á–∞–ª–∞ –≤—ã–ª—å–µ–º –Ω–∞–∫–æ–ø–ª–µ–Ω–Ω–æ–µ
            if buf:
                await message.answer("\n".join(buf), parse_mode=parse_mode)
                buf, buf_len, buf_cnt = [], 0, 0
            # –ø–æ—Ä–µ–∑–∞—Ç—å –æ–¥–Ω—É –æ—á–µ–Ω—å –¥–ª–∏–Ω–Ω—É—é —Å—Ç—Ä–æ–∫—É
            for i in range(0, len(s), MAX_CHARS):
                await message.answer(s[i:i+MAX_CHARS], parse_mode=parse_mode)
            continue

        # –ø—Ä–æ–≤–µ—Ä—è–µ–º, –≤–ª–µ–∑–µ—Ç –ª–∏ —Å–ª–µ–¥—É—é—â–∞—è —Å—Ç—Ä–æ–∫–∞ –≤ —Ç–µ–∫—É—â–∏–π –±—É—Ñ–µ—Ä
        if buf and (buf_len + 1 + len(s) > MAX_CHARS or buf_cnt >= chunk):
            await message.answer("\n".join(buf), parse_mode=parse_mode)
            buf, buf_len, buf_cnt = [], 0, 0

        # –¥–æ–±–∞–≤–ª—è–µ–º —Å—Ç—Ä–æ–∫—É
        buf.append(s)
        buf_len += (len(s) + 1)  # +1 –∑–∞ –ø–µ—Ä–µ–≤–æ–¥ —Å—Ç—Ä–æ–∫–∏
        buf_cnt += 1

    # –¥–æ–±—Ä–æ—Å–∏–º –æ—Å—Ç–∞—Ç–æ–∫
    if buf:
        await message.answer("\n".join(buf), parse_mode=parse_mode)

def _format_mask(series: pd.Series, token: str) -> pd.Series:
    """
    –ë—É–ª–µ–≤–∞ –º–∞—Å–∫–∞ –ø–æ —Ñ–æ—Ä–º–∞—Ç—É:
      - 'city', '–≥–∏–¥', ... ‚Üí –≤—Å—ë, —á—Ç–æ –Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è —Å CITY_FORMAT
      - 'billboard', 'bb'  ‚Üí BILLBOARD
      - –∏–Ω–∞—á–µ ‚Äî —Ç–æ—á–Ω–æ–µ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ –ø–æ –≤–µ—Ä—Ö–Ω–µ–º—É —Ä–µ–≥–∏—Å—Ç—Ä—É
    –ü—Ä–æ–±–µ–ª—ã –∏ —Ä–µ–≥–∏—Å—Ç—Ä –∏–≥–Ω–æ—Ä–∏—Ä—É—é—Ç—Å—è.
    """
    col = series.astype(str).str.upper().str.strip()
    t = token.strip().upper()
    if t in {"CITY", "CITY_FORMAT", "CITYFORMAT", "CITYLIGHT", "–ì–ò–î", "–ì–ò–î–´"}:
        return col.str.startswith("CITY_FORMAT")
    if t in {"BILLBOARD", "BB"}:
        return col == "BILLBOARD"
    return col == t


def save_screens_cache(df: pd.DataFrame):
    """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –∫—ç—à –Ω–∞ –¥–∏—Å–∫ –≤ data/screens_cache.*"""
    global LAST_SYNC_TS

    try:
        if df is None or df.empty:
            return False

        # —Å–æ—Ö—Ä–∞–Ω—è–µ–º parquet –∏ csv
        df.to_parquet(CACHE_PARQUET, index=False)
        df.to_csv(CACHE_CSV, index=False, encoding="utf-8-sig")

        LAST_SYNC_TS = time.time()
        meta = {"ts": LAST_SYNC_TS, "rows": len(df)}
        CACHE_META.write_text(json.dumps(meta, ensure_ascii=False, indent=2), encoding="utf-8")

        print(f"üíæ –ö—ç—à —Å–æ—Ö—Ä–∞–Ω—ë–Ω –Ω–∞ –¥–∏—Å–∫: {len(df)} —Å—Ç—Ä–æ–∫.")
        return True
    except Exception as e:
        logging.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ –∫—ç—à–∞: {e}")
        return False


def load_screens_cache() -> bool:
    """–ü—ã—Ç–∞–µ—Ç—Å—è –ø–æ–¥–Ω—è—Ç—å –∏–Ω–≤–µ–Ω—Ç–∞—Ä—å –∏–∑ –∫—ç—à–∞. –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç True/False ‚Äî —É–¥–∞–ª–æ—Å—å –ª–∏."""
    global SCREENS, LAST_SYNC_TS

    df: pd.DataFrame | None = None

    # –ø—Ä–µ–¥–ø–æ—á–∏—Ç–∞–µ–º parquet ‚Äî –±—ã—Å—Ç—Ä–µ–µ
    if CACHE_PARQUET.exists():
        try:
            df = pd.read_parquet(CACHE_PARQUET)
        except Exception:
            df = None

    # –µ—Å–ª–∏ parquet –Ω–µ —É–¥–∞–ª–æ—Å—å ‚Äî –ø—Ä–æ–±—É–µ–º csv
    if df is None and CACHE_CSV.exists():
        try:
            df = pd.read_csv(CACHE_CSV)
        except Exception:
            df = None

    if df is None or df.empty:
        return False

    SCREENS = df

    # —á–∏—Ç–∞–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ (–≤—Ä–µ–º—è/–∫–æ–ª-–≤–æ), –µ—Å–ª–∏ –µ—Å—Ç—å
    try:
        meta = json.loads(CACHE_META.read_text(encoding="utf-8"))
        LAST_SYNC_TS = float(meta.get("ts")) if "ts" in meta else None
    except Exception:
        LAST_SYNC_TS = None

    return True

if load_screens_cache():
    logging.info(f"Loaded screens cache: {len(SCREENS)} rows, ts={LAST_SYNC_TS}")
else:
    logging.info("No local screens cache found.")

def parse_mix(val: str) -> list[tuple[str, str]]:
    """
    –†–∞–∑–±–æ—Ä —Å—Ç—Ä–æ–∫–∏ mix=... –Ω–∞ –ø–∞—Ä—ã (token, value_str).
    –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª–∏: ',', ';', '|'
    –ü—Ä–∏–º–µ—Ä—ã:
      "BILLBOARD:90%,CITY:10%"
      "CITY_FORMAT_RC:5,CITY_FORMAT_WD:15"
    """
    if not isinstance(val, str) or not val.strip():
        return []
    s = val.replace("|", ",").replace(";", ",")
    items = []
    for part in s.split(","):
        part = part.strip()
        if not part or ":" not in part:
            continue
        token, v = part.split(":", 1)
        items.append((token.strip(), v.strip()))
    return items

def reach_score(item: dict, hours_per_day: int) -> float:
    # 1) –µ—Å–ª–∏ –µ—Å—Ç—å GRP ‚Äî –ø—Ä–∏–æ—Ä–∏—Ç–∏–∑–∏—Ä—É–µ–º –µ–≥–æ (–∫–∞–∫ ¬´–æ—Ö–≤–∞—Ç–Ω–æ—Å—Ç—å¬ª —ç–∫—Ä–∞–Ω–∞)
    g = item.get("grp")
    if g is not None:
        try:
            return float(g)
        except Exception:
            pass

    # 2) –∏–Ω–∞—á–µ OTS –∫–∞–∫ —Å—É—Ä—Ä–æ–≥–∞—Ç
    ots = item.get("ots")
    if ots is not None:
        try:
            return float(ots)
        except Exception:
            pass

    # 3) –ø—Ä–µ–∂–Ω–∏–µ —ç–≤—Ä–∏—Å—Ç–∏–∫–∏ (fallback)
    a = (item.get("audience_per_day") or item.get("audiencePerDay") or 0) or 0
    if a:
        return float(a)

    traffic_h = item.get("traffic_per_hour") or item.get("trafficPerHour")
    vis = item.get("visibility_index") or item.get("visibilityIndex") or 1.0
    if traffic_h:
        try:
            return float(traffic_h) * hours_per_day * float(vis)
        except Exception:
            return float(traffic_h) * hours_per_day

    vpl = item.get("viewers_per_loop") or item.get("viewersPerLoop")
    lph = item.get("loops_per_hour") or item.get("loopsPerHour")
    if vpl and lph:
        try:
            return float(vpl) * float(lph) * hours_per_day
        except Exception:
            return float(vpl) * hours_per_day

    return 0.0

# -------- helpers --------

import re

def parse_kv(text: str) -> dict:
    """
    –†–∞–∑–±–∏—Ä–∞–µ—Ç —Å—Ç—Ä–æ–∫—É –≤–∏–¥–∞ "key=val key2=val2" –∏–ª–∏ —Å —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—è–º–∏ –∑–∞–ø—è—Ç—ã–º–∏/—Ç–æ—á–∫–∞–º–∏ —Å –∑–∞–ø—è—Ç–æ–π.
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç dict —Å –∫–ª—é—á–∞–º–∏ –≤ –Ω–∏–∂–Ω–µ–º —Ä–µ–≥–∏—Å—Ç—Ä–µ.
    """
    kv = {}
    # –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º "key=val key=val", –∞ —Ç–∞–∫–∂–µ —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª–∏ , ; \n
    parts = re.split(r"[,\n;]\s*|\s+(?=\w+=)", text.strip())
    for part in parts:
        if "=" in part:
            k, v = part.split("=", 1)
            kv[k.strip().lower()] = v.strip()
    return kv

def _allocate_counts(total_n: int, mix_items: list[tuple[str, str]]) -> list[tuple[str, int]]:
    """
    –í—Ö–æ–¥: [('BILLBOARD','90%'), ('CITY','10%')] –∏–ª–∏ [('BILLBOARD','18'), ('CITY','2')]
    –í—ã—Ö–æ–¥: [('BILLBOARD', 18), ('CITY', 2)]
    –ü—Ä–∞–≤–∏–ª–∞:
      - –µ—Å–ª–∏ –µ—Å—Ç—å —Å—É—Ñ—Ñ–∏–∫—Å '%', —Å—á–∏—Ç–∞–µ–º –ø—Ä–æ—Ü–µ–Ω—Ç—ã (—Å –æ–∫—Ä—É–≥–ª–µ–Ω–∏–µ–º –∏ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ–º –æ—Å—Ç–∞—Ç–∫–∞)
      - —á–∏—Å–ª–∞ –±–µ–∑ % —Ç—Ä–∞–∫—Ç—É—é—Ç—Å—è –∫–∞–∫ —Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —à—Ç—É–∫–∏
      - –¥–æ–ø—É—Å–∫–∞–µ—Ç—Å—è —Å–º–µ—à–∞–Ω–Ω—ã–π —Ä–µ–∂–∏–º: —Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ + –ø—Ä–æ—Ü–µ–Ω—Ç—ã –Ω–∞ –æ—Å—Ç–∞—Ç–æ–∫
    """
    fixed: list[tuple[str, int]] = []
    perc:  list[tuple[str, float]] = []

    for token, v in mix_items:
        if v.endswith("%"):
            try:
                perc.append((token, float(v[:-1])))
            except:
                pass
        else:
            try:
                fixed.append((token, int(v)))
            except:
                pass

    # —Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω–∞—è —á–∞—Å—Ç—å
    fixed_sum = sum(cnt for _, cnt in fixed)
    remaining = max(0, total_n - fixed_sum)

    # –ø—Ä–æ—Ü–µ–Ω—Ç–Ω–∞—è —á–∞—Å—Ç—å
    out: list[tuple[str, int]] = fixed[:]
    if remaining > 0 and perc:
        p_total = sum(p for _, p in perc)
        if p_total <= 0:
            # –µ—Å–ª–∏ –ø—Ä–æ—Ü–µ–Ω—Ç—ã –∑–∞–¥–∞–Ω—ã, –Ω–æ —Å—É–º–º–∞ –Ω—É–ª–µ–≤–∞—è/–Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω–∞—è ‚Äî –ø—Ä–æ—Å—Ç–æ –æ—Ç–¥–∞—ë–º –≤—Å—ë –ø–µ—Ä–≤–æ–º—É
            out.append((perc[0][0], remaining))
        else:
            # –±–∞–∑–æ–≤–æ–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ + —Ä–∞–∑–¥–∞—á–∞ –æ—Å—Ç–∞—Ç–∫–æ–≤ –ø–æ —É–±—ã–≤–∞–Ω–∏—é –¥—Ä–æ–±–Ω–æ–π —á–∞—Å—Ç–∏
            raw = [(tok, remaining * p / p_total) for tok, p in perc]
            base = [(tok, int(x)) for tok, x in raw]
            used = sum(cnt for _, cnt in base)
            rem  = remaining - used
            fracs = sorted(((x - int(x), tok) for tok, x in raw), reverse=True)
            extra = {}
            for i in range(rem):
                _, tok = fracs[i % len(fracs)]
                extra[tok] = extra.get(tok, 0) + 1
            # —Å–æ–±—Ä–∞—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç
            for tok, cnt in base:
                out.append((tok, cnt + extra.get(tok, 0)))

    # –µ—Å–ª–∏ –ø—Ä–æ—Ü–µ–Ω—Ç—ã –µ—Å—Ç—å, –∞ —Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –Ω–µ—Ç –∏ remaining==0 (n –ø–µ—Ä–µ–∫—Ä—ã—Ç–æ —Ñ–∏–∫—Å–∞–º–∏) ‚Äî –ø—Ä–æ—Å—Ç–æ out —É–∂–µ –≥–æ—Ç–æ–≤
    # —É–±–µ–¥–∏–º—Å—è, —á—Ç–æ —Å—É–º–º–∞—Ä–Ω–æ –Ω–µ –ø—Ä–µ–≤—ã—à–∞–µ–º total_n (–Ω–∞ –≤—Å—è–∫–∏–π)
    total = sum(cnt for _, cnt in out)
    if total > total_n:
        # –æ—Ç—Ä–µ–∂–µ–º –ª–∏—à–Ω–µ–µ —Å –∫–æ–Ω—Ü–∞
        delta = total - total_n
        trimmed = []
        for tok, cnt in out:
            take = max(0, cnt - delta)
            delta -= (cnt - take)
            trimmed.append((tok, take))
            if delta <= 0:
                trimmed.extend(out[len(trimmed):])
                break
        out = trimmed
    return out


def _select_with_mix(df_city: pd.DataFrame, n: int, mix_arg: str | None,
                     *, random_start: bool = True, seed: int | None = None) -> pd.DataFrame:
    """
    –î–µ–ª–∏—Ç –¥–∞—Ç–∞—Ñ—Ä–µ–π–º –Ω–∞ –ø–æ–¥–Ω–∞–±–æ—Ä—ã –ø–æ —Ñ–æ—Ä–º–∞—Ç–∞–º —Å–æ–≥–ª–∞—Å–Ω–æ mix, —Ä–∞–≤–Ω–æ–º–µ—Ä–Ω–æ –≤—ã–±–∏—Ä–∞–µ—Ç –≤–Ω—É—Ç—Ä–∏ –∫–∞–∂–¥–æ–≥–æ,
    –æ–±—ä–µ–¥–∏–Ω—è–µ—Ç –∏ –¥–æ–±–∏—Ä–∞–µ—Ç –æ—Å—Ç–∞—Ç–æ–∫ –¢–û–õ–¨–ö–û –∏–∑ —Ä–∞–∑—Ä–µ—à—ë–Ω–Ω—ã—Ö —Ñ–æ—Ä–º–∞—Ç–æ–≤ mix.
    """
    # –±–µ–∑ mix ‚Üí –æ–±—ã—á–Ω—ã–π —Ä–∞–≤–Ω–æ–º–µ—Ä–Ω—ã–π –≤—ã–±–æ—Ä
    if not mix_arg:
        return spread_select(df_city.reset_index(drop=True), n, random_start=random_start, seed=seed)

    items = parse_mix(mix_arg)
    if not items:
        return spread_select(df_city.reset_index(drop=True), n, random_start=random_start, seed=seed)

    # —Å–ø–∏—Å–æ–∫ —Ä–∞–∑—Ä–µ—à—ë–Ω–Ω—ã—Ö —Ñ–æ—Ä–º–∞—Ç–æ–≤ –∏–∑ mix (–∫–∞–∫ —Ç–æ–∫–µ–Ω—ã)
    allowed_tokens = [tok for tok, _ in items]

    # —Å—É–∑–∏–º –∏—Å—Ö–æ–¥–Ω—ã–π –ø—É–ª —Å—Ä–∞–∑—É —Ç–æ–ª—å–∫–æ –∫ —Ä–∞–∑—Ä–µ—à—ë–Ω–Ω—ã–º —Ñ–æ—Ä–º–∞—Ç–∞–º
    if "format" not in df_city.columns:
        # –Ω–∞ –≤—Å—è–∫–∏–π ‚Äî –µ—Å–ª–∏ –Ω–µ—Ç –∫–æ–ª–æ–Ω–∫–∏ format, –ø–∞–¥–∞–µ–º –≤ –æ–±—ã—á–Ω—ã–π —Ä–µ–∂–∏–º
        base_pool = df_city.copy()
    else:
        mask_allowed = None
        col = df_city["format"]
        for tok in allowed_tokens:
            m = _format_mask(col, tok)
            mask_allowed = m if mask_allowed is None else (mask_allowed | m)
        base_pool = df_city[mask_allowed] if mask_allowed is not None else df_city.copy()

    if base_pool.empty:
        # –Ω–∏—á–µ–≥–æ –∏–∑ —É–∫–∞–∑–∞–Ω–Ω—ã—Ö —Ñ–æ—Ä–º–∞—Ç–æ–≤ ‚Äî –≤–µ—Ä–Ω—ë–º –æ–±—ã—á–Ω—ã–π —Ä–∞–≤–Ω–æ–º–µ—Ä–Ω—ã–π –∏–∑ –≤—Å–µ–≥–æ (—á—Ç–æ–±—ã –Ω–µ –ø—É—Å—Ç–æ)
        return spread_select(df_city.reset_index(drop=True), n, random_start=random_start, seed=seed)

    targets = _allocate_counts(n, items)  # [('BILLBOARD', 18), ('CITY', 2)]
    selected_parts: list[pd.DataFrame] = []
    used_ids: set[str] = set()

    pool = base_pool.copy()

    # –≤—ã–±–∏—Ä–∞–µ–º –ø–æ –∫–≤–æ—Ç–∞–º
    for token, need in targets:
        if need <= 0 or pool.empty:
            continue
        mask = _format_mask(pool["format"], token) if "format" in pool.columns else pd.Series([True]*len(pool), index=pool.index)
        subset = pool[mask]
        if subset.empty:
            continue
        pick_n = min(need, len(subset))
        picked = spread_select(subset.reset_index(drop=True), pick_n, random_start=random_start, seed=seed)
        selected_parts.append(picked)

        # –∏—Å–∫–ª—é—á–∏–º –≤—ã–±—Ä–∞–Ω–Ω—ã–µ –∏–∑ –ø—É–ª–∞
        if "screen_id" in pool.columns and "screen_id" in picked.columns:
            chosen_ids = picked["screen_id"].astype(str).tolist()
            used_ids.update(chosen_ids)
            pool = pool[~pool["screen_id"].astype(str).isin(used_ids)]
        else:
            # fallback –ø–æ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç–∞–º
            coords = set((float(a), float(b)) for a, b in picked[["lat","lon"]].itertuples(index=False, name=None))
            pool = pool[~((pool["lat"].astype(float).round(7).isin([x for x, _ in coords])) &
                          (pool["lon"].astype(float).round(7).isin([y for _, y in coords])))]
        if pool.empty:
            break

    combined = pd.concat(selected_parts, ignore_index=True) if selected_parts else base_pool.iloc[0:0]

    # –¥–æ–±–∏—Ä–∞–µ–º –Ω–µ–¥–æ—Å—Ç–∞—é—â–µ–µ –¢–û–õ–¨–ö–û –∏–∑ base_pool (—Ä–∞–∑—Ä–µ—à—ë–Ω–Ω—ã–µ —Ñ–æ—Ä–º–∞—Ç—ã)
    remain = n - len(combined)
    if remain > 0 and not pool.empty:
        extra = spread_select(pool.reset_index(drop=True), min(remain, len(pool)), random_start=random_start, seed=seed)
        combined = pd.concat([combined, extra], ignore_index=True)

    return combined.head(n)
async def send_gid_xlsx(chat_id: int, ids: list[str], *, filename: str = "screen_ids.xlsx", caption: str = "GID —Å–ø–∏—Å–æ–∫ (XLSX)"):
    """–û—Ç–ø—Ä–∞–≤–∫–∞ XLSX —Å –æ–¥–Ω–∏–º —Å—Ç–æ–ª–±—Ü–æ–º GID –∏–∑ —Å–ø–∏—Å–∫–∞ screen_id."""
    df = pd.DataFrame({"GID": [str(x) for x in ids]})
    bio = io.BytesIO()
    with pd.ExcelWriter(bio, engine="openpyxl") as writer:
        df.to_excel(writer, index=False)
    bio.seek(0)
    await bot.send_document(
        chat_id,
        BufferedInputFile(bio.read(), filename=filename),
        caption=caption,
    )

async def send_gid_if_any(message: types.Message, df: pd.DataFrame, *, filename: str, caption: str):
    """–ï—Å–ª–∏ –≤ df –µ—Å—Ç—å –∫–æ–ª–æ–Ω–∫–∞ screen_id –∏ —Ç–∞–º –Ω–µ –ø—É—Å—Ç–æ ‚Äî –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º XLSX —Å –∫–æ–ª–æ–Ω–∫–æ–π GID."""
    if df is None or df.empty or "screen_id" not in df.columns:
        return
    ids = [s for s in (df["screen_id"].astype(str).tolist()) if str(s).strip() and str(s).lower() != "nan"]
    if ids:
        await send_gid_xlsx(message.chat.id, ids, filename=filename, caption=caption)

# --- ACCESS CONTROL HELPERS ---

def _owner_only(user_id: int) -> bool:
    return TELEGRAM_OWNER_ID == 0 or user_id == TELEGRAM_OWNER_ID

def _auth_headers_all_variants(token: str) -> list[tuple[str, dict]]:
    """
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ (label, headers). label ‚Äî —á—Ç–æ–±—ã –∫—Ä–∞—Å–∏–≤–æ –ª–æ–≥–∏—Ä–æ–≤–∞—Ç—å, —á—Ç–æ –º—ã –ø—Ä–æ–±–æ–≤–∞–ª–∏.
    """
    t = (token or "").strip()
    if not t:
        return [("no-auth", {})]
    return [
        ("Bearer",      {"Authorization": f"Bearer {t}"}),
        ("Token",       {"Authorization": f"Token {t}"}),
        ("X-API-Key",   {"X-API-Key": t}),
        ("x-api-key",   {"x-api-key": t}),
        ("X-Auth-Token",{"X-Auth-Token": t}),
        ("Auth-Token",  {"Auth-Token": t}),
        ("authToken",   {"authToken": t}),
        ("Cookie",      {"Cookie": f"authToken={t}"}),
    ]

from urllib.parse import urljoin
import json, aiohttp, logging

# --- API FETCH (–ø–æ—Å—Ç—Ä–∞–Ω–∏—á–Ω–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ –∏–Ω–≤–µ–Ω—Ç–∞—Ä—è —Å —Å–µ—Ä–≤–µ—Ä–Ω–æ–π —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–µ–π) ---
import aiohttp

def _build_server_query(filters: dict | None) -> dict:
    """
    –ì–æ—Ç–æ–≤–∏–º –Ω–∞–±–æ—Ä query-–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –¥–ª—è —Å–µ—Ä–≤–µ—Ä–∞.
    –ú—ã –∑–∞–∫–ª–∞–¥—ã–≤–∞–µ–º —Å—Ä–∞–∑—É –Ω–µ—Å–∫–æ–ª—å–∫–æ –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤ –∏–º–µ–Ω (type/format, owner/displayOwnerName, city/cityName/search),
    –ø–æ—Ç–æ–º—É —á—Ç–æ —Å–µ—Ä–≤–µ—Ä —Å–ø–æ–∫–æ–π–Ω–æ –ø—Ä–æ–∏–≥–Ω–æ—Ä–∏—Ä—É–µ—Ç –Ω–µ–∑–Ω–∞–∫–æ–º—ã–µ, –∞ –∑–Ω–∞–∫–æ–º—ã–µ ‚Äî –ø—Ä–∏–º–µ–Ω–∏—Ç.
    """
    if not filters:
        return {}

    q: dict = {}

    # –≥–æ—Ä–æ–¥ (–ø–æ –Ω–∞–∑–≤–∞–Ω–∏—é/–ø–æ–∏—Å–∫–æ–º)
    city = (filters.get("city") or "").strip()
    if city:
        q["city"] = city          # –≤–æ–∑–º–æ–∂–Ω—ã–π –≤–∞—Ä–∏–∞–Ω—Ç
        q["cityName"] = city      # –≤–æ–∑–º–æ–∂–Ω—ã–π –≤–∞—Ä–∏–∞–Ω—Ç
        q["search"] = city        # —á–∞—Å—Ç–æ –µ—Å—Ç—å –æ–±—â–∏–π —Ç–µ–∫—Å—Ç–æ–≤—ã–π —Ñ–∏–ª—å—Ç—Ä

    # —Ñ–æ—Ä–º–∞—Ç—ã (–Ω–µ—Å–∫–æ–ª—å–∫–æ —á–µ—Ä–µ–∑ –ø–æ–≤—Ç–æ—Ä—è—é—â–∏–µ—Å—è –ø–∞—Ä–∞–º–µ—Ç—Ä—ã)
    fmts = filters.get("formats") or []
    if fmts:
        q["type"] = fmts          # canonical (—É Omniboard field 'type')
        q["format"] = fmts        # –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω–æ–µ –∏–º—è
        q["types"] = fmts
        q["formats"] = fmts

    # –ø–æ–¥—Ä—è–¥—á–∏–∫–∏ (–ø–æ –Ω–∞–∑–≤–∞–Ω–∏—é)
    owners = filters.get("owners") or []
    if owners:
        q["owner"] = owners                 # –≤–æ–∑–º–æ–∂–Ω–æ–µ –∏–º—è
        q["displayOwnerName"] = owners      # –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω–æ–µ –∏–º—è
        # –¥–æ–±–∞–≤–∏–º –≤ –æ–±—â–∏–π search, —á—Ç–æ–±—ã —É–≤–µ–ª–∏—á–∏—Ç—å —à–∞–Ω—Å —Å–µ—Ä–≤–µ—Ä–Ω–æ–π —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏
        q["search"] = (" ".join([q.get("search",""), *owners])).strip()

    # –ø—Ä–æ–∏–∑–≤–æ–ª—å–Ω—ã–µ ¬´—Å—ã—Ä–æ–≤—ã–µ¬ª –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∏–∑ /sync_api –≤–∏–¥–∞ api.cityId=7
    for k, v in (filters.get("api_params") or {}).items():
        q[k] = v

    # –≤—ã–∫–∏–Ω–µ–º –ø—É—Å—Ç—ã–µ
    return {k: v for k, v in q.items() if v not in ("", None, [], {})}

def _normalize_format_token(tok: str) -> str:
    if not tok:
        return tok
    t = str(tok).upper().strip()
    # —á–∞—Å—Ç—ã–µ —Å–∫–ª–µ–π–∫–∏ ‚Üí —Å–æ—Ñ—Ç-–º—ç–ø
    MAP = {
        "MEDIAFACADE": "MEDIA_FACADE",
        "CITYBOARD": "CITY_BOARD",
        "CITYBOARDY": "CITY_BOARD",  # –Ω–∞ –≤—Å—è–∫–∏–π —Å–ª—É—á–∞–π –æ–ø–µ—á–∞—Ç–∫–∏
        "SUPERBOARD": "SUPERSITE",   # –µ—Å–ª–∏ —É –≤–∞—Å —ç—Ç–æ —Å–∏–Ω–æ–Ω–∏–º; —É–±–µ—Ä–∏, –µ—Å–ª–∏ –Ω–µ –Ω—É–∂–Ω–æ
    }
    return MAP.get(t, t)

def _normalize_formats_list(lst) -> list[str]:
    out = []
    for x in (lst or []):
        t = _normalize_format_token(x)
        out.append(t)
    return out

async def _fetch_inventories(
    pages_limit: int | None = None,
    page_size: int = 500,
    total_limit: int | None = None,
    m: types.Message | None = None,
    filters: dict | None = None,          # <--- –ù–û–í–û–ï
) -> list[dict]:
    """
    /api/v1.0/clients/inventories ‚Äî —Ç—è–Ω–µ–º –ø–æ—Å—Ç—Ä–∞–Ω–∏—á–Ω–æ.
    –ü–∞—Ä–∞–º–µ—Ç—Ä—ã:
      - pages_limit: –º–∞–∫—Å–∏–º—É–º —Å—Ç—Ä–∞–Ω–∏—Ü (None = –≤—Å–µ)
      - page_size:   —Ä–∞–∑–º–µ—Ä —Å—Ç—Ä–∞–Ω–∏—Ü—ã
      - total_limit: –æ–±—â–∏–π –ª–∏–º–∏—Ç —ç–ª–µ–º–µ–Ω—Ç–æ–≤ (None = –±–µ–∑ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–π)
      - m:           Telegram message –¥–ª—è –ø—Ä–æ–≥—Ä–µ—Å—Å–∞
      - filters:     { city: str, formats: [..], owners: [..], api_params: {rawKey: rawVal} }
    """
    base = (OBDSP_BASE or "https://proddsp.omniboard360.io").rstrip("/")
    root = f"{base}/api/v1.0/clients/inventories"

    headers = {
        "Authorization": f"Bearer {OBDSP_TOKEN}",
        "Accept": "application/json",
    }

    timeout = aiohttp.ClientTimeout(total=180)
    ssl_param = _make_ssl_param_for_aiohttp()

    # –ø–æ–¥–≥–æ—Ç–æ–≤–∏–º —Å–µ—Ä–≤–µ—Ä–Ω—ã–µ query-–ø–∞—Ä–∞–º–µ—Ç—Ä—ã (–æ–Ω–∏ –±—É–¥—É—Ç –¥–æ–±–∞–≤–ª—è—Ç—å—Å—è –∫ page/size)
    server_q = _build_server_query(filters)

    items: list[dict] = []
    page = 0
    pages_fetched = 0

    async with aiohttp.ClientSession(timeout=timeout) as session:
        while True:
            params = {"page": page, "size": page_size}
            # –¥–æ–±–∞–≤–ª—è–µ–º —Å–µ—Ä–≤–µ—Ä–Ω—ã–µ —Ñ–∏–ª—å—Ç—Ä—ã
            for k, v in server_q.items():
                params[k] = v

            async with session.get(root, headers=headers, params=params, ssl=ssl_param) as resp:
                text = await resp.text()
                if resp.status != 200:
                    raise RuntimeError(f"API {resp.status}: {text[:300]}")

                try:
                    data = await resp.json()
                except Exception:
                    raise RuntimeError(f"–ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å JSON: {text[:500]}")

                page_items = data.get("content") or []
                items.extend(page_items)

                pages_fetched += 1
                page += 1

                # –ª–∏–º–∏—Ç –ø–æ –æ–±—â–µ–º—É –∫–æ–ª–∏—á–µ—Å—Ç–≤—É
                if total_limit is not None and len(items) >= total_limit:
                    items = items[:total_limit]
                    break

                # –ª–∏–º–∏—Ç –ø–æ —Å—Ç—Ä–∞–Ω–∏—Ü–∞–º
                if pages_limit is not None and pages_fetched >= pages_limit:
                    break

                # –ø—Ä–∏–∑–Ω–∞–∫–∏ –æ–∫–æ–Ω—á–∞–Ω–∏—è
                if data.get("last") is True:
                    break
                if data.get("totalPages") is not None and page >= int(data["totalPages"]):
                    break
                if data.get("numberOfElements") == 0:
                    break

                # –ø—Ä–æ–≥—Ä–µ—Å—Å
                if m and (pages_fetched % 5 == 0):
                    try:
                        await m.answer(f"‚Ä¶–∑–∞–≥—Ä—É–∂–µ–Ω–æ —Å—Ç—Ä–∞–Ω–∏—Ü: {pages_fetched}, –≤—Å–µ–≥–æ –ø–æ–∑–∏—Ü–∏–π: {len(items)}")
                    except Exception:
                        pass

    return items

# ---------- helpers for /plan (city/format normalization) ----------

CITY_SYNONYMS = {
    "—Å–ø–±": "—Å–∞–Ω–∫—Ç-–ø–µ—Ç–µ—Ä–±—É—Ä–≥",
    "–ø–∏—Ç–µ—Ä": "—Å–∞–Ω–∫—Ç-–ø–µ—Ç–µ—Ä–±—É—Ä–≥",
    "—Å–∞–Ω–∫—Ç –ø–µ—Ç–µ—Ä–±—É—Ä–≥": "—Å–∞–Ω–∫—Ç-–ø–µ—Ç–µ—Ä–±—É—Ä–≥",
    "–º—Å–∫": "–º–æ—Å–∫–≤–∞",
    "–º–æ—Å–∫–≤–∞": "–ú–æ—Å–∫–≤–∞",    
    "–º–æ—Å–∫–≤–µ": "–ú–æ—Å–∫–≤–∞",
}

def _norm_text(s: str) -> str:
    s = str(s or "").strip().lower()
    s = s.replace("—ë", "–µ")
    # —É–±–∏—Ä–∞–µ–º —Å–ª—É–∂–µ–±–Ω—ã–µ "–≥.", "–≥ ", –ª–∏—à–Ω–∏–µ –∑–∞–ø—è—Ç—ã–µ
    for junk in ["–≥.", "–≥ ", "–≥–æ—Ä–æ–¥ ", ",", " —Ä–∞–π–æ–Ω", " –æ–±–ª.", " –æ–±–ª–∞—Å—Ç—å"]:
        s = s.replace(junk, " ")
    s = " ".join(s.split())
    return CITY_SYNONYMS.get(s, s)

def city_matches(cell: str, target: str) -> bool:
    """–õ–∏–±–µ—Ä–∞–ª—å–Ω–æ–µ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ –≥–æ—Ä–æ–¥–∞: —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ –ø–æ –ø–æ–¥—Å—Ç—Ä–æ–∫–µ –ø–æ—Å–ª–µ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏."""
    a = _norm_text(cell)
    b = _norm_text(target)
    if not a or not b:
        return False
    return (a == b) or (b in a) or (a in b)

def norm_format(s: str) -> str:
    s = str(s or "").strip().upper().replace("-", "_").replace(" ", "_")
    if s in {"MEDIAFACADE"}:
        s = "MEDIA_FACADE"
    if s in {"CITYBOARD", "CITY-BOARD"}:
        s = "CITY_BOARD"
    return s

def load_inventory_df_from_cache() -> "pd.DataFrame|None":
    """
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç DataFrame —ç–∫—Ä–∞–Ω–æ–≤:
      1) –µ—Å–ª–∏ –µ—Å—Ç—å –≥–ª–æ–±–∞–ª—å–Ω—ã–π SCREENS (–ø–æ—Å–ª–µ /sync_api –∏–ª–∏ –∑–∞–≥—Ä—É–∑–∫–∏ CSV/XLSX) ‚Äî –∏—Å–ø–æ–ª—å–∑—É–µ–º –µ–≥–æ,
      2) –∏–Ω–∞—á–µ –ø—Ä–æ–±—É–µ–º –Ω–∞–π—Ç–∏ –ø–æ—Å–ª–µ–¥–Ω–∏–π —Ñ–∞–π–ª –≤ /mnt/data/ (–µ—Å–ª–∏ —Ç—ã —Ç—É–¥–∞ —Å–∫–ª–∞–¥—ã–≤–∞–µ—à—å –∏–º–ø–æ—Ä—Ç),
      3) –∏–Ω–∞—á–µ None.
    """
    global SCREENS
    try:
        import pandas as _pd, os, glob
        if SCREENS is not None and not SCREENS.empty:
            return SCREENS

        # –ø–æ–∏—Å–∫ –ª—é–±–æ–≥–æ –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ CSV/XLSX
        candidates = sorted(
            glob.glob("/mnt/data/*.csv") + glob.glob("/mnt/data/*.xlsx"),
            key=os.path.getmtime, reverse=True
        )
        for path in candidates:
            try:
                if path.lower().endswith(".csv"):
                    df = _pd.read_csv(path)
                else:
                    df = _pd.read_excel(path)
                if not df.empty:
                    return df
            except Exception:
                continue
    except Exception:
        pass
    return None

CITY_SYNONYMS = {
    "—Å–ø–±": "—Å–∞–Ω–∫—Ç-–ø–µ—Ç–µ—Ä–±—É—Ä–≥",
    "—Å–∞–Ω–∫—Ç –ø–µ—Ç–µ—Ä–±—É—Ä–≥": "—Å–∞–Ω–∫—Ç-–ø–µ—Ç–µ—Ä–±—É—Ä–≥",
    "–ø–∏—Ç–µ—Ä": "—Å–∞–Ω–∫—Ç-–ø–µ—Ç–µ—Ä–±—É—Ä–≥",
    "–º–æ—Å–∫–≤–∞": "–ú–æ—Å–∫–≤–∞",    
    "–º–æ—Å–∫–≤–µ": "–ú–æ—Å–∫–≤–∞",
}

def _norm_city(s: str) -> str:
    s = (s or "").strip().lower()
    s = s.replace("—ë", "–µ")
    s = re.sub(r"^\s*–≥\.\s*", "", s)           # —É–±–∏—Ä–∞–µ–º "–≥. "
    s = re.sub(r"[^\w\s-]", " ", s)            # –ø—É–Ω–∫—Ç—É–∞—Ü–∏—é –≤ –ø—Ä–æ–±–µ–ª
    s = re.sub(r"\s+", " ", s).strip()
    s = CITY_SYNONYMS.get(s, s)
    return s

def _city_match(item_city: str, targets: set[str]) -> bool:
    """–õ–æ—è–ª—å–Ω–æ–µ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ: —Ç–æ—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–æ–π —Ñ–æ—Ä–º—ã –ò–õ–ò –ø–æ–¥—Å—Ç—Ä–æ–∫–∞."""
    ic = _norm_city(item_city)
    if ic in targets:
        return True
    # –ø–æ–¥—Å—Ç—Ä–æ—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ (–Ω–∞–ø—Ä–∏–º–µ—Ä, "–∫–∞–∑–∞–Ω—å" –Ω–∞–π–¥—ë—Ç "—Ä–µ—Å–ø—É–±–ª–∏–∫–∞ —Ç–∞—Ç–∞—Ä—Å—Ç–∞–Ω, –∫–∞–∑–∞–Ω—å")
    return any(ic.find(t) != -1 or t.find(ic) != -1 for t in targets)

def _norm_format(s: str) -> str:
    up = (s or "").strip().upper().replace("-", "_").replace(" ", "_")
    # –Ω–µ—Å–∫–æ–ª—å–∫–æ —Å–∏–Ω–æ–Ω–∏–º–æ–≤
    if up in {"MEDIAFACADE"}: up = "MEDIA_FACADE"
    if up in {"CITYBOARD", "CITY_BOARD"}: up = "CITY_BOARD"
    if up in {"SUPER_SITE", "SUPERSITE"}: up = "SUPER_SITE"
    if up in {"BILLBOARD", "BILL_BOARD"}: up = "BILLBOARD"
    return up

def _split_list(val: str) -> list[str]:
    if val is None: return []
    return [x.strip() for x in re.split(r"[;,|]", str(val)) if x.strip()]

def _plan_cities(s: str) -> list[str]:
    raw = re.split(r"[;,]", s or "")
    return [c.strip() for c in raw if c.strip()]

def _city_name(item: dict) -> str:
    c = item.get("city")
    if c:
        return str(c)
    addr = item.get("address") or ""
    return addr.split(",")[0].strip() if addr else "‚Äî"

def _reach_score(item: dict, hours_per_day: int) -> float:
    a = (item.get("audience_per_day") or item.get("audiencePerDay") or 0) or 0
    if a:
        return float(a)
    traffic_h = item.get("traffic_per_hour") or item.get("trafficPerHour")
    vis = item.get("visibility_index") or item.get("visibilityIndex") or 1.0
    if traffic_h:
        return float(traffic_h) * hours_per_day * float(vis)
    vpl = item.get("viewers_per_loop") or item.get("viewersPerLoop")
    lph = item.get("loops_per_hour") or item.get("loopsPerHour")
    if vpl and lph:
        return float(vpl) * float(lph) * hours_per_day
    return 0.0

def _plays_per_day(item: dict, hours_per_day: int, share_in_loop: float) -> float:
    pph = item.get("plays_per_hour") or item.get("playsPerHour")
    if pph:
        return float(pph) * hours_per_day
    loop_s = (item.get("loop_seconds") or item.get("loopSeconds") or 60)
    try:
        loops_per_hour = 3600 / float(loop_s)
    except Exception:
        loops_per_hour = 60
    return loops_per_hour * hours_per_day * float(share_in_loop)

def _impr_per_play(item: dict) -> float:
    ipp = item.get("impressions_per_play") or item.get("impressionsPerPlay")
    if ipp:
        return float(ipp)
    vpl = item.get("viewers_per_loop") or item.get("viewersPerLoop")
    slots = item.get("slots_in_loop") or item.get("slotsInLoop") or 10
    if vpl:
        try:
            return float(vpl) / float(slots)
        except Exception:
            return float(vpl)
    return 1.0

def _price_for_plays(item: dict, plays: float, impressions: float) -> float:
    ppp = item.get("price_per_play") or item.get("pricePerPlay")
    if ppp:
        return float(ppp) * plays
    cpm = item.get("cpm")
    if cpm and impressions:
        return float(cpm) * (impressions / 1000.0)
    ppd = item.get("price_per_day") or item.get("pricePerDay")
    if ppd:
        return float(ppd)   # –∑–∞ –¥–µ–Ω—å; —É–º–Ω–æ–∂–∏–º –ø–æ–∑–∂–µ –Ω–∞ days
    return 0.0

async def _fetch_inventories(session: aiohttp.ClientSession, page_size=500, filters: dict | None=None) -> list[dict]:
    candidates = [
        f"{OBDSP_BASE}/api/v1.0/clients/inventories",
        f"{OBDSP_BASE}/api/v1.0/inventories",
        f"{OBDSP_BASE}/api/v1/inventories",
    ]
    out = []
    for base in candidates:
        page = 0
        while True:
            tried = False
            for ps in ({"page": page, "size": page_size}, {"pageNumber": page+1, "pageSize": page_size}):
                tried = True
                params = {**ps}
                if OBDSP_CLIENT_ID:
                    params["clientId"] = OBDSP_CLIENT_ID
                if filters:
                    params.update(filters)
                async with session.get(base, headers=HEADERS_PLAN, params=params) as r:
                    if r.status == 404:
                        break
                    if r.status >= 300:
                        continue
                    data = await r.json(content_type=None)
                    if isinstance(data, list):
                        content = data
                        last = not bool(content)
                    else:
                        content = data.get("content") or data.get("items") or data.get("data") or []
                        last = bool(data.get("last")) or not bool(content)
                        tp = data.get("totalPages")
                        if isinstance(tp, int):
                            if ("page" in params and page+1 >= tp) or ("pageNumber" in params and params["pageNumber"] >= tp):
                                last = True
                    out.extend(content)
                    if last:
                        return out
            if not tried:
                break
            page += 1
    return out

async def build_plan(
    cities: list[str],
    days: int = 30,
    hours: int = 10,
    share_in_loop: float = 1.0,
    max_screens_per_city: int = 20,
    formats: list[str] | None = None,
    owners: list[str] | None = None,
):
    timeout = aiohttp.ClientTimeout(total=240)
    async with aiohttp.ClientSession(timeout=timeout) as session:
        # 1) –≤—ã—Ç–∞—Å–∫–∏–≤–∞–µ–º –∏–Ω–≤–µ–Ω—Ç–∞—Ä—å
        inv = await fetch_inventories(session, page_size=500)
        # fallback –≤ –∫—ç—à SCREENS, –µ—Å–ª–∏ API –ø—É—Å—Ç–æ
        if not inv:
            try:
                from bot import SCREENS  # –µ—Å–ª–∏ –≤ —Ç–æ–º –∂–µ —Ñ–∞–π–ª–µ ‚Äî –ø—Ä–æ—Å—Ç–æ –∏—Å–ø–æ–ª—å–∑—É–µ–º –≥–ª–æ–±–∞–ª—å–Ω—É—é
                if SCREENS is not None and not SCREENS.empty:
                    inv = SCREENS.to_dict(orient="records")
            except Exception:
                pass

        if not inv:
            return None, None

        # 2) —Ñ–∏–ª—å—Ç—Ä –ø–æ –≥–æ—Ä–æ–¥–∞–º (—É—Å—Ç–æ–π—á–∏–≤–æ)
        target_set = {_norm_city(c) for c in cities}
        inv = [i for i in inv if _city_match(str(i.get("city") or i.get("address") or ""), target_set)]

        # 3) —Ñ–∏–ª—å—Ç—Ä –ø–æ —Ñ–æ—Ä–º–∞—Ç–∞–º/–≤–ª–∞–¥–µ–ª—å—Ü–∞–º (–µ—Å–ª–∏ –∑–∞–¥–∞–Ω—ã)
        if formats:
            fmt_set = { _norm_format(f) for f in formats }
            inv = [i for i in inv if _norm_format(str(i.get("format") or i.get("formatName") or "")) in fmt_set]

        if owners:
            pat = "|".join(re.escape(x) for x in owners)
            inv = [i for i in inv if re.search(pat, str(i.get("owner") or i.get("vendor") or ""), flags=re.I)]

        if not inv:
            return None, None

    # 3) —Ä–∞–Ω–∂–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–æ –≥–æ—Ä–æ–¥–∞–º
    by_city = {}
    for it in filtered:
        by_city.setdefault(_city_name(it), []).append(it)

    picked = []
    for c in cities:
        group = by_city.get(c, [])
        group.sort(key=lambda x: _reach_score(x, hours), reverse=True)
        picked.extend(group[:max_per_city])

    if not picked:
        return None, None

    # 4) –º–µ—Ç—Ä–∏–∫–∏
    rows = []
    for it in picked:
        c = _city_name(it)
        code = it.get("screen_id") or it.get("code") or it.get("uid") or it.get("name") or it.get("id")
        loop_s = (it.get("loop_seconds") or it.get("loopSeconds") or 60)
        pday   = _plays_per_day(it, hours, share_in_loop)
        plays  = pday * days
        ipp    = _impr_per_play(it)
        impr   = plays * ipp
        base_price = _price_for_plays(it, plays, impr)
        # –µ—Å–ª–∏ price_per_day ‚Äî —É–º–Ω–æ–∂–∞–µ–º –Ω–∞ –¥–Ω–∏:
        if (it.get("price_per_play") or it.get("pricePerPlay")):
            budget = base_price
        else:
            budget = base_price * days
        rows.append({
            "City": c,
            "Screen": code,
            "Format": it.get("format") or it.get("formatName") or "",
            "Owner": it.get("owner")  or it.get("vendor") or "",
            "Loop, s": loop_s,
            "Plays/day": round(pday, 1),
            "Plays (period)": int(plays),
            "Impressions": int(impr),
            "Budget": round(budget, 2),
            "Reach score": int(_reach_score(it, hours)),
        })

    df = pd.DataFrame(rows)
    if df.empty:
        return None, None

        # --- 10) –∞–≥—Ä–µ–≥–∞—Ç—ã –ø–æ –≥–æ—Ä–æ–¥–∞–º ---
    id_for_agg = "GID" if "GID" in plan_df.columns else "Screen"

    agg = (plan_df.groupby("City", as_index=False)
                .agg(Screens=(id_for_agg, "nunique"),
                 Plays=("Plays (period)","sum"),
                 OTS_total=("OTS total","sum"),
                 Budget=("Budget","sum"),
                 OTS_avg_play=("OTS avg/play","mean"),          # –ù–û–í–û–ï
                 MinBid_avg_used=("MinBid avg (used)","mean") # –ù–û–í–û–ï
             ))

    # 5) Excel
    buf = io.BytesIO()
    with pd.ExcelWriter(buf, engine="xlsxwriter") as w:
        # Summary
        cols_summary = ["City","Screens","Plays","OTS_total","Budget","OTS_avg_play","MinBid_avg_used"]
        agg[cols_summary].sort_values("OTS_total", ascending=False).to_excel(w, sheet_name="Summary", index=False)
        ws = w.sheets["Summary"]

        # —à–∏—Ä–∏–Ω—ã –∫–æ–ª–æ–Ω–æ–∫
        widths = [18,10,14,14,14,14,16]
        for i, width in enumerate(widths):
            ws.set_column(i, i, width)

        # —Ñ–æ—Ä–º–∞—Ç—ã
        fmt_int   = w.book.add_format({"num_format":"#,##0"})
        fmt_money = w.book.add_format({"num_format":"#,##0"})
        fmt_float = w.book.add_format({"num_format":"#,##0.00"})

        # –∫–æ–ª–æ–Ω–∫–∏ —Å —á–∏—Å–ª–∞–º–∏
        # Screens (1), Plays (2), OTS_total (3) ‚Äî —Ü–µ–ª—ã–µ
        ws.set_column(1, 3, None, fmt_int)
        # Budget (4) ‚Äî –¥–µ–Ω—å–≥–∏
        ws.set_column(4, 4, None, fmt_money)
        # OTS_avg_play (5), MinBid_avg_used (6) ‚Äî –≤–µ—â–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ/–¥–µ–Ω—å–≥–∏
        ws.set_column(5, 5, None, fmt_float)
        ws.set_column(6, 6, None, fmt_money)

    buf.seek(0)
    meta = {"rows": len(df), "cities": len(agg)}
    return buf, meta

# ==== PLAN inventory access (cache + API fallback) ====
import os, aiohttp, re, pandas as pd

# –±–µ—Ä—ë–º —Ç–æ, —á—Ç–æ —É–∂–µ –º–æ–∂–µ—Ç –±—ã—Ç—å –≤ —Ñ–∞–π–ª–µ (–≥–ª–æ–±–∞–ª—å —É —Ç–µ–±—è –µ—Å—Ç—å –≤ –±–æ—Ç–µ)
try:
    SCREENS  # noqa
except NameError:
    SCREENS = None  # –µ—Å–ª–∏ –≤—ã—à–µ –µ—â—ë –Ω–µ –æ–±—ä—è–≤–ª–µ–Ω–æ ‚Äî —Å–æ–∑–¥–∞–¥–∏–º


# –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è —Ñ–æ—Ä–º–∞—Ç–æ–≤ (—Å–∏–Ω–æ–Ω–∏–º—ã)
def _norm_formats(items):
    out = []
    for it in (items or []):
        up = str(it).strip().upper().replace(" ", "_").replace("-", "_")
        if up in {"MEDIAFACADE"}: up = "MEDIA_FACADE"
        if up in {"CITYBOARD", "CITY_BOARD"}: up = "CITY_BOARD"
        if up in {"SUPER_SITE", "SUPERSITE"}: up = "SUPER_SITE"
        if up: out.append(up)
    return out

def _str_contains_any_ci(series: pd.Series, needles: list[str]) -> pd.Series:
    if not needles:
        return pd.Series([True] * len(series), index=series.index)
    pat = "|".join(re.escape(x) for x in needles)
    return series.astype(str).str.contains(pat, case=False, na=False)

async def fetch_inventories(session: aiohttp.ClientSession, page_size=500, filters: dict | None=None) -> list[dict]:
    """
    –£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π —Å–±–æ—Ä –∏–Ω–≤–µ–Ω—Ç–∞—Ä—è —Å –ø–∞–≥–∏–Ω–∞—Ü–∏–µ–π.
    –ü—Ä–æ–±—É–µ–º –Ω–µ—Å–∫–æ–ª—å–∫–æ –ø—É—Ç–µ–π, –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º page/size –∏ pageNumber/pageSize.
    """
    async def _try(url, params):
        async with session.get(url, headers=HEADERS_PLAN, params=params) as r:
            txt = await r.text()
            if r.status >= 300:
                return r.status, None
            try:
                return r.status, await r.json(content_type=None)
            except Exception:
                import json as _json
                try:
                    return r.status, _json.loads(txt)
                except Exception:
                    return r.status, None

    candidates = [
        f"{BASE_URL}/api/v1.0/clients/inventories",
        f"{BASE_URL}/api/v1.0/inventories",
        f"{BASE_URL}/api/v1/inventories",
    ]
    out = []
    for base in candidates:
        page = 0
        got = False
        while True:
            for ps in ({"page": page, "size": page_size}, {"pageNumber": page+1, "pageSize": page_size}):
                params = ps.copy()
                if CLIENT_ID:
                    params["clientId"] = CLIENT_ID
                if filters:
                    params.update(filters)
                status, data = await _try(base, params)
                if not data or status and status >= 300:
                    continue
                if isinstance(data, list):
                    content = data
                    last_flag = not bool(content)
                else:
                    content = (data.get("content") or data.get("items") or data.get("data") or []) if isinstance(data, dict) else []
                    last_flag = bool(getattr(data, "get", lambda *_: False)("last")) or not bool(content)
                    if isinstance(data, dict) and isinstance(data.get("totalPages"), int):
                        tp = data["totalPages"]
                        if ("page" in params and page + 1 >= tp) or ("pageNumber" in params and params["pageNumber"] >= tp):
                            last_flag = True
                if content:
                    out.extend(content); got = True
                if last_flag:
                    break
            if not got:
                break
            page += 1
        if out:
            break
    return out

async def get_inventories(filters: dict | None = None, use_cache: bool = True) -> list[dict]:
    """
    1) –ï—Å–ª–∏ –µ—Å—Ç—å –∫—ç—à SCREENS (DataFrame) ‚Äî –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –µ–≥–æ —Å—Ç—Ä–æ–∫–∏ –∫–∞–∫ dict.
    2) –ò–Ω–∞—á–µ –∏–¥—ë–º –≤ API.
    –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç —Ñ–∏–ª—å—Ç—Ä—ã: city, format (–∏–ª–∏ formats).
    """
    fmt_list = _norm_formats(filters.get("formats") if filters else [])
    city     = (filters.get("city") or "").strip() if filters else ""

    # 1) –ö–≠–®
    global SCREENS
    if use_cache and isinstance(SCREENS, pd.DataFrame) and not SCREENS.empty:
        df = SCREENS.copy()
        # —Ñ–∏–ª—å—Ç—Ä –ø–æ –≥–æ—Ä–æ–¥—É (—Å—Ç—Ä–æ–≥–æ–µ —Ä–∞–≤–µ–Ω—Å—Ç–≤–æ –±–µ–∑ —Ä–µ–≥–∏—Å—Ç—Ä–∞)
        if city and "city" in df.columns:
            df = df[df["city"].astype(str).str.strip().str.lower() == city.lower()]
        # —Ñ–∏–ª—å—Ç—Ä –ø–æ —Ñ–æ—Ä–º–∞—Ç—É
        if fmt_list and "format" in df.columns:
            df["__fmt"] = df["format"].astype(str).str.upper().str.replace(" ", "_").str.replace("-", "_")
            df = df[df["__fmt"].isin(set(fmt_list))]
            df = df.drop(columns=["__fmt"], errors="ignore")
        return df.to_dict("records")

    # 2) API
    timeout = aiohttp.ClientTimeout(total=240)
    async with aiohttp.ClientSession(timeout=timeout) as session:
        # –ø—Ä–æ–∫–∏–Ω–µ–º –ø—Ä–æ—Å—Ç—ã–µ —Ñ–∏–ª—å—Ç—Ä—ã
        api_filters = {}
        if city:
            api_filters["city"] = city
        if fmt_list:
            api_filters["format"] = ",".join(fmt_list)
        return await fetch_inventories(session, page_size=500, filters=api_filters)

# ================== helpers for /plan ==================

import re
import numpy as np
import pandas as pd
from aiogram.filters import Command
from aiogram import types

# --- helpers –¥–ª—è –±—é–¥–∂–µ—Ç–∞ –∏ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏ ---
def _parse_budget(v: str | float | int | None) -> float | None:
    if v is None:
        return None
    if isinstance(v, (int, float)):
        return float(v)
    s = str(v).strip().lower().replace(" ", "")
    try:
        if s.endswith("m"):
            return float(s[:-1]) * 1_000_000
        if s.endswith("k"):
            return float(s[:-1]) * 1_000
        return float(s)
    except Exception:
        return None

def _safe_float(x, default=0.0):
    try:
        if x is None: return default
        f = float(x)
        if f != f:   # NaN
            return default
        return f
    except Exception:
        return default


def _norm_text(x: str) -> str:
    if x is None:
        return ""
    return str(x).strip().lower().replace("—ë", "–µ")

def norm_format(x: str) -> str:
    if x is None:
        return ""
    up = str(x).strip().upper().replace(" ", "_")
    if up in {"MEDIAFACADE", "MEDIA-FACADE"}:
        up = "MEDIA_FACADE"
    if up in {"CITYBOARD", "CITY-BOARD"}:
        up = "CITY_BOARD"
    return up

def _num_to_float(x):
    """ '50 000 ‚ÇΩ', '2,5k', '1.2m' -> float (NaN –¥–ª—è –ø—É—Å—Ç—ã—Ö/–Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã—Ö) """
    if x is None or (isinstance(x, float) and np.isnan(x)):
        return np.nan
    s = str(x).strip()
    if not s:
        return np.nan
    s = s.replace("\u00A0", " ").replace(" ", "")
    s = s.replace("‚ÇΩ", "").replace("—Ä—É–±", "").replace("—Ä.", "").replace("$", "").replace("‚Ç¨", "")
    s = s.replace(",", ".")
    mult = 1.0
    if s.lower().endswith("k"):
        mult, s = 1_000.0, s[:-1]
    elif s.lower().endswith("m"):
        mult, s = 1_000_000.0, s[:-1]
    s = re.sub(r"[^0-9\.]+", "", s)
    if s.count(".") > 1 or s == "":
        return np.nan
    try:
        v = float(s) * mult
        return np.nan if v <= 0 else v
    except:
        return np.nan

def parse_kv_for_plan(text: str) -> dict:
    # –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º "key=val key=val", –∑–∞–ø—è—Ç—ã–µ, —Ç–æ—á–∫–∏ —Å –∑–∞–ø—è—Ç–æ–π –∏ –ø–µ—Ä–µ–Ω–æ—Å—ã
    parts = re.split(r"[,\n;]\s*|\s+(?=\w+=)", (text or "").strip())
    kv = {}
    for part in parts:
        if "=" in part:
            k, v = part.split("=", 1)
            kv[k.strip().lower()] = v.strip()
    return kv

def normalize_cities_arg(s: str) -> list[str]:
    raw = re.split(r"[;,]", s or "")
    return [c.strip() for c in raw if c.strip()]

def plays_per_day_row(row: pd.Series, hours: int) -> float:
    # 1) –≥–æ—Ç–æ–≤–æ–µ plays_per_hour
    for k in ("plays_per_hour", "playsPerHour"):
        if k in row and pd.notna(row[k]):
            try:
                return float(row[k]) * hours
            except:
                pass
    # 2) –∏–∑ –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –ª—É–ø–∞
    loop_s = 60.0
    for k in ("loop_seconds", "loopSeconds"):
        if k in row and pd.notna(row[k]):
            try:
                loop_s = max(1.0, float(row[k]))
                break
            except:
                pass
    loops_per_hour = 3600.0 / loop_s
    # —Å–ª–æ—Ç–æ–≤ –≤ –ª—É–ø–µ (–µ—Å–ª–∏ –µ—Å—Ç—å) –º–æ–∂–µ—Ç –≤–ª–∏—è—Ç—å –Ω–∞ —à–∞–Ω—Å –ø–æ–∫–∞–∑–∞, –Ω–æ –∑–¥–µ—Å—å –º—ã —Å—á–∏—Ç–∞–µ–º ¬´–≤—ã—Ö–æ–¥—ã¬ª –∫–∞–∫ –æ—Ç–¥–µ–ª—å–Ω—ã–µ –ø–æ—è–≤–ª–µ–Ω–∏—è:
    # –¥–ª—è —É–ø—Ä–æ—â–µ–Ω–∏—è –ø—Ä–∏–Ω–∏–º–∞–µ–º 1 –≤—ã—Ö–æ–¥ –Ω–∞ 1 —Å–ª–æ—Ç —Ü–∏–∫–ª–∞; –µ—Å–ª–∏ —É –≤–∞—Å –µ—Å—Ç—å —Ñ–∞–∫—Ç–∏—á–µ—Å–∫–∏–π slots_in_loop ‚Äî —É–º–Ω–æ–∂—å—Ç–µ –∑–¥–µ—Å—å.
    slots = None
    for k in ("slots_in_loop", "slotsInLoop"):
        if k in row and pd.notna(row[k]):
            try:
                slots = max(1, int(row[k]))
            except:
                pass
    if slots:
        return loops_per_hour * hours * float(slots)
    return loops_per_hour * hours

def impressions_per_play_row(row: pd.Series) -> float:
    # –ø—Ä–∏ –Ω–∞–ª–∏—á–∏–∏ –ø–æ–ª—è ‚Äî –∏—Å–ø–æ–ª—å–∑—É–µ–º –µ–≥–æ
    for k in ("impressions_per_play", "impressionsPerPlay"):
        if k in row and pd.notna(row[k]):
            try:
                return float(row[k])
            except:
                pass
    # fallback –∏–∑ viewers_per_loop / slots_in_loop
    vpl = None
    for k in ("viewers_per_loop", "viewersPerLoop"):
        if k in row and pd.notna(row[k]):
            vpl = row[k]; break
    slots = 10
    for k in ("slots_in_loop", "slotsInLoop"):
        if k in row and pd.notna(row[k]):
            try:
                slots = max(1, int(row[k])); break
            except:
                pass
    if vpl:
        try:
            return float(vpl) / float(slots)
        except:
            return float(vpl)
    return 1.0

def fill_min_bid_hierarchy(df: pd.DataFrame) -> pd.DataFrame:
    """
    –î–æ–±–∞–≤–ª—è–µ—Ç:
      - minBid_raw   : —Ä–∞—Å–ø–∞—Ä—Å–µ–Ω–Ω—ã–π minBid/price_per_play
      - minBid_used  : –∑–∞–ø–æ–ª–Ω–µ–Ω–æ –ø–æ –∏–µ—Ä–∞—Ä—Ö–∏–∏ (city,format,owner) ‚Üí (format,owner) ‚Üí (format) ‚Üí global
      - minBid_source: –∏—Å—Ç–æ—á–Ω–∏–∫ (raw|avg(...))
    """
    df = df.copy()
    for col in ("city", "format", "owner"):
        if col not in df.columns:
            df[col] = ""

    # —Å–æ–±–µ—Ä—ë–º –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤ —Ü–µ–Ω—ã ¬´–∑–∞ –≤—ã—Ö–æ–¥¬ª
    cands = []
    for k in ("minBid", "min_bid", "price_per_play", "pricePerPlay"):
        if k in df.columns:
            cands.append(df[k].map(_num_to_float))
    if cands:
        minBid_raw = pd.concat(cands, axis=1).bfill(axis=1).iloc[:, 0]
    else:
        minBid_raw = pd.Series(np.nan, index=df.index, dtype="float")
    df["minBid_raw"] = minBid_raw

    # –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –∫–ª—é—á–µ–π
    df["city_norm"]   = df["city"].astype(str).map(_norm_text)
    df["format_norm"] = df["format"].astype(str).map(norm_format)
    df["owner_norm"]  = df["owner"].astype(str).map(lambda x: str(x).strip().lower() if x is not None else "")

    # –º–µ–¥–∏–∞–Ω—ã –ø–æ –≥—Ä—É–ø–ø–∞–º (—É—Å—Ç–æ–π—á–∏–≤–µ–µ —Å—Ä–µ–¥–Ω–µ–≥–æ)
    def _median(s: pd.Series):
        s = s.dropna()
        return np.nan if s.empty else float(s.median())

    g_cfo = (df.groupby(["city_norm", "format_norm", "owner_norm"], dropna=False)["minBid_raw"].apply(_median))
    g_fo  = (df.groupby(["format_norm", "owner_norm"], dropna=False)["minBid_raw"].apply(_median))
    g_f   = (df.groupby(["format_norm"], dropna=False)["minBid_raw"].apply(_median))
    global_med = _median(df["minBid_raw"])

    key_cfo = list(zip(df["city_norm"], df["format_norm"], df["owner_norm"]))
    key_fo  = list(zip(df["format_norm"], df["owner_norm"]))
    key_f   = df["format_norm"]

    used = df["minBid_raw"].copy()
    src  = pd.Series(np.where(used.notna(), "raw", ""), index=df.index, dtype=object)

    m = used.isna()
    if m.any():
        used.loc[m] = pd.Series(key_cfo, index=df.index)[m].map(g_cfo)
        src.loc[m & used.notna()] = "avg(city,format,owner)"

    m = used.isna()
    if m.any():
        used.loc[m] = pd.Series(key_fo, index=df.index)[m].map(g_fo)
        src.loc[m & used.notna()] = "avg(format,owner)"

    m = used.isna()
    if m.any():
        used.loc[m] = key_f[m].map(g_f)
        src.loc[m & used.notna()] = "avg(format)"

    m = used.isna()
    if m.any():
        used.loc[m] = global_med
        src.loc[m]  = "avg(global)"

    df["minBid_used"]   = used.astype(float)
    df["minBid_source"] = src.astype(str)
    return df

def _load_cached_inventory_df() -> pd.DataFrame | None:
    """–ü—Ä–æ–±—É–µ–º –≤–∑—è—Ç—å –∏–∑ SCREENS, –∏–Ω–∞—á–µ –∏–∑ –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω–æ–≥–æ CSV/XLSX (–≤–∞—à–∞ —Ñ—É–Ω–∫—Ü–∏—è, –µ—Å–ª–∏ –µ—Å—Ç—å)."""
    try:
        if "SCREENS" in globals() and SCREENS is not None and not SCREENS.empty:
            return SCREENS.copy()
    except:
        pass
    try:
        # –µ—Å–ª–∏ —É –≤–∞—Å –µ—Å—Ç—å —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è: load_inventory_df_from_cache()
        return load_inventory_df_from_cache()
    except:
        return None

import numpy as np
import pandas as pd
import re

def _is_pos_num(x) -> bool:
    try:
        return float(x) > 0
    except:
        return False

def _pick_series(df: pd.DataFrame, name: str):
    # –±–µ–∑–æ–ø–∞—Å–Ω–æ –≤–µ—Ä–Ω—É—Ç—å —Å–µ—Ä–∏—é –∏–ª–∏ –ø—É—Å—Ç—É—é
    return df[name] if name in df.columns else pd.Series([np.nan] * len(df), index=df.index)

def _format_family(fmt: str) -> str:
    f = (fmt or "").strip().upper().replace(" ", "_")
    # –Ω–æ—Ä–º–∞–ª–∏–∑—É–µ–º –ø–æ–ø—É–ª—è—Ä–Ω—ã–µ —Å–∏–Ω–æ–Ω–∏–º—ã
    if f in {"MEDIAFACADE", "MEDIA-FACADE"}: f = "MEDIA_FACADE"
    if f in {"CITYBOARD", "CITY-BOARD"}:     f = "CITY_BOARD"
    if f in {"SUPERSITE", "SUPER_SITE"}:     f = "SUPERSITE"
    if f in {"CITYFORMAT", "CITY_FORMAT", "CITYLIGHT", "CITY_LIGHT"}: f = "CITY_FORMAT"
    return f or "OTHER"

def _ots_baseline_scale(fmt_norm: str) -> float:
    # –º–∞—Å—à—Ç–∞–± –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ –±–∏–ª–±–æ—Ä–¥–∞ –≤ –≥–æ—Ä–æ–¥–µ
    fam = _format_family(fmt_norm)
    if fam == "CITY_BOARD":   return 0.5
    if fam == "CITY_FORMAT":  return 0.25
    if fam == "SUPERSITE":    return 1.2
    if fam == "MEDIA_FACADE": return 4.0
    if fam == "BILLBOARD":    return 1.0
    return 0.125  # OTHER

def _city_size_index(df: pd.DataFrame) -> pd.Series:
    """
    –ü—Ä–∏–±–ª–∏–∂–∞–µ–º ¬´—Ä–∞–∑–º–µ—Ä –≥–æ—Ä–æ–¥–∞¬ª –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ–º —ç–∫—Ä–∞–Ω–æ–≤ –≤ –∫—ç—à–µ.
    –ï—Å–ª–∏ –µ—Å—Ç—å –∫–æ–ª–æ–Ω–∫–∞ city_pop ‚Äî –∏—Å–ø–æ–ª—å–∑—É–µ–º –µ—ë.
    """
    if "city_pop" in df.columns:
        return (df.groupby("city", as_index=True)["city_pop"].first()
                  .reindex(df["city"]).reset_index(drop=True))
    counts = df.groupby("city", as_index=False).size().rename(columns={"size": "screens_in_city"})
    return df.merge(counts, on="city", how="left")["screens_in_city"].fillna(0)

def fill_ots_hierarchy(df: pd.DataFrame) -> pd.DataFrame:
    """
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç df —Å –∫–æ–ª–æ–Ω–∫–∞–º–∏:
      - ots_used: float ‚Äî —É—Å—Ä–µ–¥–Ω—ë–Ω–Ω—ã–π OTS –≤ –¥–µ–Ω—å (–∏–ª–∏ —Å–æ–ø–æ—Å—Ç–∞–≤–∏–º–∞—è –º–µ—Ç—Ä–∏–∫–∞)
      - ots_used_source: —Å—Ç—Ä–æ–∫–∞ ‚Äî –∏–∑ –∫–∞–∫–æ–≥–æ –ø–æ–ª—è –≤–∑—è—Ç–æ
    –ò–µ—Ä–∞—Ä—Ö–∏—è:
      1) ots_used (–µ—Å–ª–∏ —É–∂–µ –µ—Å—Ç—å)
      2) ots / OTS / ots_per_day / audience_per_day
      3) viewers_per_loop * loops_per_hour
      4) traffic_per_hour * visibility_index (–µ—Å–ª–∏ –µ—Å—Ç—å)
    –¢–∞–∫–∂–µ —Å–æ–∑–¥–∞—ë—Ç 'format_norm', –µ—Å–ª–∏ –µ—ë –Ω–µ –±—ã–ª–æ (–±–µ—Ä—ë—Ç _fmt_norm –∏–ª–∏ –Ω–æ—Ä–º–∞–ª–∏–∑—É–µ—Ç format).
    """
    d = df.copy().reset_index(drop=True)

    # format_norm ‚Äî –ø—Ä–∏–≤–æ–¥–∏–º –∫ –∫–∞–Ω–æ–Ω—É, –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
    if "format_norm" not in d.columns:
        if "_fmt_norm" in d.columns:
            d["format_norm"] = d["_fmt_norm"]
        else:
            # –Ω—É–∂–Ω–∞ —Ñ—É–Ω–∫—Ü–∏—è norm_format –∏–∑ —Ç–≤–æ–µ–≥–æ –∫–æ–¥–∞
            if "format" in d.columns:
                d["format_norm"] = d["format"].astype(str).map(norm_format)
            else:
                d["format_norm"] = ""

    def num(col):
        return pd.to_numeric(d.get(col), errors="coerce") if col in d.columns else pd.Series(np.nan, index=d.index)

    # –ë–∞–∑–æ–≤—ã–µ –∫–∞–Ω–¥–∏–¥–∞—Ç—ã
    c_ots_used   = num("ots_used")
    c_ots        = num("ots")
    c_OTS        = num("OTS")
    c_ots_p_day  = num("ots_per_day")
    c_aud_day    = num("audience_per_day")

    # –í—ã—á–∏—Å–ª–∏–º –ø—Ä–æ–∏–∑–≤–æ–¥–Ω—ã–µ –∫–∞–Ω–¥–∏–¥–∞—Ç—ã (–≤–µ–∫—Ç–æ—Ä–Ω–æ)
    vpl = num("viewers_per_loop")
    if vpl.isna().all() and "viewersPerLoop" in d.columns:
        vpl = num("viewersPerLoop")
    lph = num("loops_per_hour")
    if lph.isna().all() and "loopsPerHour" in d.columns:
        lph = num("loopsPerHour")
    prod_vpl_lph = vpl * lph

    tph = num("traffic_per_hour")
    if tph.isna().all() and "trafficPerHour" in d.columns:
        tph = num("trafficPerHour")
    vis = num("visibility_index")
    if vis.isna().all() and "visibilityIndex" in d.columns:
        vis = num("visibilityIndex")
    prod_tph_vis = tph * vis

    # –û–±—ä–µ–¥–∏–Ω–∏–º –ø–æ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç—É
    used = pd.Series(np.nan, index=d.index, dtype="float64")
    src  = pd.Series("",     index=d.index, dtype="object")

    candidates = [
        ("ots_used",           c_ots_used),
        ("ots",                c_ots),
        ("OTS",                c_OTS),
        ("ots_per_day",        c_ots_p_day),
        ("audience_per_day",   c_aud_day),
        ("viewers_per_loop*loops_per_hour", prod_vpl_lph),
        ("traffic_per_hour*visibility_index", prod_tph_vis),
    ]

    for name, series in candidates:
        mask = used.isna() & series.notna() & np.isfinite(series) & (series > 0)
        used = used.where(~mask, series)
        src  = src.where(~mask, name)

    d["ots_used"]        = used.fillna(0.0).astype(float)
    d["ots_used_source"] = src.where(src != "", "na")
    return d


@dp.message(Command("plan"))
async def cmd_plan(m: types.Message, _call_args: dict | None = None):
    """
    /plan –≥–æ—Ä–æ–¥–∞=–ö–∞–∑–∞–Ω—å;–û—Ä–µ–Ω–±—É—Ä–≥ [format=BILLBOARD,MEDIA_FACADE] [days=30] [hours=10]
         [max_per_city=20] [max_total=120] [budget=2.5m] [mode=even|top] [rank=ots|reach]
    –ò—Å—Ç–æ—á–Ω–∏–∫: –ª–æ–∫–∞–ª—å–Ω—ã–π –∫—ç—à (CSV/XLSX –∏–ª–∏ /sync_api —Ä–∞–Ω–µ–µ).
    """
    import re, io
    import pandas as pd
    import numpy as np

    # ===== 0) BYPASS: –ø—Ä—è–º–æ–π –≤—ã–∑–æ–≤ –∏–∑ /ask =====
    if _call_args:
        try:
            return await _plan_core(
                m,
                cities=_call_args.get("cities") or [],
                days=int(_call_args.get("days") or 7),
                hours=int(_call_args.get("hours") or 12),
                formats_req=_call_args.get("formats_req") or [],
                max_per_city=_call_args.get("max_per_city"),
                max_total=_call_args.get("max_total"),
                budget_total=_call_args.get("budget_total"),
                mode=_call_args.get("mode") or "even",
                rank=_call_args.get("rank") or "ots",
            )
        except Exception as e:
            await m.answer(f"–ü–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –Ω–µ —É–¥–∞–ª–æ—Å—å (call_args): {e}")
            return

    # ===== 1) –æ–±—ã—á–Ω—ã–π —Ä–∞–∑–±–æ—Ä key=value –∏–∑ —Ç–µ–∫—Å—Ç–∞ (/plan –≤—Ä—É—á–Ω—É—é) =====
    def parse_kv(text: str) -> dict:
        parts = re.split(r"[,\n;]\s*|\s+(?=\w+=)", (text or "").strip())
        kv = {}
        for p in parts:
            if "=" in p:
                k, v = p.split("=", 1)
                kv[k.strip().lower()] = v.strip()
        return kv

    def normalize_cities_arg(s: str) -> list[str]:
        raw = re.split(r"[;,]", s or "")
        return [c.strip() for c in raw if c.strip()]

    def _to_int(val, default=None):
        try:
            if val is None: return default
            return int(float(val))
        except Exception:
            return default

    def _parse_budget(v) -> float | None:
        if v is None: return None
        if isinstance(v, (int, float)): return float(v)
        s = str(v).strip().lower().replace(" ", "")
        try:
            if s.endswith("m"): return float(s[:-1]) * 1_000_000
            if s.endswith("k"): return float(s[:-1]) * 1_000
            return float(s)
        except Exception:
            return None

    kv = parse_kv(m.text or "")
    cities = normalize_cities_arg(kv.get("–≥–æ—Ä–æ–¥–∞", kv.get("cities", "")))
    if not cities:
        await m.answer("–£–∫–∞–∂–∏ –≥–æ—Ä–æ–¥–∞: `/plan –≥–æ—Ä–æ–¥–∞=–û—Ä–µ–Ω–±—É—Ä–≥;–ï–∫–∞—Ç–µ—Ä–∏–Ω–±—É—Ä–≥;–°–ü–±;–í–µ–ª–∏–∫–∏–π –ù–æ–≤–≥–æ—Ä–æ–¥`", parse_mode="Markdown")
        return

    days  = _to_int(kv.get("–¥–Ω–µ–π",  kv.get("days", 30)), 30)
    hours = _to_int(kv.get("—á–∞—Å—ã", kv.get("hours", 10)), 10)

    formats_req = []
    fraw = kv.get("format", kv.get("formats", kv.get("—Ñ–æ—Ä–º–∞—Ç", "")))
    if fraw:
        for x in re.split(r"[;,]", fraw):
            x = x.strip()
            if x:
                formats_req.append(norm_format(x))

    mode = (kv.get("mode") or kv.get("strategy") or "").strip().lower() or "even"
    rank = (kv.get("rank") or "ots").strip().lower()

    max_per_city = _to_int(kv.get("–º–∞–∫—Å_—ç–∫—Ä–∞–Ω–æ–≤_–≤_–≥–æ—Ä–æ–¥–µ", kv.get("max_per_city")), None)
    max_total    = _to_int(kv.get("max_total", kv.get("–∫–æ–ª–∏—á–µ—Å—Ç–≤–æ")), None)
    budget_total = _parse_budget(kv.get("budget"))

    # –ø—Ä–∞–≤–∏–ª–æ –∫–∞–∫ —Ä–∞–Ω—å—à–µ: –Ω—É–∂–Ω–æ –ª–∏–±–æ –±—é–¥–∂–µ—Ç, –ª–∏–±–æ –ª–∏–º–∏—Ç(—ã)
    if budget_total is None and max_per_city is None and max_total is None:
        await m.answer(
            "–ù—É–∂–Ω–æ —É–∫–∞–∑–∞—Ç—å –±—é–¥–∂–µ—Ç –∏–ª–∏ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –ø–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤—É —ç–∫—Ä–∞–Ω–æ–≤.\n\n"
            "–ü—Ä–∏–º–µ—Ä—ã:\n"
            "‚Ä¢ /plan –≥–æ—Ä–æ–¥–∞=–ú–æ—Å–∫–≤–∞;–°–ü–± budget=2.5m\n"
            "‚Ä¢ /plan –≥–æ—Ä–æ–¥–∞=–ï–∫–∞—Ç–µ—Ä–∏–Ω–±—É—Ä–≥ max_per_city=30\n"
            "‚Ä¢ /plan –≥–æ—Ä–æ–¥–∞=–ö–∞–∑–∞–Ω—å max_total=120"
        )
        return

    # –∏ –∑–∞–ø—É—Å–∫–∞–µ–º –æ–±—â–µ–µ —è–¥—Ä–æ
    await _plan_core(
        m,
        cities=cities, days=days, hours=hours,
        formats_req=formats_req,
        max_per_city=max_per_city, max_total=max_total, budget_total=budget_total,
        mode=mode, rank=rank
    )

# ---------------- core runner for planning (no message mutation) --------------
async def _plan_core(
    m: types.Message,
    *,
    cities: list[str],
    days: int,
    hours: int,
    formats_req: list[str] | None = None,
    max_per_city: int | None = None,
    max_total: int | None = None,
    budget_total: float | None = None,
    mode: str = "even",          # even | top
    rank: str = "ots",           # ots | reach (–¥–ª—è mode=top)
):
    """
    –û–±—â–∏–π –∏—Å–ø–æ–ª–Ω–∏—Ç–µ–ª—å –ø–ª–∞–Ω–∞. –ù–ò–ß–ï–ì–û –Ω–µ —á–∏—Ç–∞–µ—Ç –∏–∑ m.text ‚Äî —Ç–æ–ª—å–∫–æ –ø–µ—Ä–µ–¥–∞–Ω–Ω—ã–µ –∞—Ä–≥—É–º–µ–Ω—Ç—ã.
    –¢—Ä–µ–±—É–µ–º—ã–µ –≤–Ω–µ—à–Ω–∏–µ —Ö–µ–ª–ø–µ—Ä—ã (–¥–æ–ª–∂–Ω—ã —Å—É—â–µ—Å—Ç–≤–æ–≤–∞—Ç—å –≤ –º–æ–¥—É–ª–µ):
      - _load_cached_inventory_df()
      - _norm_text(s: str) -> str
      - norm_format(s: str) -> str
      - fill_min_bid_hierarchy(df) -> df (+ minBid_used, minBid_source)
      - fill_ots_hierarchy(df)     -> df (+ ots_used, ots_used_source)
      - –æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ: spread_select(df, n, random_start=False, seed=None) –¥–ª—è even
    """
    import io
    import pandas as pd
    import numpy as np

    formats_req = (formats_req or [])

    # ---------- —Å—Ç–∞—Ç—É—Å–Ω–∞—è —Å—Ç—Ä–æ–∫–∞ ----------
    lims = []
    if max_per_city is not None: lims.append(f"max_per_city={max_per_city}")
    if max_total    is not None: lims.append(f"max_total={max_total}")
    if budget_total is not None: lims.append(f"budget‚âà{int(budget_total):,} ‚ÇΩ".replace(",", " "))
    lims_tag = (" [" + ", ".join(lims) + "]") if lims else ""
    ftag = f" [format={','.join(formats_req)}]" if formats_req else ""
    await m.answer(f"–°—á–∏—Ç–∞—é –ø–ª–∞–Ω –Ω–∞ {days} –¥–Ω, {hours} —á/–¥, mode={mode}, rank={rank}{ftag}{lims_tag}")

    # ---------- 1) –∑–∞–≥—Ä—É–∑–∫–∞ –∫—ç—à–∞ ----------
    df = _load_cached_inventory_df()
    if df is None or df.empty:
        await m.answer("–ù–µ—Ç –ª–æ–∫–∞–ª—å–Ω–æ–≥–æ –∫—ç—à–∞ —ç–∫—Ä–∞–Ω–æ–≤. –ó–∞–≥—Ä—É–∑–∏—Ç–µ CSV/XLSX.")
        return
    df = df.copy()

    # –±–∞–∑–æ–≤—ã–µ –∫–æ–ª–æ–Ω–∫–∏
    if "city" not in df.columns:
        if "address" in df.columns:
            df["city"] = df["address"].astype(str).str.split(",").str[0]
        else:
            df["city"] = ""
    if "format" not in df.columns:
        cand = [c for c in df.columns if str(c).lower() in {"formatname","format_type","format_type_name"}]
        df["format"] = df[cand[0]] if cand else ""

    # –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏
    df["_city_norm"] = df["city"].astype(str).map(_norm_text)
    df["_fmt_norm"]  = df["format"].astype(str).map(norm_format)

    # ---------- 2) —Ñ–∏–ª—å—Ç—Ä –ø–æ –≥–æ—Ä–æ–¥–∞–º/—Ñ–æ—Ä–º–∞—Ç–∞–º ----------
    import numpy as _np
    mask_city = _np.zeros(len(df), dtype=bool)
    for c in cities:
        c_norm = _norm_text(c)
        mask_city |= df["_city_norm"].apply(lambda x: (x == c_norm) or (c_norm in x) or (x in c_norm))
    filtered = df[mask_city].copy()

    if formats_req:
        filtered = filtered[filtered["_fmt_norm"].isin(set(formats_req))].copy()

    if filtered.empty:
        await m.answer("–ü–æ —É–∫–∞–∑–∞–Ω–Ω—ã–º –≥–æ—Ä–æ–¥–∞–º/—Ñ–æ—Ä–º–∞—Ç–∞–º —ç–∫—Ä–∞–Ω—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã.")
        return

    # –æ–±–µ–∑–æ–ø–∞—Å–∏–º –∏–Ω–¥–µ–∫—Å –ø–µ—Ä–µ–¥ –∏–µ—Ä–∞—Ä—Ö–∏—è–º–∏ (–∏—Å–ø—Ä–∞–≤–ª—è–µ—Ç KeyError: np.int64(...))
    filtered.reset_index(drop=True, inplace=True)

    # ---------- 3) reach-score ----------
    cols_set = set(filtered.columns.tolist())

    def reach_score_row(row: pd.Series) -> float:
        # audience_per_day –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–Ω–æ
        for k in ("audience_per_day","audiencePerDay"):
            if k in cols_set and pd.notna(row.get(k, _np.nan)):
                try:
                    return float(row[k])
                except Exception:
                    pass
        # traffic_per_hour * hours * visibility
        traffic = None
        if "traffic_per_hour" in cols_set:
            traffic = row.get("traffic_per_hour", None)
        if traffic is None and "trafficPerHour" in cols_set:
            traffic = row.get("trafficPerHour", None)
        vis = 1.0
        for k in ("visibility_index","visibilityIndex"):
            if k in cols_set and pd.notna(row.get(k, _np.nan)):
                try:
                    vis = float(row[k]); break
                except Exception:
                    pass
        if traffic is not None:
            try:
                return float(traffic) * hours * float(vis)
            except Exception:
                pass
        # viewers_per_loop * loops_per_hour * hours
        vpl = row.get("viewers_per_loop", None) if "viewers_per_loop" in cols_set else None
        if vpl is None and "viewersPerLoop" in cols_set:
            vpl = row.get("viewersPerLoop", None)
        lph = row.get("loops_per_hour", None) if "loops_per_hour" in cols_set else None
        if lph is None and "loopsPerHour" in cols_set:
            lph = row.get("loopsPerHour", None)
        if vpl is not None and lph is not None and pd.notna(vpl) and pd.notna(lph):
            try:
                return float(vpl) * float(lph) * hours
            except Exception:
                return 0.0
        return 0.0

    filtered["reach_score_calc"] = filtered.apply(reach_score_row, axis=1)

    # ---------- 4) —Å—Ç–∞–≤–∫–∏ –∏ OTS (—Å –∑–∞—â–∏—Ç–æ–π) ----------
    filtered = fill_min_bid_hierarchy(filtered)
    try:
        filtered = fill_ots_hierarchy(filtered.reset_index(drop=True))
    except Exception:
        # —Ñ–æ–ª–±—ç–∫: –Ω–µ—Ç OTS ‚Äî —Å—Ç–∞–≤–∏–º 0
        filtered = filtered.copy()
        filtered["ots_used"] = 0.0
        filtered["ots_used_source"] = "na"

    # ---------- 5) plays/day –∏ —Å—Ç–æ–∏–º–æ—Å—Ç—å –ø–µ—Ä–∏–æ–¥–∞ ----------
    def plays_per_day_row(row: pd.Series) -> float:
        # plays_per_hour, –µ—Å–ª–∏ –µ—Å—Ç—å
        for k in ("plays_per_hour","playsPerHour"):
            if k in cols_set and pd.notna(row.get(k, _np.nan)):
                try:
                    return float(row[k]) * hours
                except Exception:
                    pass
        # –∏–Ω–∞—á–µ –ø–æ loop_seconds (1 –ø–æ–∫–∞–∑/—Ü–∏–∫–ª)
        loop_s = 60.0
        for k in ("loop_seconds","loopSeconds"):
            if k in cols_set and pd.notna(row.get(k, _np.nan)):
                try:
                    loop_s = float(row[k]); break
                except Exception:
                    pass
        return (3600.0 / max(loop_s, 1.0)) * hours

    filtered["_pday"]  = filtered.apply(plays_per_day_row, axis=1)
    filtered["_plays"] = (filtered["_pday"] * days).clip(lower=0).round().astype(int)
    filtered["_minbid_used_f"] = pd.to_numeric(filtered.get("minBid_used", _np.nan), errors="coerce").fillna(0.0)
    filtered["_cost_period"]   = (filtered["_minbid_used_f"] * filtered["_plays"]).astype(float)

    # ---------- 6) –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∞ –ø–æ –≥–æ—Ä–æ–¥–∞–º ----------
    by_city: dict[str, pd.DataFrame] = {}
    for c in cities:
        c_norm = _norm_text(c)
        part = filtered[filtered["_city_norm"].apply(lambda x: (x == c_norm) or (c_norm in x) or (x in c_norm))].copy()
        if not part.empty:
            by_city[c] = part
    if not by_city:
        await m.answer("–ü–æ—Å–ª–µ –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∏ –ø–æ –≥–æ—Ä–æ–¥–∞–º ‚Äî –ø—É—Å—Ç–æ.")
        return
    cities_order = [c for c in cities if c in by_city]

    # ---------- 7) —Ä–∞–∑–º–µ—Ä –≤—ã–±–æ—Ä–∫–∏ (n_total) ----------
    if budget_total is not None:
        pos = filtered["_cost_period"] > 0
        global_mean_cost = float(filtered.loc[pos, "_cost_period"].mean()) if pos.any() else 0.0
        approx_mean = global_mean_cost if global_mean_cost > 0 else 1.0
        n_total = int(budget_total // approx_mean)
        if max_total is not None:
            n_total = min(n_total, max_total)
        n_total = max(n_total, 1)
    else:
        if max_total is not None:
            n_total = max_total
        else:
            # –µ—Å–ª–∏ –≤–æ–æ–±—â–µ –Ω–µ—Ç –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–π ‚Äî –≤–æ–∑—å–º—ë–º –≤—Å—ë, –Ω–æ –Ω–µ –±–æ–ª—å—à–µ —á–µ–º –ø–æ max_per_city (–µ—Å–ª–∏ –∑–∞–¥–∞–Ω)
            n_total = sum(min(max_per_city or len(g), len(g)) for g in by_city.values())

    # ---------- 8) —Ü–µ–ª—å –ø–æ –≥–æ—Ä–æ–¥–∞–º ----------
    k = len(cities_order)
    base = n_total // k
    rem  = n_total % k
    target_by_city: dict[str, int] = {}
    for idx, c in enumerate(cities_order):
        target = base + (1 if idx < rem else 0)
        if max_per_city is not None:
            target = min(target, max_per_city)
        target = min(target, len(by_city[c]))
        target_by_city[c] = max(0, target)
    if sum(target_by_city.values()) == 0:
        for c in cities_order:
            if len(by_city[c]) > 0:
                target_by_city[c] = 1
                break

    # ---------- 9) –≤—ã–±–æ—Ä even/top ----------
    def even_pick_city(df_city: pd.DataFrame, n: int, seed: int | None = None) -> pd.DataFrame:
        if n <= 0 or df_city.empty:
            return df_city.iloc[0:0]
        cand = df_city.reset_index(drop=True).copy()
        if not {"lat","lon"}.issubset(set(cand.columns)):
            return cand.head(n)
        try:
            if "spread_select" in globals() and callable(globals()["spread_select"]):
                res = globals()["spread_select"](cand, n, random_start=False, seed=seed)
                if isinstance(res, pd.DataFrame) and not res.empty:
                    return res
        except Exception:
            pass
        return cand.head(n)

    def top_pick_city(df_city: pd.DataFrame, n: int, rank: str) -> pd.DataFrame:
        if n <= 0 or df_city.empty:
            return df_city.iloc[0:0]
        tmp = df_city.copy()
        if rank == "reach":
            if "reach_score_calc" not in tmp.columns: tmp["reach_score_calc"] = 0.0
            if "_cost_period" not in tmp.columns:     tmp["_cost_period"]     = 0.0
            return tmp.sort_values(["reach_score_calc","_cost_period"],
                                   ascending=[False, True],
                                   na_position="last").head(n)
        # rank=ots
        if "ots_used" not in tmp.columns:    tmp["ots_used"]    = 0.0
        if "_cost_period" not in tmp.columns:tmp["_cost_period"] = 0.0
        return tmp.sort_values(["ots_used","_cost_period"],
                               ascending=[False, True],
                               na_position="last").head(n)

    picked_parts = []
    for c in cities_order:
        part = by_city[c]
        n_c  = target_by_city.get(c, 0)
        if n_c <= 0:
            continue
        chosen = top_pick_city(part, n_c, rank=rank) if mode == "top" else even_pick_city(part, n_c, seed=42)
        if chosen is not None and not chosen.empty:
            chosen = chosen.copy()
            chosen["__city_display__"] = c
            picked_parts.append(chosen)

    # –≤—Å–µ–≥–¥–∞ —Å–æ–∑–¥–∞—ë–º picked
    if picked_parts:
        picked = pd.concat(picked_parts, ignore_index=True)
    else:
        picked = pd.DataFrame(columns=list(filtered.columns) + ["__city_display__"])

    # ---------- 9.1) –¥–æ–±–æ—Ä –ø–æ–¥ –±—é–¥–∂–µ—Ç (–µ—Å–ª–∏ –±—é–¥–∂–µ—Ç –∑–∞–¥–∞–Ω –∏ –Ω–µ–¥–æ—Ç—è–Ω—É–ª–∏) ----------
    if budget_total is not None:
        current_spend = float(picked["_cost_period"].sum()) if not picked.empty else 0.0
        target_spend  = float(budget_total)

        if current_spend + 1 < target_spend:
            def _gid(row):
                return (row.get("screen_id") or row.get("code") or row.get("uid") or
                        row.get("name") or row.get("id"))

            picked_gids = set()
            if not picked.empty:
                picked_gids = set(picked.apply(_gid, axis=1))

            rest_by_city: dict[str, pd.DataFrame] = {}
            for c in cities_order:
                part = by_city[c].copy()
                if part is None or part.empty:
                    continue

                # –∏—Å–∫–ª—é—á–∞–µ–º —É–∂–µ –≤—ã–±—Ä–∞–Ω–Ω—ã–µ
                part["__gid__"] = part.apply(_gid, axis=1)
                if picked_gids:
                    part = part[~part["__gid__"].isin(picked_gids)].copy()
                if part.empty:
                    continue

                # –≥–∞—Ä–∞–Ω—Ç–∏—Ä—É–µ–º —Å—Ç–æ–∏–º–æ—Å—Ç—å –ø–µ—Ä–∏–æ–¥–∞ (–µ—Å–ª–∏ –≤–¥—Ä—É–≥ –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç)
                if "_cost_period" not in part.columns or part["_cost_period"].isna().all():
                    part["_minbid_used_f"] = pd.to_numeric(part.get("minBid_used", _np.nan), errors="coerce").fillna(0.0)
                    if "_pday" not in part.columns or part["_pday"].isna().all():
                        part["_pday"] = part.apply(plays_per_day_row, axis=1)
                    part["_plays"] = (part["_pday"] * days).clip(lower=0).round().astype(int)
                    part["_cost_period"] = (part["_minbid_used_f"] * part["_plays"]).astype(float)

                # —Å–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –ø—É–ª–∞
                if mode == "top":
                    if rank == "reach":
                        if "reach_score_calc" not in part.columns: part["reach_score_calc"] = 0.0
                        part = part.sort_values(["reach_score_calc","_cost_period"], ascending=[False, True])
                    else:
                        if "ots_used" not in part.columns: part["ots_used"] = 0.0
                        part = part.sort_values(["ots_used","_cost_period"], ascending=[False, True])
                else:
                    # –¥–ª—è even ‚Äî –±–µ—Ä—ë–º –ø–æ–¥–æ—Ä–æ–∂–µ —Å–Ω–∞—á–∞–ª–∞, —á—Ç–æ–±—ã –±—ã—Å—Ç—Ä–µ–µ –¥–æ—Ç—è–Ω—É—Ç—å –±—é–¥–∂–µ—Ç
                    part = part.sort_values(["_cost_period"], ascending=False)

                rest_by_city[c] = part.reset_index(drop=True)

            if rest_by_city:
                city_idx = 0
                safe_guard = 0
                while current_spend + 1 < target_spend and safe_guard < 1_000_000:
                    safe_guard += 1
                    progressed = False

                    for _ in range(len(cities_order) or 1):
                        if not cities_order:
                            break
                        c = cities_order[city_idx % len(cities_order)]
                        city_idx += 1

                        pool = rest_by_city.get(c)
                        if pool is None or pool.empty:
                            continue

                        row = pool.iloc[0]
                        pool = pool.iloc[1:].reset_index(drop=True)
                        rest_by_city[c] = pool

                        cost_add = float(row.get("_cost_period", 0.0) or 0.0)
                        if cost_add <= 0:
                            continue

                        row = row.copy()
                        row["__city_display__"] = c
                        picked = pd.concat([picked, row.to_frame().T], ignore_index=True)
                        current_spend += cost_add
                        progressed = True

                        if current_spend + 1 >= target_spend:
                            break

                    if not progressed:
                        break  # –Ω–µ—á–µ–º –¥–æ–±–∏—Ä–∞—Ç—å

    if picked.empty:
        await m.answer("–ü–æ—Å–ª–µ –æ—Ç–±–æ—Ä–∞ —ç–∫—Ä–∞–Ω–æ–≤ ‚Äî –ø—É—Å—Ç–æ. –£–≤–µ–ª–∏—á—å—Ç–µ –±—é–¥–∂–µ—Ç/–ª–∏–º–∏—Ç—ã –∏–ª–∏ –æ—Å–ª–∞–±—å—Ç–µ —Ñ–∏–ª—å—Ç—Ä—ã.")
        return

    # ---------- 10) —Ñ–∏–Ω–∞–ª—å–Ω—ã–µ —Å—Ç—Ä–æ–∫–∏ ----------
    def _sf(x, d=0.0):
        try:
            f = float(x)
            return d if not np.isfinite(f) else f
        except Exception:
            return d

    rows = []
    for _, r in picked.iterrows():
        pday  = _sf(r.get("_pday"), 0.0)
        plays = int(max(0, round(pday * days)))

        ots_day   = _sf(r.get("ots_used"), 0.0)   # —Ç—Ä–∞–∫—Ç—É–µ–º –∫–∞–∫ —Å—Ä–µ–¥–Ω–∏–π OTS/–¥–µ–Ω—å
        ots_total = int(round(ots_day * days))

        minbid_used = _sf(r.get("minBid_used"), 0.0)
        cost        = round(minbid_used * plays, 2) if minbid_used > 0 else 0.0

        gid = (r.get("screen_id") or r.get("code") or r.get("uid") or
               r.get("name") or r.get("id"))

        rows.append({
            "City": r.get("__city_display__") or r.get("city"),
            "GID": gid,
            "Format": r.get("format"),
            "Owner":  r.get("owner") or r.get("vendor"),
            "Plays/day": round(pday, 1),
            "Plays (period)": plays,
            "OTS avg/day": ots_day,
            "OTS total": ots_total,
            "MinBid avg (used)": (None if minbid_used <= 0 else minbid_used),
            "minBid_source": r.get("minBid_source"),
            "OTS source": r.get("ots_used_source"),
            "Budget": cost,
            "Reach score": int(_sf(r.get("reach_score_calc"), 0.0)),
            "Lat": r.get("lat"),
            "Lon": r.get("lon"),
        })

    plan_df = pd.DataFrame(rows)
    if plan_df.empty:
        await m.answer("–ù–µ –ø–æ–ª—É—á–∏–ª–æ—Å—å —Å–æ–±—Ä–∞—Ç—å –ø–ª–∞–Ω (–ø–æ—Å–ª–µ –æ—Ç–±–æ—Ä–∞ –ø—É—Å—Ç–æ).")
        return

    # –∞–≥—Ä–µ–≥–∞—Ç—ã
    agg = (plan_df.groupby("City", as_index=False)
           .agg(Screens=("GID","nunique"),
                Plays=("Plays (period)","sum"),
                OTS=("OTS total","sum"),
                Budget=("Budget","sum"),
                OTS_avg_day=("OTS avg/day","mean"),
                MinBid_avg_used=("MinBid avg (used)","mean")))
    total_budget = float(plan_df["Budget"].sum())

    # ---------- 11) Excel ----------
    buf = io.BytesIO()
    with pd.ExcelWriter(buf, engine="xlsxwriter") as w:
        # Summary
        agg_sorted = agg.sort_values("OTS", ascending=False)
        agg_sorted.to_excel(w, sheet_name="Summary", index=False)
        ws = w.sheets["Summary"]
        widths = [18,10,14,14,14,14,18]
        for i, width in enumerate(widths[:len(agg_sorted.columns)]):
            ws.set_column(i, i, width)

        fmt_int   = w.book.add_format({"num_format":"#,##0"})
        fmt_money = w.book.add_format({"num_format":"#,##0"})
        fmt_float = w.book.add_format({"num_format":"#,##0.00"})
        cols = list(agg_sorted.columns)
        def _setc(name, fmt):
            if name in cols:
                j = cols.index(name)
                ws.set_column(j, j, None, fmt)
        _setc("Screens", fmt_int)
        _setc("Plays", fmt_int)
        _setc("OTS", fmt_int)
        _setc("Budget", fmt_money)
        _setc("OTS_avg_day", fmt_float)
        _setc("MinBid_avg_used", fmt_money)

        # Screens
        order = ["City","GID","Format","Owner",
                 "Plays/day","Plays (period)",
                 "OTS avg/day","OTS total",
                 "MinBid avg (used)","minBid_source","OTS source",
                 "Budget","Reach score","Lat","Lon"]
        exist = [c for c in order if c in plan_df.columns]
        plan_sorted = plan_df[exist].sort_values(["City","Reach score"], ascending=[True, False])
        plan_sorted.to_excel(w, sheet_name="Screens", index=False)
        ws2 = w.sheets["Screens"]
        widths2 = [18,22,14,16,12,16,14,16,16,16,16,14,12,10,10]
        for i, width in enumerate(widths2[:len(exist)]):
            ws2.set_column(i, i, width)

        # —á–∏—Å–ª–æ–≤—ã–µ —Ñ–æ—Ä–º–∞—Ç—ã –ª–∏—Å—Ç–∞ Screens
        idx = {c:i for i,c in enumerate(exist)}
        for c, fmt in [("Plays/day", fmt_float),
                       ("Plays (period)", fmt_int),
                       ("OTS avg/day", fmt_float),
                       ("OTS total", fmt_int),
                       ("MinBid avg (used)", fmt_money),
                       ("Budget", fmt_money)]:
            if c in idx:
                ws2.set_column(idx[c], idx[c], None, fmt)

        # Assumptions
        ass = pd.DataFrame([
            {"Parameter":"Days", "Value":days},
            {"Parameter":"Hours per day", "Value":hours},
            {"Parameter":"Formats filter", "Value":", ".join(formats_req) if formats_req else "‚Äî"},
            {"Parameter":"Budget", "Value":(int(budget_total) if budget_total is not None else "‚Äî")},
            {"Parameter":"max_per_city", "Value":(max_per_city if max_per_city is not None else "‚Äî")},
            {"Parameter":"max_total", "Value":(max_total if max_total is not None else "‚Äî")},
            {"Parameter":"Rows selected", "Value":len(plan_df)},
            {"Parameter":"Total Budget (selected)", "Value":int(total_budget)},
            {"Parameter":"Mode", "Value":mode},
            {"Parameter":"Rank", "Value":rank},
        ])
        ass.to_excel(w, sheet_name="Assumptions", index=False)

    buf.seek(0)
    await m.answer_document(
        types.BufferedInputFile(buf.getvalue(), filename="DOOH_Plan.xlsx"),
        caption=f"–ì–æ—Ç–æ–≤–æ ‚úÖ  –ì–æ—Ä–æ–¥–∞: {', '.join(cities)}\n–°—Ç—Ä–æ–∫: {len(plan_df)}"
    )

# ================================
# –¢–ï–•–¢–†–ï–ë–û–í–ê–ù–ò–Ø –ü–û –ö–ê–ú–ü–ê–ù–ò–ò (/techreqs)
# ================================
from typing import Any, Dict, List, Optional
import aiohttp
import pandas as pd
import io as _io
import json as _json

def _flatten_one(obj: Any, prefix: str = "", out: Optional[Dict[str, Any]] = None) -> Dict[str, Any]:
    """–ü–ª–æ—Å–∫–æ–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ dict/list –¥–ª—è —É–¥–æ–±–Ω–æ–π —Ç–∞–±–ª–∏—á–∫–∏."""
    if out is None:
        out = {}
    if isinstance(obj, dict):
        for k, v in obj.items():
            _flatten_one(v, f"{prefix}{k}." if prefix else f"{k}.", out)
    elif isinstance(obj, list):
        # –µ—Å–ª–∏ —ç—Ç–æ —Å–ø–∏—Å–æ–∫ {name,value} ‚Äî –ø—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ –∫–æ–ª–æ–Ω–∫–∏ –ø–æ name
        if all(isinstance(x, dict) and {"name", "value"} & set(x.keys()) for x in obj):
            for x in obj:
                name = str(x.get("name") or "").strip()
                if name:
                    out[(prefix + name).rstrip(".")] = x.get("value")
        else:
            out[(prefix + "items").rstrip(".")] = _json.dumps(obj, ensure_ascii=False)
    else:
        out[prefix[:-1] if prefix.endswith(".") else prefix] = obj
    return out

async def _fetch_inventory_techreq(
    session: aiohttp.ClientSession,
    base: str,
    headers: Dict[str, str],
    inv_id: str,
    ssl_param,
    dbg: bool = False,
    m: Optional[types.Message] = None,
) -> Dict[str, Any]:
    """GET /api/v1.0/clients/inventories/{id}/technical-requirements"""
    url = f"{base}/api/v1.0/clients/inventories/{inv_id}/technical-requirements"
    if dbg and m:
        await m.answer(f"¬∑ techreq GET {url}")
    async with session.get(url, headers=headers, ssl=ssl_param) as resp:
        body = await resp.read()
        if resp.status >= 300:
            # –≤–µ—Ä–Ω—ë–º –∫–∞–∫ —Å—Ç—Ä–æ–∫—É-–ø–æ–¥—Å–∫–∞–∑–∫—É
            return {"inventory_id": inv_id, "_http_status": resp.status, "_body": body.decode("utf-8", errors="ignore")}
        try:
            data = await resp.json(content_type=None)
        except Exception:
            data = _json.loads(body.decode("utf-8", errors="ignore"))
        # –Ω–æ—Ä–º–∞–ª–∏–∑—É–µ–º: –∫–ª–∞–¥—ë–º –≤—Å—ë "–ø–ª–æ—Å–∫–æ"
        row = {"inventory_id": inv_id}
        row.update(_flatten_one(data))
        return row

@dp.message(Command("start"))
async def start(message: Message):
    await message.answer(
        "–ü—Ä–∏–≤–µ—Ç! –Ø –û–º–Ω–∏–∫–∞.\n"
        "‚Ä¢ –ú–æ–≥—É –ø–æ–¥–æ–±—Ä–∞—Ç—å —â–∏—Ç—ã: –Ω–∞–ø–∏—à–∏ —á—Ç–æ-—Ç–æ –≤—Ä–æ–¥–µ: ¬´–ø–æ–¥–±–µ—Ä–∏ 30 –±–∏–ª–±–æ—Ä–¥–æ–≤ –∏ —Å—É–ø–µ—Ä—Å–∞–π—Ç–æ–≤ –ø–æ –ú–æ—Å–∫–≤–µ —Ä–∞–≤–Ω–æ–º–µ—Ä–Ω–æ¬ª\n"
        "‚Ä¢ –ú–æ–≥—É —Å–¥–µ–ª–∞—Ç—å –ø—Ä–æ–≥–Ω–æ–∑ –ø–æ –ø–æ—Å–ª–µ–¥–Ω–µ–π –≤—ã–±–æ—Ä–∫–µ: ¬´–ø—Ä–æ–≥–Ω–æ–∑ –Ω–∞ –Ω–µ–¥–µ–ª—é –ø–æ –ø–æ—Å–ª–µ–¥–Ω–µ–π –≤—ã–±–æ—Ä–∫–µ¬ª\n"
        "–ò–ª–∏ –ø—Ä–æ—Å—Ç–æ –Ω–∞–ø–∏—à–∏, —á—Ç–æ —Ç–µ–±–µ –Ω—É–∂–Ω–æ üôÇ"
    )

GREETINGS = re.compile(r"^\s*(–ø—Ä–∏–≤(–µ—Ç)?|–∑–¥—Ä–∞–≤—Å—Ç–≤—É–π(—Ç–µ)?|hi|hello|yo|hey)\s*[\!\.]?$", re.I)

@dp.message(F.text & ~F.text.startswith("/"))
async def smalltalk_or_route(message: Message):
    text = message.text.strip()

    # –ü—Ä–æ—Å—Ç—ã–µ –ø—Ä–∏–≤–µ—Ç—Å—Ç–≤–∏—è ‚Äî –±—ã—Å—Ç—Ä—ã–π –æ—Ç–≤–µ—Ç –±–µ–∑ OpenAI, —á—Ç–æ–±—ã –Ω–µ –∂–µ—á—å —Ç–æ–∫–µ–Ω—ã
    if GREETINGS.match(text):
        await message.answer(
            "–ü—Ä–∏–≤–µ—Ç! üëã –ß–µ–º –º–æ–≥—É –ø–æ–º–æ—á—å? –ú–æ–≥—É:\n"
            "‚Ä¢ –ø–æ–¥–æ–±—Ä–∞—Ç—å –∏–Ω–≤–µ–Ω—Ç–∞—Ä—å (–≥–æ—Ä–æ–¥, –∫–æ–ª-–≤–æ, —Ñ–æ—Ä–º–∞—Ç—ã)\n"
            "‚Ä¢ —Å–¥–µ–ª–∞—Ç—å –ø—Ä–æ–≥–Ω–æ–∑ –ø–æ —Ç–µ–∫—É—â–µ–π –≤—ã–±–æ—Ä–∫–µ\n"
            "‚Ä¢ –æ—Ç–≤–µ—Ç–∏—Ç—å –Ω–∞ –≤–æ–ø—Ä–æ—Å—ã –ø—Ä–æ –∫–∞–º–ø–∞–Ω–∏—é\n"
            "–ù–∞–ø–∏—à–∏ –∑–∞–¥–∞—á—É –æ–±—ã—á–Ω—ã–º —Ç–µ–∫—Å—Ç–æ–º."
        )
        return

    # –§–æ–ª–±—ç–∫: –æ—Ç–¥–∞—ë–º –≤ OpenAI –∫–∞–∫ small talk/assistant
    try:
        completion = openai_client.chat.completions.create(
            model="gpt-4o-mini",  # –∏–ª–∏ —Ç–≤–æ—è –º–æ–¥–µ–ª—å
            messages=[
                {
                    "role": "system",
                    "content": (
                        "–¢—ã ‚Äî –¥—Ä—É–∂–µ–ª—é–±–Ω—ã–π –ø–æ–º–æ—â–Ω–∏–∫ –º–µ–¥–∏–∞–ø–ª–∞–Ω–µ—Ä–∞ –Ω–∞—Ä—É–∂–Ω–æ–π —Ä–µ–∫–ª–∞–º—ã. "
                        "–û—Ç–≤–µ—á–∞–π –∫–æ—Ä–æ—Ç–∫–æ –∏ –ø–æ –¥–µ–ª—É, –ø–æ-—á–µ–ª–æ–≤–µ—á–µ—Å–∫–∏. –ï—Å–ª–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –ø—Ä–æ—Å–∏—Ç "
                        "–æ–ø–µ—Ä–∞—Ü–∏—é —Å —â–∏—Ç–∞–º–∏/–ø—Ä–æ–≥–Ω–æ–∑–æ–º ‚Äî –ø–µ—Ä–µ—Ñ–æ—Ä–º—É–ª–∏—Ä—É–π –≤ –ø–æ–Ω—è—Ç–Ω–æ–µ –¥–µ–π—Å—Ç–≤–∏–µ "
                        "–∏ –ø—Ä–µ–¥–ª–æ–∂–∏ –≤—ã–ø–æ–ª–Ω–∏—Ç—å."
                    ),
                },
                {"role": "user", "content": text},
            ],
            temperature=0.6,
            max_tokens=350,
        )
        reply = completion.choices[0].message.content.strip()
        await message.answer(reply)
    except Exception as e:
        # –ù–∞ –≤—Å—è–∫–∏–π –ø–æ–∂–∞—Ä–Ω—ã–π ‚Äî –Ω–µ –º–æ–ª—á–∏–º
        await message.answer("–•–º, —è –∑–∞–¥—É–º–∞–ª–∞—Å—å –∏ –æ—Å—Ç—É–ø–∏–ª–∞—Å—å üòÖ –ü–æ–ø—Ä–æ–±—É–π –µ—â—ë —Ä–∞–∑ –∏–ª–∏ —Å—Ñ–æ—Ä–º—É–ª–∏—Ä—É–π –∏–Ω–∞—á–µ.")
        # (–ò –≤ –ª–æ–≥)
        logging.exception("Smalltalk OpenAI error: %s", e)

@dp.message(Command("techreqs"))
async def cmd_techreqs(m: types.Message):
    """
    /techreqs campaign=<ID> [fields=...] [dbg=1]
    –°–æ–±–∏—Ä–∞–µ—Ç technical-requirements –ø–æ –≤—Å–µ–º –∏–Ω–≤–µ–Ω—Ç–∞—Ä—è–º –∫–∞–º–ø–∞–Ω–∏–∏ –≤ –µ–¥–∏–Ω—É—é —Ç–∞–±–ª–∏—Ü—É.
    """
    if not _owner_only(m.from_user.id):
        await m.answer("‚õîÔ∏è –¢–æ–ª—å–∫–æ –≤–ª–∞–¥–µ–ª–µ—Ü –±–æ—Ç–∞ –º–æ–∂–µ—Ç –≤—ã–ø–æ–ª–Ω—è—Ç—å —ç—Ç—É –∫–æ–º–∞–Ω–¥—É.")
        return

    text = (m.text or "").strip()
    parts = text.split()[1:]

    def _opt_str(name, default=""):
        for p in parts:
            if p.startswith(name + "="):
                return p.split("=", 1)[1]
        return default

    def _opt_bool(name, default=False):
        v = _opt_str(name, "")
        if not v:
            return default
        return str(v).lower() in {"1","true","yes","on"}

    def _opt_int(name, default=None):
        v = _opt_str(name, "")
        try:
            return int(v)
        except:
            return default

    campaign_id = _opt_int("campaign", None)
    fields_req  = _opt_str("fields", "").strip()
    dbg         = _opt_bool("dbg", False)

    if not campaign_id:
        await m.answer("–§–æ—Ä–º–∞—Ç: /techreqs campaign=<ID> [fields=...] [dbg=1]")
        return

    base  = (OBDSP_BASE or "https://proddsp.omniboard360.io").rstrip("/")
    token = (OBDSP_TOKEN or "").strip()
    if not token:
        await m.answer("–ù–µ—Ç OBDSP_TOKEN.")
        return

    await m.answer(f"üîß –°–æ–±–∏—Ä–∞—é technical requirements –¥–ª—è –∫–∞–º–ø–∞–Ω–∏–∏ {campaign_id}‚Ä¶")

    headers_json = {
        "Authorization": f"Bearer {token}",
        "Accept": "application/json",
    }
    ssl_param = _make_ssl_param_for_aiohttp()
    timeout = aiohttp.ClientTimeout(total=300)

    # 1) –ø–æ–ª—É—á–∞–µ–º —Å–ø–∏—Å–æ–∫ –∏–Ω–≤–µ–Ω—Ç–∞—Ä–µ–π –∫–∞–º–ø–∞–Ω–∏–∏
    try:
        async with aiohttp.ClientSession(timeout=timeout) as session:
            inventories = await _list_campaign_inventories(
                campaign_id, session, base, headers_json, ssl_param, m=(m if dbg else None), dbg=dbg
            )
    except Exception as e:
        await m.answer(f"üö´ –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ –∏–Ω–≤–µ–Ω—Ç–∞—Ä–µ–π: {e}")
        return

    if not inventories:
        await m.answer("–ò–Ω–≤–µ–Ω—Ç–∞—Ä–∏ –∫–∞–º–ø–∞–Ω–∏–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã.")
        return

    inv_ids: List[str] = []
    for it in inventories:
        inv_id = it.get("id") or it.get("inventoryId") or it.get("inventory_id")
        if inv_id is not None:
            inv_ids.append(str(inv_id))

    if not inv_ids:
        await m.answer("–í –æ—Ç–≤–µ—Ç–µ –Ω–µ—Ç id —É –∏–Ω–≤–µ–Ω—Ç–∞—Ä–µ–π.")
        return

    # 2) —Ç—è–Ω–µ–º tech requirements –ø–æ –∫–∞–∂–¥–æ–º—É –∏–Ω–≤–µ–Ω—Ç–∞—Ä—é (–ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ)
    rows: List[Dict[str, Any]] = []
    try:
        async with aiohttp.ClientSession(timeout=timeout) as session:
            import asyncio
            sem = asyncio.Semaphore(8)

            async def worker(iid: str):
                async with sem:
                    try:
                        row = await _fetch_inventory_techreq(session, base, headers_json, iid, ssl_param, dbg=dbg, m=(m if dbg else None))
                    except Exception as e:
                        row = {"inventory_id": iid, "_error": str(e)}
                    rows.append(row)

            await asyncio.gather(*[worker(i) for i in inv_ids])
    except Exception as e:
        await m.answer(f"üö´ –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏–π: {e}")
        return

    if not rows:
        await m.answer("–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–±—Ä–∞—Ç—å —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è.")
        return

    # 3) –¥–µ–ª–∞–µ–º DataFrame –∏ –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º
    df = pd.json_normalize(rows, sep=".")
    # –ø–æ–ª–µ–∑–Ω—ã–µ ¬´—á—Ç–æ–ø–æ–∫–∞–∑–∞—Ç—å¬ª –∫–æ–ª–æ–Ω–∫–∏ –Ω–∞–≤–µ—Ä—Ö
    preferred = [c for c in ["inventory_id", "screen_id", "name", "format", "owner"] if c in df.columns]
    other = [c for c in df.columns if c not in preferred]
    df = df[preferred + other] if preferred else df

    # –ø–æ –∑–∞–ø—Ä–æ—Å—É ‚Äî —Ç–æ–ª—å–∫–æ –≤—ã–±—Ä–∞–Ω–Ω—ã–µ –ø–æ–ª—è
    if fields_req:
        cols = [c.strip() for c in fields_req.split(",") if c.strip()]
        cols = [c for c in cols if c in df.columns]
        if not cols:
            await m.answer("–ü–æ–ª—è –Ω–µ —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω—ã. –î–æ—Å—Ç—É–ø–Ω—ã–µ: " + ", ".join(df.columns))
            return
        df = df[cols]

    # –æ—Ç–ø—Ä–∞–≤–∏–º CSV+XLSX
    try:
        csv_bytes = df.to_csv(index=False).encode("utf-8-sig")
        await bot.send_document(
            m.chat.id,
            BufferedInputFile(csv_bytes, filename=f"techreqs_campaign_{campaign_id}.csv"),
            caption=f"–¢–µ—Ö. —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è –ø–æ –∫–∞–º–ø–∞–Ω–∏–∏ {campaign_id} (CSV, {len(df)} —Å—Ç—Ä–æ–∫)"
        )
    except Exception as e:
        await m.answer(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –æ—Ç–ø—Ä–∞–≤–∏—Ç—å CSV: {e}")

    try:
        buf = _io.BytesIO()
        with pd.ExcelWriter(buf, engine="openpyxl") as w:
            df.to_excel(w, index=False, sheet_name="techreqs")
        buf.seek(0)
        await bot.send_document(
            m.chat.id,
            BufferedInputFile(buf.getvalue(), filename=f"techreqs_campaign_{campaign_id}.xlsx"),
            caption=f"–¢–µ—Ö. —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è –ø–æ –∫–∞–º–ø–∞–Ω–∏–∏ {campaign_id} (XLSX, {len(df)} —Å—Ç—Ä–æ–∫)"
        )
    except Exception as e:
        await m.answer(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –æ—Ç–ø—Ä–∞–≤–∏—Ç—å XLSX: {e}")

    # –∫—Ä–∞—Ç–∫–∏–π –∏—Ç–æ–≥ –Ω–∞ —ç–∫—Ä–∞–Ω
    await m.answer(f"‚úÖ –°–æ–±—Ä–∞–ª —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è –ø–æ {len(df)} –∏–Ω–≤–µ–Ω—Ç–∞—Ä—è–º (–∫–∞–º–ø–∞–Ω–∏—è {campaign_id}).")

# ---------- one place to export selections ----------
from aiogram.types import BufferedInputFile
import pandas as pd
import numpy as np
import io as _io

def _ensure_gid(df: pd.DataFrame) -> pd.DataFrame:
    d = df.copy()
    if "GID" not in d.columns:
        for c in ("screen_id", "code", "uid", "id", "name"):
            if c in d.columns:
                d["GID"] = d[c]
                break
        else:
            d["GID"] = range(1, len(d) + 1)
    cols = ["GID"] + [c for c in d.columns if c != "GID"]
    return d.loc[:, cols]

async def send_selection_files(
    m,
    df: pd.DataFrame,
    *,
    basename: str = "selection",
    caption_prefix: str = "",
    fields: list[str] | None = None,
):
    if df is None or df.empty:
        await m.answer("–ü—É—Å—Ç–∞—è –≤—ã–±–æ—Ä–∫–∞ ‚Äî –Ω–µ—á–µ–≥–æ –æ—Ç–ø—Ä–∞–≤–ª—è—Ç—å.")
        return

    # 1) –ì–∞—Ä–∞–Ω—Ç–∏—Ä—É–µ–º GID –∏ —É–±–∏—Ä–∞–µ–º –¥—É–±–ª–∏—Ä—É—é—â–∏–µ ID-–ø–æ–ª—è
    exp = _ensure_gid(df)
    for _c in ("screen_id", "code", "uid", "id"):
        if _c in exp.columns:
            exp = exp.drop(columns=[_c])

    # 2) –ü–æ–ª—è: –µ—Å–ª–∏ —É–∫–∞–∑–∞–Ω—ã ‚Äî –±–µ—Ä—ë–º –∏—Ö, –Ω–æ GID –≤—Å–µ–≥–¥–∞ –ø–µ—Ä–≤—ã–π
    if fields:
        want = []
        seen = set()
        # GID –≤—Å–µ–≥–¥–∞ –ø–µ—Ä–≤—ã–º
        if "GID" not in fields:
            want.append("GID"); seen.add("GID")
        for c in fields:
            if c in exp.columns and c not in seen:
                want.append(c); seen.add(c)
        # –¥–æ–±–∞–≤–∏–º —Ç–µ, —á—Ç–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –ø–æ–ø—Ä–æ—Å–∏–ª, –Ω–æ –∏—Ö –Ω–µ—Ç ‚Äî –∏–≥–Ω–æ—Ä quietly
        exp = exp.loc[:, [c for c in want if c in exp.columns]]
    else:
        # –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –æ—Å—Ç–∞–≤–ª—è–µ–º –∫–∞–∫ –µ—Å—Ç—å (GID —É–∂–µ –ø–µ—Ä–≤—ã–π)
        pass

    # 3) CSV
    try:
        csv_bytes = exp.to_csv(index=False).encode("utf-8-sig")
        await m.answer_document(
            BufferedInputFile(csv_bytes, filename=f"{basename}.csv"),
            caption=(caption_prefix or "")
        )
    except Exception as e:
        await m.answer(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –æ—Ç–ø—Ä–∞–≤–∏—Ç—å CSV: {e}")

    # 4) XLSX
    try:
        xbuf = _io.BytesIO()
        with pd.ExcelWriter(xbuf, engine="xlsxwriter") as w:
            exp.to_excel(w, index=False, sheet_name="selection")
            ws = w.sheets["selection"]
            # –±–∞–∑–æ–≤—ã–µ —à–∏—Ä–∏–Ω—ã
            for i, col in enumerate(exp.columns):
                ws.set_column(i, i, min(max(10, len(str(col)) + 2), 36))
        xbuf.seek(0)
        await m.answer_document(
            BufferedInputFile(xbuf.getvalue(), filename=f"{basename}.xlsx"),
            caption=(caption_prefix or "")
        )
    except Exception as e:
        await m.answer(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –æ—Ç–ø—Ä–∞–≤–∏—Ç—å XLSX: {e}")

# --- FOTO / IMPRESSION SHOTS -------------------------------------------------
import aiohttp

# --- —Ñ–æ—Ç–æ–æ—Ç—á—ë—Ç—ã –ø–æ –∫–∞–º–ø–∞–Ω–∏–∏: –∏–Ω–≤–µ–Ω—Ç–∞—Ä–∏ -> —à–æ—Ç—ã ---
# –¢—Ä–µ–±—É–µ—Ç: aiohttp, OBDSP_BASE, OBDSP_TOKEN, _make_ssl_param_for_aiohttp()
# –°–æ–≤–º–µ—Å—Ç–∏–º–æ —Å —Ç–≤–æ–∏–º cmd_shots (–≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç list[dict] –∏–ª–∏ bytes –ø—Ä–∏ ZIP)

from typing import Union, List, Dict, Any

async def _list_campaign_inventories(
    campaign_id: int,
    session: aiohttp.ClientSession,
    base: str,
    headers: Dict[str, str],
    ssl_param,
    m: types.Message | None = None,
    dbg: bool = False,
) -> List[Dict[str, Any]]:
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –∏–Ω–≤–µ–Ω—Ç–∞—Ä–µ–π –∫–∞–º–ø–∞–Ω–∏–∏ (—Å –ø–æ–ª–µ–º id / inventoryId)."""
    url = f"{base}/api/v1.0/clients/campaigns/{campaign_id}/inventories"
    page, size = 0, 500
    out: List[Dict[str, Any]] = []

    while True:
        params = {"page": page, "size": size}
        if dbg and m:
            await m.answer(f"¬∑ –ø—Ä–æ–±—É—é GET {url}?page={page}&size={size}")

        async with session.get(url, headers=headers, params=params, ssl=ssl_param) as resp:
            if resp.status >= 300:
                # –µ—Å–ª–∏ —ç–Ω–¥–ø–æ–π–Ω—Ç –±–µ–∑ –ø–∞–≥–∏–Ω–∞—Ü–∏–∏ ‚Äî –ø–æ–ø—Ä–æ–±—É–µ–º –æ–¥–∏–Ω —Ä–∞–∑ –±–µ–∑ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
                if page == 0:
                    body = (await resp.read()).decode("utf-8", errors="ignore")
                    if dbg and m:
                        await m.answer(f"‚Ä¶–∏–Ω–≤–µ–Ω—Ç–∞—Ä–∏: {resp.status} {body[:200]}")
                    # –ü–æ–ø—Ä–æ–±—É–µ–º –±–µ–∑ –ø–∞–≥–∏–Ω–∞—Ü–∏–∏
                    async with session.get(url, headers=headers, ssl=ssl_param) as r2:
                        data = await r2.json(content_type=None)
                    items = data if isinstance(data, list) else data.get("items") or data.get("content") or []
                    out.extend(items or [])
                break

            data = await resp.json(content_type=None)
            items = data if isinstance(data, list) else data.get("items") or data.get("content") or []
            if not items:
                break
            out.extend(items)
            if len(items) < size:
                break
            page += 1

    return out


# ==== API helpers ====
import re as _re

_FORMAT_ALIAS = {
    "MEDIAFACADE": "MEDIA_FACADE",
    "MEDIA-FACADE": "MEDIA_FACADE",
    "MEDIA FACADE": "MEDIA_FACADE",
    "CITYBOARD": "CITY_BOARD",
    "CITY-BOARD": "CITY_BOARD",
    "BILLBOARD": "BILLBOARD",
    "SUPERSITE": "SUPERSITE",
}

def normalize_format_name(s: str) -> str:
    if not s:
        return ""
    u = str(s).strip().upper()
    u = _FORMAT_ALIAS.get(u, u)
    u = _re.sub(r"[^A-Z0-9]+", "_", u).strip("_")
    return u

def normalize_format_list(lst) -> list[str]:
    out, seen = [], set()
    for v in (lst or []):
        nv = normalize_format_name(v)
        if nv and nv not in seen:
            out.append(nv); seen.add(nv)
    return out

def suggest_formats(df, requested: list[str], topn: int = 8) -> str:
    if "format" not in df.columns:
        return "–í –¥–∞–Ω–Ω—ã—Ö –Ω–µ—Ç —Å—Ç–æ–ª–±—Ü–∞ format."
    vc = (df["format"].astype(str)
          .str.upper()
          .str.replace(r"[^A-Z0-9]+", "_", regex=True)
          .str.strip("_")
          .value_counts(dropna=True))
    if vc.empty:
        return "–°–ø–∏—Å–æ–∫ —Ñ–æ—Ä–º–∞—Ç–æ–≤ –ø—É—Å—Ç."
    head = vc.head(topn)
    req = ", ".join(requested) if requested else "‚Äî"
    return "–ó–∞–ø—Ä–æ—à–µ–Ω–æ: " + req + "\n–î–æ—Å—Ç—É–ø–Ω—ã–µ —Ç–æ–ø—ã: " + ", ".join([f"{k} ({int(v)})" for k, v in head.items()])


async def _fetch_impression_shots(
    campaign_id: int,
    per: int | None = None,        # shotCountPerInventoryCreative
    m: types.Message | None = None,
    dbg: bool = False,
) -> Union[List[Dict[str, Any]], Dict[str, Any], bytes]:
    """
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç:
      - list[dict] —Å–æ —à–æ—Ç–∞–º–∏ –ø–æ –≤—Å–µ–º –∏–Ω–≤–µ–Ω—Ç–∞—Ä—è–º –∫–∞–º–ø–∞–Ω–∏–∏, –ò–õ–ò
      - bytes (–µ—Å–ª–∏ –≤–¥—Ä—É–≥ —Å–µ—Ä–≤–µ—Ä –æ—Ç–¥–∞—Å—Ç ZIP –Ω–∞ —É—Ä–æ–≤–Ω–µ –∏–Ω–≤–µ–Ω—Ç–∞—Ä—è ‚Äî –º–∞–ª–æ–≤–µ—Ä–æ—è—Ç–Ω–æ).

    –õ–æ–≥–∏–∫–∞:
      1) GET /api/v1.0/clients/campaigns/{campaignId}/inventories
      2) –î–ª—è –∫–∞–∂–¥–æ–≥–æ inventoryId:
         GET /api/v1.0/clients/campaigns/{campaignId}/inventories/{inventoryId}/impression-shots
         (—Å –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–º shotCountPerInventoryCreative=per –ø—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏)
    """
    base = (OBDSP_BASE or "https://proddsp.omniboard360.io").rstrip("/")
    token = (OBDSP_TOKEN or "").strip()
    if not token:
        raise RuntimeError("–ù–µ—Ç OBDSP_TOKEN")

    headers_json = {
        "Authorization": f"Bearer {token}",
        "Accept": "application/json",
        "Content-Type": "application/json",
    }
    headers_any = {
        "Authorization": f"Bearer {token}",
        "Accept": "*/*",
    }

    ssl_param = _make_ssl_param_for_aiohttp()
    timeout = aiohttp.ClientTimeout(total=300)

    all_rows: List[Dict[str, Any]] = []

    async with aiohttp.ClientSession(timeout=timeout) as session:
        # --- –ø–æ–ª—É—á–∞–µ–º —Å–ø–∏—Å–æ–∫ –∏–Ω–≤–µ–Ω—Ç–∞—Ä–µ–π ---
        inventories = await _list_campaign_inventories(
            campaign_id, session, base, headers_json, ssl_param, m=m, dbg=dbg
        )
        if not inventories:
            if dbg and m:
                await m.answer("‚Ä¶–∏–Ω–≤–µ–Ω—Ç–∞—Ä–∏ –∫–∞–º–ø–∞–Ω–∏–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã.")
            return []

        inv_ids = []
        for it in inventories:
            inv_id = it.get("id") or it.get("inventoryId") or it.get("inventory_id")
            if inv_id:
                inv_ids.append(str(inv_id))

        if not inv_ids:
            if dbg and m:
                await m.answer("‚Ä¶–≤ –æ—Ç–≤–µ—Ç–µ –Ω–µ—Ç id —É –∏–Ω–≤–µ–Ω—Ç–∞—Ä–µ–π.")
            return []

        # --- –ø–æ –∫–∞–∂–¥–æ–º—É inventoryId —Ç—è–Ω–µ–º —à–æ—Ç—ã ---
        for idx, inv_id in enumerate(inv_ids, 1):
            url = f"{base}/api/v1.0/clients/campaigns/{campaign_id}/inventories/{inv_id}/impression-shots"
            q = {}
            if per is not None:
                q["shotCountPerInventoryCreative"] = per

            if dbg and m:
                await m.answer(f"¬∑ [{idx}/{len(inv_ids)}] GET {url}")

            try:
                async with session.get(url, headers=headers_any, params=q, ssl=ssl_param) as resp:
                    ct = resp.headers.get("Content-Type", "")
                    body = await resp.read()

                    if "application/zip" in ct or "application/octet-stream" in ct:
                        return body

                    if resp.status == 404:
                        continue
                    if resp.status >= 300:
                        if dbg and m:
                            msg = body.decode("utf-8", errors="ignore")[:200]
                            await m.answer(f"‚Ä¶{resp.status} –¥–ª—è inventory {inv_id}: {msg}")
                        continue

                    try:
                        data = await resp.json(content_type=None)
                    except Exception:
                        import json as _json
                        data = _json.loads(body.decode("utf-8", errors="ignore"))

                    items = (
                        data if isinstance(data, list)
                        else data.get("items") or data.get("content") or data.get("shots") or []
                    )
                    for it in (items or []):
                        if isinstance(it, dict):
                            it.setdefault("inventory_id", inv_id)
                    all_rows.extend(items or [])

            except Exception as e:
                if dbg and m:
                    await m.answer(f"‚Ä¶–æ—à–∏–±–∫–∞ –¥–ª—è inventory {inv_id}: {e}")
                continue

    return all_rows


# ==== API helpers (–æ–±–Ω–æ–≤–ª—ë–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è) ====

async def _list_campaign_inventories(
    campaign_id: int,
    session: aiohttp.ClientSession,
    base: str,
    headers_json: dict,
    ssl_param,
    m: types.Message | None = None,
    dbg: bool = False,
) -> list[dict]:
    """
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –∏–Ω–≤–µ–Ω—Ç–∞—Ä–µ–π –∫–∞–º–ø–∞–Ω–∏–∏ –∫–∞–∫ list[dict].
    –ü—Ä–æ–±—É–µ—Ç:
      - v1.0 –∏ v1
      - —Å /clients –∏ –±–µ–∑
      - —Ä–∞–∑–Ω—ã–µ —Ä–µ—Å—É—Ä—Å—ã: inventories / campaign-inventories / placements / screens
      - —Å –ø–∞–≥–∏–Ω–∞—Ü–∏–µ–π (page/size –∏ pageNumber/pageSize) –∏ –±–µ–∑
      - fallback: –≥—Ä—É–∑–∏—Ç –∫–∞–º–ø–∞–Ω–∏—é —Ü–µ–ª–∏–∫–æ–º –∏ –ø—ã—Ç–∞–µ—Ç—Å—è –∏–∑–≤–ª–µ—á—å –∏–Ω–≤–µ–Ω—Ç–∞—Ä–∏ –∏–∑ –ø–æ–ª–µ–π
    """

    def _log(s: str):
        if dbg and m:
            return m.answer(s)

    # 1) –ù–∞–±–æ—Ä –±–∞–∑–æ–≤—ã—Ö –ø—Ä–µ—Ñ–∏–∫—Å–æ–≤ –≤–µ—Ä—Å–∏–π –∏ clients
    vers = ["v1.0", "v1"]
    roots = []
    for v in vers:
        roots.append(f"{base}/api/{v}/clients/campaigns/{campaign_id}")
        roots.append(f"{base}/api/{v}/campaigns/{campaign_id}")

    # 2) –ö–∞–Ω–¥–∏–¥–∞—Ç—ã-–∫–æ–ª–ª–µ–∫—Ü–∏–∏, –≥–¥–µ –º–æ–≥—É—Ç –ª–µ–∂–∞—Ç—å –∏–Ω–≤–µ–Ω—Ç–∞—Ä–∏
    suffixes = [
        "inventories",
        "campaign-inventories",
        "placements",
        "screens",
        "inventory",               # –Ω–∞ –≤—Å—è–∫–∏–π
        "items",                   # –≤–¥—Ä—É–≥
    ]

    # 3) –ü–æ–ø—Ä–æ–±—É–µ–º –∫–æ–ª–ª–µ–∫—Ü–∏–∏ —Å –ø–∞–≥–∏–Ω–∞—Ü–∏–µ–π
    collected: list[dict] = []
    for root in roots:
        for suffix in suffixes:
            url = f"{root}/{suffix}"
            page = 0
            size = 500
            tried_pages = 0
            while True:
                tried_pages += 1
                param_sets = [
                    {"page": page, "size": size},
                    {"pageNumber": page + 1, "pageSize": size},
                ]
                got_any = False

                for params in param_sets:
                    try:
                        if dbg and m:
                            await _log(f"¬∑ GET {url} {params}")

                        async with session.get(url, headers=headers_json, params=params, ssl=ssl_param) as resp:
                            body = await resp.read()

                            if resp.status == 404:
                                # –Ω–µ—Ç —Ç–∞–∫–æ–π —Ä—É—á–∫–∏ ‚Äî –≤—ã—Ö–æ–¥–∏–º –∏–∑ —Ü–∏–∫–ª–∞ –ø–æ params –∏ –ø—Ä–æ–±—É–µ–º —Å–ª–µ–¥—É—é—â—É—é
                                if dbg and m and tried_pages == 1:
                                    txt = body.decode("utf-8", errors="ignore")[:200]
                                    await _log(f"‚Ä¶404 –¥–ª—è {url}: {txt}")
                                got_any = False
                                break

                            if resp.status >= 300:
                                if dbg and m:
                                    txt = body.decode("utf-8", errors="ignore")[:200]
                                    await _log(f"‚Ä¶{resp.status} {url} {params}: {txt}")
                                continue

                            # –Ω–æ—Ä–º–∞–ª—å–Ω—ã–π –æ—Ç–≤–µ—Ç ‚Üí –ø—ã—Ç–∞–µ–º—Å—è —Ä–∞–∑–æ–±—Ä–∞—Ç—å
                            try:
                                data = await resp.json(content_type=None)
                            except Exception:
                                import json as _json
                                data = _json.loads(body.decode("utf-8", errors="ignore"))

                            if isinstance(data, list):
                                page_items = data
                            elif isinstance(data, dict):
                                page_items = (
                                    data.get("items")
                                    or data.get("content")
                                    or data.get("data")
                                    or data.get("results")
                                    or data.get("inventories")
                                    or data.get("placements")
                                    or []
                                )
                            else:
                                page_items = []

                            if page_items:
                                collected.extend(page_items)
                                got_any = True
                            else:
                                got_any = False

                            # —ç–≤—Ä–∏—Å—Ç–∏–∫–∞ ¬´–ø–æ—Å–ª–µ–¥–Ω–µ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã¬ª
                            last_flag = False
                            if isinstance(data, dict):
                                if data.get("last") is True:
                                    last_flag = True
                                tp = data.get("totalPages")
                                if isinstance(tp, int):
                                    if params.get("page") is not None and page + 1 >= tp:
                                        last_flag = True
                                    if params.get("pageNumber") is not None and params["pageNumber"] >= tp:
                                        last_flag = True

                            if not page_items or last_flag:
                                break

                            page += 1

                    except Exception as e:
                        if dbg and m:
                            await _log(f"‚Ä¶–æ—à–∏–±–∫–∞ {url} {params}: {e}")
                        continue

                if not got_any:
                    # –ª–∏–±–æ 404, –ª–∏–±–æ –ø—É—Å—Ç–æ ‚Äî –≤—ã—Ö–æ–¥–∏–º –∏–∑ –ø–∞–≥–∏–Ω–∞—Ü–∏–∏ –ø–æ —ç—Ç–æ–º—É url
                    break

            if collected:
                if dbg and m:
                    await _log(f"‚úîÔ∏é –ò–Ω–≤–µ–Ω—Ç–∞—Ä–µ–π –ø–æ–ª—É—á–µ–Ω–æ: {len(collected)} (—á–µ—Ä–µ–∑ {url})")
                return collected

    # 4) –ü–æ–ø—Ä–æ–±—É–µ–º –ø–æ–ª—É—á–∏—Ç—å —Å–∞–º—É –∫–∞–º–ø–∞–Ω–∏—é –∏ –≤—ã—Ç–∞—â–∏—Ç—å –∏–Ω–≤–µ–Ω—Ç–∞—Ä–∏ –∏–∑ –≤–ª–æ–∂–µ–Ω–Ω—ã—Ö –ø–æ–ª–µ–π
    for root in roots:
        try:
            if dbg and m:
                await _log(f"¬∑ GET {root}")

            async with session.get(root, headers=headers_json, ssl=ssl_param) as resp:
                body = await resp.read()
                if resp.status >= 300:
                    if dbg and m:
                        txt = body.decode("utf-8", errors="ignore")[:200]
                        await _log(f"‚Ä¶{resp.status} {root}: {txt}")
                    continue

                try:
                    camp = await resp.json(content_type=None)
                except Exception:
                    import json as _json
                    camp = _json.loads(body.decode("utf-8", errors="ignore"))

                # —Ç–∏–ø–∏—á–Ω—ã–µ –º–µ—Å—Ç–∞, –≥–¥–µ –≤—Å—Ç—Ä–µ—á–∞–ª inventory:
                # - campaign["inventories"] : [ {id, ...}, ... ]
                # - campaign["placements"] : [ {inventory:{id,...}}, ... ] –∏–ª–∏ inventoryId
                # - campaign["campaignCreatives"] : [ {inventory:{id,...}}, ... ]

                buckets = []
                if isinstance(camp, dict):
                    for key in ("inventories", "placements", "campaignCreatives", "items", "content", "data", "results"):
                        val = camp.get(key)
                        if isinstance(val, list) and val:
                            buckets.append(val)

                invs: list[dict] = []

                def _id_from(obj):
                    if not isinstance(obj, dict):
                        return None
                    return obj.get("id") or obj.get("inventoryId") or obj.get("inventory_id")

                for bucket in buckets:
                    for it in bucket:
                        # –ø—Ä—è–º–æ–π –æ–±—ä–µ–∫—Ç –∏–Ω–≤–µ–Ω—Ç–∞—Ä—è
                        iid = _id_from(it)
                        if iid:
                            invs.append({"id": iid, **(it if isinstance(it, dict) else {})})
                            continue
                        # –≤–ª–æ–∂–µ–Ω–Ω—ã–π inventory
                        if isinstance(it, dict):
                            inv = it.get("inventory") or it.get("screen") or {}
                            iid = _id_from(inv)
                            if iid:
                                invs.append({"id": iid, **inv})

                if invs:
                    # —É–¥–∞–ª–∏–º –¥—É–±–ª–∏–∫–∞—Ç—ã –ø–æ id
                    seen = set()
                    uniq: list[dict] = []
                    for d in invs:
                        i = str(d.get("id"))
                        if i not in seen:
                            uniq.append(d)
                            seen.add(i)
                    if dbg and m:
                        await _log(f"‚úîÔ∏é –ò–Ω–≤–µ–Ω—Ç–∞—Ä–µ–π –Ω–∞–π–¥–µ–Ω–æ –≤–æ –≤–ª–æ–∂–µ–Ω–∏—è—Ö: {len(uniq)} (—á–µ—Ä–µ–∑ {root})")
                    return uniq

        except Exception as e:
            if dbg and m:
                await _log(f"‚Ä¶–æ—à–∏–±–∫–∞ {root}: {e}")
            continue

    # 5) –ù–∏—á–µ–≥–æ –Ω–µ –Ω–∞—à–ª–∏
    return []

def _make_ssl_param_for_aiohttp():
    """
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç:
      - False  -> –æ—Ç–∫–ª—é—á–∏—Ç—å –ø—Ä–æ–≤–µ—Ä–∫—É (aiohttp –ø—Ä–∏–Ω–∏–º–∞–µ—Ç ssl=False)
      - ssl.SSLContext -> —Å –∫–∞—Å—Ç–æ–º–Ω—ã–º CA (OBDSP_CA_BUNDLE) –∏–ª–∏ certifi
      - None  -> –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é —Å–∏—Å—Ç–µ–º–Ω—ã–µ –∫–æ—Ä–Ω–∏
    """
    if OBDSP_SSL_VERIFY in {"0", "false", "no", "off"}:
        return False  # –æ—Ç–∫–ª—é—á–∏—Ç—å –ø—Ä–æ–≤–µ—Ä–∫—É (–Ω–∞ —Å–≤–æ–π —Å—Ç—Ä–∞—Ö –∏ —Ä–∏—Å–∫)

    # –ö–∞—Å—Ç–æ–º–Ω—ã–π –±–∞–Ω–¥–ª, –µ—Å–ª–∏ —É–∫–∞–∑–∞–Ω
    if OBDSP_CA_BUNDLE:
        ctx = ssl.create_default_context(cafile=OBDSP_CA_BUNDLE)
        return ctx

    # –ü–∞–∫–µ—Ç certifi, –µ—Å–ª–∏ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω
    if certifi is not None:
        try:
            ctx = ssl.create_default_context(cafile=certifi.where())
            return ctx
        except Exception:
            pass

    # –ò–Ω–∞—á–µ –ø—É—Å—Ç—å aiohttp –∏—Å–ø–æ–ª—å–∑—É–µ—Ç —Å–∏—Å—Ç–µ–º–Ω—ã–µ –∫–æ—Ä–Ω–∏
    return None

def _auth_headers() -> dict:
    """–§–æ—Ä–º–∏—Ä—É–µ—Ç –∑–∞–≥–æ–ª–æ–≤–∫–∏ –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏ –¥–ª—è API DSP."""
    t = (OBDSP_TOKEN or "").strip()
    scheme = (OBDSP_AUTH_SCHEME or "Bearer").strip().lower()
    if not t:
        return {}
    if scheme == "apikey":
        return {"X-API-Key": t}
    if scheme == "basic":
        return {"Authorization": f"Basic {t}"}
    if scheme == "token":
        return {"Authorization": f"Token {t}"}
    return {"Authorization": f"Bearer {t}"}

def _map_inventory_row(item: dict) -> dict:
    """
    –ü—Ä–∏–≤–µ–¥–µ–Ω–∏–µ –ø–æ–ª–µ–π API –∫ –Ω–∞—à–∏–º –∫–æ–ª–æ–Ω–∫–∞–º: screen_id,name,lat,lon,city,format,owner.
    –ü—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏ –ø–æ–ø—Ä–∞–≤—å –∞–ª–∏–∞—Å—ã –ø–æ–¥ —Ñ–∞–∫—Ç–∏—á–µ—Å–∫–∏–π JSON.
    """
    def pick(*keys, default=""):
        for k in keys:
            if k in item and item[k] is not None:
                return item[k]
        return default

    screen_id = str(pick("id", "screen_id", "guid", "gid", default="")).strip()
    name      = str(pick("name", "title", "screen_name", default="")).strip()
    lat       = pick("lat", "latitude", "geo_lat", default=None)
    lon       = pick("lon", "longitude", "geo_lon", default=None)
    city      = str(pick("city", "city_name", default="")).strip()
    format_   = str(pick("format", "screen_format", "type", default="")).strip()
    owner     = str(pick("owner", "vendor", "operator", "owner_name", default="")).strip()

    try:
        lat = float(lat)
        lon = float(lon)
    except (TypeError, ValueError):
        lat, lon = None, None

    return {
        "screen_id": screen_id,
        "name": name,
        "lat": lat,
        "lon": lon,
        "city": city,
        "format": format_,
        "owner": owner,
    }

# ==== FORECAST core helper =====================================================
from io import BytesIO

def run_forecast(
    screens_df: pd.DataFrame,
    budget: float | None,
    days: int,
    hours_per_day: int | None = None,
    hours: list[int] | None = None,
) -> tuple[str, list[tuple[str, bytes, str]]]:
    """
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç:
      result_text: –∫—Ä–∞—Ç–∫–æ–µ —Ä–µ–∑—é–º–µ
      files: [(filename, bytes, caption), ...] ‚Äî CSV —Å –¥–µ—Ç–∞–ª–∏–∑–∞—Ü–∏–µ–π.

    –õ–æ–≥–∏–∫–∞ —Å—Ç–∞–≤–æ–∫:
      - –±–µ—Ä—ë–º minBid, –≥–¥–µ –µ—Å—Ç—å;
      - –¥–ª—è –ø—É—Å—Ç—ã—Ö: –∑–∞–ø–æ–ª–Ω—è–µ–º —Å—Ä–µ–¥–Ω–∏–º –ø–æ (city, format, owner),
        –∑–∞—Ç–µ–º –ø–æ (format, owner), –∑–∞—Ç–µ–º –ø–æ format, –∑–∞—Ç–µ–º –≥–ª–æ–±–∞–ª—å–Ω—ã–º —Å—Ä–µ–¥–Ω–∏–º.
    –ü—Ä–æ–ø—É—Å–∫–Ω–∞—è —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç—å:
      capacity = N_screens * days * H * 30 (–≤—ã—Ö–æ–¥–æ–≤/—Å–ª–æ—Ç–æ–≤)
      –≥–¥–µ H = len(hours) –µ—Å–ª–∏ –ø–µ—Ä–µ–¥–∞–Ω —Å–ø–∏—Å–æ–∫ —á–∞—Å–æ–≤, –∏–Ω–∞—á–µ hours_per_day.
    """
    df = screens_df.copy()

    # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –∫–æ–ª–æ–Ω–æ–∫
    for col in ("city", "format", "owner", "screen_id"):
        if col not in df.columns:
            df[col] = ""
    if "minBid" not in df.columns:
        df["minBid"] = np.nan

    # –ü—Ä–∏–≤–µ–¥—ë–º minBid –∫ —á–∏—Å–ª—É
    def _num(x):
        try:
            return float(str(x).replace(",", "."))
        except Exception:
            return np.nan
    df["minBid_raw"] = df["minBid"].apply(_num)

    # –ì—Ä—É–ø–ø–æ–≤—ã–µ —Å—Ä–µ–¥–Ω–∏–µ
    g_city_fmt_owner = df.groupby(["city","format","owner"], dropna=False)["minBid_raw"].mean()
    g_fmt_owner      = df.groupby(["format","owner"], dropna=False)["minBid_raw"].mean()
    g_fmt            = df.groupby(["format"], dropna=False)["minBid_raw"].mean()
    global_mean      = float(df["minBid_raw"].mean()) if df["minBid_raw"].notna().any() else 0.0

    # –ó–∞–ø–æ–ª–Ω–µ–Ω–∏–µ –ø–æ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–∞–º
    used = []
    src  = []
    for _, r in df.iterrows():
        v = r["minBid_raw"]
        if not np.isnan(v):
            used.append(v); src.append("raw")
            continue

        key1 = (r["city"], r["format"], r["owner"])
        v1 = g_city_fmt_owner.get(key1, np.nan)
        if not np.isnan(v1):
            used.append(float(v1)); src.append("avg(city,format,owner)")
            continue

        key2 = (r["format"], r["owner"])
        v2 = g_fmt_owner.get(key2, np.nan)
        if not np.isnan(v2):
            used.append(float(v2)); src.append("avg(format,owner)")
            continue

        v3 = g_fmt.get(r["format"], np.nan)
        if not np.isnan(v3):
            used.append(float(v3)); src.append("avg(format)")
            continue

        used.append(global_mean); src.append("avg(global)")

    df["minBid_used"] = used
    df["minBid_source"] = src

    # –°—Ä–µ–¥–Ω—è—è –º–∏–Ω–∏–º–∞–ª—å–Ω–∞—è —Å—Ç–∞–≤–∫–∞
    if df["minBid_used"].notna().any():
        avg_minbid = float(df["minBid_used"].mean())
    else:
        avg_minbid = 0.0

    # –ß–∞—Å—ã
    if hours and isinstance(hours, (list, tuple)):
        # –æ—Å—Ç–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–µ —á–∞—Å—ã 0..23
        hours_clean = sorted({int(h) for h in hours if str(h).isdigit() and 0 <= int(h) <= 23})
        H = max(1, len(hours_clean))
    else:
        H = max(1, int(hours_per_day or 10))

    N = int(len(df))
    capacity = int(N * days * H * 30)  # –º–∞–∫—Å–∏–º—É–º –≤—ã—Ö–æ–¥–æ–≤ –ø–æ –∑–∞–¥–∞–Ω–Ω–æ–º—É –æ–∫–Ω—É

    text_lines = []
    text_lines.append(f"–≠–∫—Ä–∞–Ω–æ–≤: {N}")
    text_lines.append(f"–û–∫–Ω–æ –ø—Ä–æ–≥–Ω–æ–∑–∞: {days} –¥–Ω √ó {H} —á/–¥–µ–Ω—å √ó 30 —Å–ª–æ—Ç–æ–≤/—á = capacity {capacity:,}".replace(",", " "))
    text_lines.append(f"–°—Ä–µ–¥–Ω—è—è –º–∏–Ω–∏–º–∞–ª—å–Ω–∞—è —Å—Ç–∞–≤–∫–∞: {avg_minbid:,.2f}".replace(",", " "))

    result = {}
    if budget is not None and budget > 0 and avg_minbid > 0:
        possible_exits = int(budget // avg_minbid)
        exits = min(possible_exits, capacity)
        result["exits"] = exits
        result["budget"] = float(budget)
        text_lines.append(f"–ë—é–¥–∂–µ—Ç: {budget:,.2f} ‚Üí –º–∞–∫—Å–∏–º—É–º –≤—ã—Ö–æ–¥–æ–≤ –ø–æ —Å—Ç–∞–≤–∫–µ ‚âà {possible_exits:,}".replace(",", " "))
        if exits < possible_exits:
            text_lines.append(f"–û–≥—Ä–∞–Ω–∏—á–µ–Ω–æ capacity ‚Üí –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä—É–µ–º—ã–µ –≤—ã—Ö–æ–¥—ã: {exits:,}".replace(",", " "))
        else:
            text_lines.append(f"–ü—Ä–æ–≥–Ω–æ–∑–∏—Ä—É–µ–º—ã–µ –≤—ã—Ö–æ–¥—ã: {exits:,}".replace(",", " "))
    else:
        # –ù–µ—Ç –±—é–¥–∂–µ—Ç–∞ ‚Üí —Å—á–∏—Ç–∞–µ–º –ø–æ–ª–Ω—É—é –∑–∞–≥—Ä—É–∑–∫—É –æ–∫–Ω–∞
        budget_needed = float(capacity * avg_minbid)
        result["budget_needed"] = budget_needed
        result["exits"] = capacity
        text_lines.append(f"–ë–µ–∑ –±—é–¥–∂–µ—Ç–∞: –ø–æ–ª–Ω–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ = {capacity:,} –≤—ã—Ö–æ–¥–æ–≤".replace(",", " "))
        text_lines.append(f"–û—Ü–µ–Ω–∫–∞ –±—é–¥–∂–µ—Ç–∞: {budget_needed:,.2f}".replace(",", " "))

    # CSV —Å –¥–µ—Ç–∞–ª–∏–∑–∞—Ü–∏–µ–π
    cols = [
        "screen_id", "city", "format", "owner",
        "minBid_raw", "minBid_used", "minBid_source"
    ]
    view = df[cols].copy()
    buf = BytesIO()
    view.to_csv(buf, index=False)
    csv_bytes = buf.getvalue()

    files = [
        ("forecast_breakdown.csv", csv_bytes,
         "–î–µ—Ç–∞–ª–∏–∑–∞—Ü–∏—è —Å—Ç–∞–≤–æ–∫ (raw/used/source)")
    ]
    return "\n".join(text_lines), files


# ================== /forecast ==================
@dp.message(Command("forecast"))
async def cmd_forecast(m: types.Message, _call_args: dict | None = None):
    """
    /forecast [budget=...] [days=7] [hours_per_day=8] [hours=07-10,17-21]
    –û—Å–Ω–æ–≤–∞–Ω–æ –Ω–∞ –ø–æ—Å–ª–µ–¥–Ω–µ–π –≤—ã–±–æ—Ä–∫–µ (LAST_RESULT). –ü—Ä–∏–º–µ—Ä –ø—Ä–æ–≥—Ä–∞–º–º–Ω–æ–≥–æ –≤—ã–∑–æ–≤–∞:
      await cmd_forecast(m, _call_args={"budget": 2_000_000, "days": 7, "hours_per_day": 10, "hours": ["07-10","17-21"]})
    """
    # --- –ª–æ–∫–∞–ª—å–Ω—ã–µ –∏–º–ø–æ—Ä—Ç—ã ---
    import re
    import io
    from datetime import datetime
    import numpy as np
    import pandas as pd
    from aiogram.types import BufferedInputFile

    # --- –±–µ–∑–æ–ø–∞—Å–Ω—ã–µ –≥–ª–æ–±–∞–ª—å–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è ---
    global LAST_RESULT, LAST_SELECTION_NAME
    MAX_PLAYS_PER_HOUR = globals().get("MAX_PLAYS_PER_HOUR", 30)

    # --- –Ω–∞–ª–∏—á–∏–µ –ø–æ—Å–ª–µ–¥–Ω–µ–π –≤—ã–±–æ—Ä–∫–∏ ---
    if LAST_RESULT is None or getattr(LAST_RESULT, "empty", True):
        await m.answer("–ù–µ—Ç –ø–æ—Å–ª–µ–¥–Ω–µ–π –≤—ã–±–æ—Ä–∫–∏. –°–Ω–∞—á–∞–ª–∞ –ø–æ–¥–±–µ—Ä–∏—Ç–µ —ç–∫—Ä–∞–Ω—ã (/pick_city, /pick_any, /pick_at, /near –∏–ª–∏ —á–µ—Ä–µ–∑ /ask).")
        return

    df = LAST_RESULT.copy()

    # ---------- –ø–∞—Ä—Å–∏–Ω–≥ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ ----------
    def _parse_budget(v):
        if v is None or v == "":
            return None
        if isinstance(v, (int, float)):
            return float(v)
        s = str(v).strip().lower().replace(" ", "").replace("‚ÇΩ", "").replace(",", ".")
        try:
            if s.endswith("m"): return float(s[:-1]) * 1_000_000
            if s.endswith("–∫"): return float(s[:-1]) * 1_000
            if s.endswith("k"): return float(s[:-1]) * 1_000
            return float(s)
        except Exception:
            return None

    def _parse_hours_windows(text_or_list):
        """
        hours="07-10,17-21" –∏–ª–∏ ["07-10","17-21"] ‚Üí [7,8,9,17,18,19,20]
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –æ—Ç—Å–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Å–ø–∏—Å–æ–∫ —á–∞—Å–æ–≤ –∏–ª–∏ None.
        """
        if text_or_list is None:
            return None
        if isinstance(text_or_list, list):
            uniq = set()
            for item in text_or_list:
                hh = _parse_hours_windows(item) or []
                uniq.update(hh)
            return sorted(uniq) if uniq else None

        s = str(text_or_list).strip()
        if not s:
            return None

        hours = set()
        for part in re.split(r"[,\s]+", s):
            part = part.strip()
            if not part:
                continue
            if "-" in part:
                a, b = part.split("-", 1)
                try:
                    a = int(a); b = int(b)
                    lo, hi = (a, b) if a <= b else (b, a)
                    for h in range(lo, hi):
                        if 0 <= h <= 23:
                            hours.add(h)
                except Exception:
                    continue
            else:
                try:
                    h = int(part)
                    if 0 <= h <= 23:
                        hours.add(h)
                except Exception:
                    continue
        return sorted(hours) if hours else None

    def _parse_inline_kv(text: str) -> dict:
        out = {}
        for p in (text or "").strip().split()[1:]:
            if "=" in p:
                k, v = p.split("=", 1)
                out[k.strip().lower()] = v.strip()
        return out

    kv = dict(_call_args or _parse_inline_kv(m.text or ""))

    budget = _parse_budget(kv.get("budget"))
    # days
    try:
        days = int(kv.get("days", 7))
    except Exception:
        days = 7
    # hours / hours_per_day
    hours_windows = _parse_hours_windows(kv.get("hours"))
    try:
        hours_per_day = int(kv.get("hours_per_day")) if kv.get("hours_per_day") is not None else None
    except Exception:
        hours_per_day = None
    if hours_per_day is None:
        hours_per_day = len(hours_windows) if hours_windows else 8
    if hours_windows and len(hours_windows) != hours_per_day:
        # –ï—Å–ª–∏ –ø–µ—Ä–µ–¥–∞–Ω—ã –æ–∫–Ω–∞ –∏ hours_per_day, –∏—Å–ø–æ–ª—å–∑—É–µ–º —Ñ–∞–∫—Ç–∏—á–µ—Å–∫–æ–µ –∫–æ–ª-–≤–æ —á–∞—Å–æ–≤ –∏–∑ –æ–∫–æ–Ω
        hours_per_day = len(hours_windows)

    # ---------- –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è —Å—Ç–∞–≤–æ–∫ (minBid_used) ----------
    def _num(series):
        return pd.to_numeric(series, errors="coerce")

    def fill_min_bid_hierarchy(df_in: pd.DataFrame) -> pd.DataFrame:
        d = df_in.copy().reset_index(drop=True)
        idx = d.index

        def col(name):
            return _num(d[name]) if name in d.columns else pd.Series(np.nan, index=idx)

        candidates = [
            ("minBid_used", col("minBid_used")),
            ("minBid",      col("minBid")),
            ("min_bid",     col("min_bid")),
            ("price_per_play", col("price_per_play")),
            ("PricePerPlay",   col("PricePerPlay")),
            ("cpm_play",       col("cpm_play")),
        ]

        used = pd.Series(np.nan, index=idx, dtype="float64")
        src  = pd.Series("",     index=idx, dtype="object")
        for name, ser in candidates:
            mask = used.isna() & ser.notna() & np.isfinite(ser) & (ser >= 0)
            used = used.where(~mask, ser)
            src  = src.where(~mask, name)

        d["minBid_used"]   = used.fillna(0.0).astype(float)
        d["minBid_source"] = src.where(src != "", "na")
        return d

    df = fill_min_bid_hierarchy(df)

    # —Å—Ä–µ–¥–Ω—è—è —Å—Ç–∞–≤–∫–∞ –¥–ª—è —Ñ–æ–ª–±—ç–∫–æ–≤/–¥–µ–ª–µ–Ω–∏—è –±—é–¥–∂–µ—Ç–∞
    pos = df["minBid_used"] > 0
    avg_min = float(df.loc[pos, "minBid_used"].mean()) if pos.any() else 0.0
    if not np.isfinite(avg_min) or avg_min <= 0:
        avg_min = 1.0  # —á—Ç–æ–±—ã –Ω–µ –¥–µ–ª–∏—Ç—å –Ω–∞ –Ω–æ–ª—å

    # ---------- –æ—Ü–µ–Ω–∫–∞ plays_per_hour –∏ —ë–º–∫–æ—Å—Ç–∏ –∫–∞–∂–¥–æ–≥–æ —ç–∫—Ä–∞–Ω–∞ ----------
    # –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç: plays_per_hour -> loops_per_hour -> loop_seconds -> –¥–µ—Ñ–æ–ª—Ç
    plays_per_hour = None
    if "plays_per_hour" in df.columns:
        plays_per_hour = _num(df["plays_per_hour"])
    elif "playsPerHour" in df.columns:
        plays_per_hour = _num(df["playsPerHour"])

    loops_per_hour = None
    if plays_per_hour is None or plays_per_hour.isna().all():
        if "loops_per_hour" in df.columns:
            loops_per_hour = _num(df["loops_per_hour"])
        elif "loopsPerHour" in df.columns:
            loops_per_hour = _num(df["loopsPerHour"])

    loop_seconds = None
    if (plays_per_hour is None or plays_per_hour.isna().all()) and (loops_per_hour is None or loops_per_hour.isna().all()):
        if "loop_seconds" in df.columns:
            loop_seconds = _num(df["loop_seconds"])
        elif "loopSeconds" in df.columns:
            loop_seconds = _num(df["loopSeconds"])

    if plays_per_hour is not None and not plays_per_hour.isna().all():
        pph = plays_per_hour
    elif loops_per_hour is not None and not loops_per_hour.isna().all():
        pph = loops_per_hour
    elif loop_seconds is not None and not loop_seconds.isna().all():
        # —Ö–æ—Ç—è –±—ã 1 –ø–æ–∫–∞–∑ –∑–∞ —Ü–∏–∫–ª
        pph = 3600.0 / loop_seconds.replace(0, np.nan)
    else:
        pph = pd.Series(float(MAX_PLAYS_PER_HOUR), index=df.index)

    pph = pph.fillna(float(MAX_PLAYS_PER_HOUR)).clip(lower=0)

    # —ë–º–∫–æ—Å—Ç—å —ç–∫—Ä–∞–Ω–∞ –∑–∞ –≤–µ—Å—å –ø–µ—Ä–∏–æ–¥
    cap_per_screen = (pph * hours_per_day * days).round().astype("int64").clip(lower=0)
    total_capacity = int(cap_per_screen.sum())

    if total_capacity <= 0:
        await m.answer("–ù–µ —É–¥–∞–ª–æ—Å—å –æ—Ü–µ–Ω–∏—Ç—å –ø–æ–∫–∞–∑–∞–µ–º–æ—Å—Ç—å —ç–∫—Ä–∞–Ω–æ–≤ (–Ω—É–ª–µ–≤–∞—è —ë–º–∫–æ—Å—Ç—å). –ü—Ä–æ–≤–µ—Ä—å—Ç–µ plays_per_hour/loop_seconds –∏–ª–∏ —É—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ MAX_PLAYS_PER_HOUR.")
        return

    # ---------- —Å–∫–æ–ª—å–∫–æ –≤—ã—Ö–æ–¥–æ–≤ –º–æ–∂–µ–º –∫—É–ø–∏—Ç—å ----------
    if budget is not None:
        target_slots = int(max(0, min(total_capacity, budget // max(avg_min, 1e-9))))
    else:
        target_slots = int(total_capacity)
        budget = float(target_slots * avg_min)

    # ---------- —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø—Ä–æ–ø–æ—Ä—Ü–∏–æ–Ω–∞–ª—å–Ω–æ —ë–º–∫–æ—Å—Ç–∏ ----------
    # –Ω–µ–ø—Ä–µ—Ä—ã–≤–Ω—ã–µ –¥–æ–ª–∏:
    weights = cap_per_screen.astype(float)
    wsum = float(weights.sum())
    shares = (weights / wsum) if wsum > 0 else pd.Series(0.0, index=df.index)

    # –¥—Ä–æ–±–Ω—ã–µ –∂–µ–ª–∞–µ–º—ã–µ —Å–ª–æ—Ç—ã:
    desired = shares * target_slots
    base = np.floor(desired).astype(int)
    remainder = target_slots - int(base.sum())

    # —Ä–∞–∑–¥–∞—ë–º –æ—Å—Ç–∞—Ç–æ–∫ –ø–æ –Ω–∞–∏–±–æ–ª—å—à–∏–º –¥—Ä–æ–±–Ω—ã–º —á–∞—Å—Ç—è–º
    frac = (desired - base).to_numpy()
    order = np.argsort(frac)[::-1]  # –∏–Ω–¥–µ–∫—Å—ã –ø–æ —É–±—ã–≤–∞–Ω–∏—é –¥—Ä–æ–±–Ω–æ–π —á–∞—Å—Ç–∏
    add = np.zeros(len(df), dtype=int)
    if remainder > 0:
        add[order[:remainder]] = 1

    per_screen = base.to_numpy() + add
    # –∫–ª–∏–ø –ø–æ —ë–º–∫–æ—Å—Ç–∏ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ —ç–∫—Ä–∞–Ω–∞
    per_screen = np.minimum(per_screen, cap_per_screen.to_numpy())
    # –µ—Å–ª–∏ –∏–∑-–∑–∞ –∫–ª–∏–ø–æ–≤ —Å—É–º–º–∞ –ø—Ä–æ—Å–µ–ª–∞ ‚Äî –¥–æ–±–∏–≤–∞—Ç—å –Ω–µ –±—É–¥–µ–º, —ç—Ç–æ –∑–Ω–∞—á–∏—Ç capacity —É–∑–∫–æ–µ.
    planned_slots_total = int(per_screen.sum())

    # –∏—Ç–æ–≥–æ–≤–∞—è —Å—Ç–æ–∏–º–æ—Å—Ç—å
    mb = pd.to_numeric(df["minBid_used"], errors="coerce").fillna(avg_min)
    planned_cost = (per_screen * mb).astype(float)
    total_cost = float(planned_cost.sum())

    # ---------- —Å–±–æ—Ä —Ç–∞–±–ª–∏—Ü—ã –Ω–∞ —ç–∫—Å–ø–æ—Ä—Ç ----------
    df = df.reset_index(drop=True).copy()
    df["planned_slots"] = per_screen
    df["planned_cost"]  = planned_cost

    # –ø–æ–¥—Ö–≤–∞—Ç–∏–º –Ω–∞–∏–±–æ–ª–µ–µ —Ç–∏–ø–∏—á–Ω—ã–µ —Å–ª—É–∂–µ–±–Ω—ã–µ –ø–æ–ª—è, –Ω–æ –Ω–µ –±—É–¥–µ–º —Ç—Ä–µ–±–æ–≤–∞—Ç—å –∏—Ö –æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
    export_cols_pref = [
        "screen_id","id","uid","code","name",
        "city","format","owner",
        "lat","lon",
        "plays_per_hour","loops_per_hour","loop_seconds",
        "minBid","min_bid","minBid_used","minBid_source",
        "planned_slots","planned_cost"
    ]
    export_cols = [c for c in export_cols_pref if c in df.columns]
    if "screen_id" not in export_cols:
        export_cols.insert(0, export_cols_pref[1] if export_cols_pref[1] in df.columns else export_cols_pref[2] if export_cols_pref[2] in df.columns else "planned_slots")

    plan_df = df[export_cols].copy()

    # ---------- –∏–º–µ–Ω–∞ —Ñ–∞–π–ª–æ–≤ / –ø–æ–¥–ø–∏—Å–∏ ----------
    sel_name = (globals().get("LAST_SELECTION_NAME")
                or f"selection_{datetime.now().strftime('%Y%m%d_%H%M%S')}")
    hours_hint = f"{hours_per_day} —á/–¥" if not hours_windows else f"{hours_per_day} —á/–¥ ({','.join(str(h).zfill(2) for h in hours_windows)})"

    # ---------- CSV ----------
    try:
        csv_bytes = plan_df.to_csv(index=False).encode("utf-8-sig")
        await m.answer_document(
            BufferedInputFile(csv_bytes, filename=f"forecast_{sel_name}.csv"),
            caption=(f"–ü—Ä–æ–≥–Ω–æ–∑: {planned_slots_total:,} –≤—ã—Ö–æ–¥–æ–≤, –±—é–¥–∂–µ—Ç‚âà{round(total_cost):,} ‚ÇΩ\n"
                     f"(–¥–Ω–µ–π={days}, {hours_hint}, –ª–∏–º–∏—Ç {int(MAX_PLAYS_PER_HOUR)}/—á–∞—Å, avg minBid‚âà{round(avg_min):,} ‚ÇΩ)")
        )
    except Exception as e:
        await m.answer(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –æ—Ç–ø—Ä–∞–≤–∏—Ç—å CSV: {e}")

    # ---------- XLSX ----------
    try:
        xbuf = io.BytesIO()
        with pd.ExcelWriter(xbuf, engine="xlsxwriter") as w:
            plan_df.to_excel(w, index=False, sheet_name="forecast")
            ws = w.sheets["forecast"]
            # —á—É—Ç—å-—á—É—Ç—å —à–∏—Ä–∏–Ω—ã –∫–æ–ª–æ–Ω–æ–∫
            for i, col in enumerate(plan_df.columns):
                ws.set_column(i, i, min(24, max(10, len(str(col)) + 4)))
        xbuf.seek(0)
        await m.answer_document(
            BufferedInputFile(xbuf.getvalue(), filename=f"forecast_{sel_name}.xlsx"),
            caption=f"–î–µ—Ç–∞–ª–∏ –ø—Ä–æ–≥–Ω–æ–∑–∞ (–¥–Ω–µ–π={days}, {hours_hint}, –ª–∏–º–∏—Ç {int(MAX_PLAYS_PER_HOUR)}/—á–∞—Å)"
        )
    except Exception as e:
        await m.answer(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –æ—Ç–ø—Ä–∞–≤–∏—Ç—å XLSX: {e}")


# --- NORMALIZATION (API ‚Üí DataFrame) ---
def _normalize_api_to_df(items: list[dict]) -> pd.DataFrame:
    """
    –ü—Ä–µ–≤—Ä–∞—â–∞–µ—Ç —Å—ã—Ä—ã–µ items –∏–∑ Omniboard /clients/inventories –≤ —É–¥–æ–±–Ω—ã–π DataFrame.
    –ù–∏–∫–∞–∫–æ–π —Ä–µ–∫—É—Ä—Å–∏–∏ —Ç—É—Ç –±—ã—Ç—å –Ω–µ –¥–æ–ª–∂–Ω–æ.
    """
    if not items:
        return pd.DataFrame(columns=[
            "id","screen_id","name","format","placement","installation",
            "owner_id","owner","city","address","lat","lon",
            "width_mm","height_mm","width_px","height_px",
            "phys_width_px","phys_height_px",
            "sspProvider","sspTypes","minBid","ots","grp","meta_format",
            "image_url","image_preview"
        ])

    def g(obj, path, default=None):
        try:
            cur = obj
            for k in path:
                if cur is None:
                    return default
                if isinstance(k, int):
                    cur = (cur or [])[k] if isinstance(cur, list) and len(cur) > k else None
                else:
                    cur = (cur or {}).get(k)
            return default if cur is None else cur
        except Exception:
            return default

    rows = []
    for it in items:
        rows.append({
            "id": it.get("id"),
            "screen_id": it.get("gid"),
            "name": it.get("name"),
            "format": it.get("type"),
            "placement": it.get("placement"),
            "installation": it.get("installation"),

            "owner_id": g(it, ["displayOwner","id"]),
            "owner":    g(it, ["displayOwner","name"]),

            "city":    g(it, ["location","city"]),
            "address": g(it, ["location","address"]),
            "lat":     g(it, ["location","latitude"]),
            "lon":     g(it, ["location","longitude"]),

            "width_mm":  g(it, ["surfaceDimensionMM","width"]),
            "height_mm": g(it, ["surfaceDimensionMM","height"]),
            "width_px":  g(it, ["screenResolutionPx","width"]),
            "height_px": g(it, ["screenResolutionPx","height"]),
            "phys_width_px":  g(it, ["physicalResolutionPx","width"]),
            "phys_height_px": g(it, ["physicalResolutionPx","height"]),

            "sspProvider": it.get("sspProvider"),
            "sspTypes":    ",".join(it.get("sspTypes") or []),

            "minBid": g(it, ["minBidInfo","minBid"]),
            "ots":    g(it, ["minBidInfo","ots"]),
            "grp":    g(it, ["metadata","grp"]),
            "meta_format": g(it, ["metadata","format"]),

            "image_url":     g(it, ["images", 0, "url"]),
            "image_preview": g(it, ["images", 0, "preview"]),
        })

    return pd.DataFrame(rows)


def _first_list_like(obj):
    """
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø–µ—Ä–≤—ã–π ¬´—Å–ø–∏—Å–∫–æ–æ–±—Ä–∞–∑–Ω—ã–π¬ª –∫—É—Å–æ–∫ –∏–∑ —Å–ª–æ–≤–∞—Ä—è: content/items/data/rows/result/shots.
    –ï—Å–ª–∏ obj —É–∂–µ list ‚Äî –≤–µ—Ä–Ω—ë—Ç –µ–≥–æ.
    """
    if isinstance(obj, list):
        return obj
    if isinstance(obj, dict):
        for k in ("content", "items", "data", "rows", "result", "shots", "list"):
            v = obj.get(k)
            if isinstance(v, list) and v:
                return v
    return []

def _dig(o, path, default=None):
    cur = o
    try:
        for k in path:
            if cur is None:
                return default
            if isinstance(k, int):
                if isinstance(cur, list) and len(cur) > k:
                    cur = cur[k]
                else:
                    return default
            else:
                cur = cur.get(k) if isinstance(cur, dict) else default
        return default if cur is None else cur
    except Exception:
        return default

def _normalize_shots(raw) -> pd.DataFrame:
    """
    –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç:
      - list[dict] (–ø–ª–æ—Å–∫–∏–π)
      - dict —Å –∫–ª—é—á–∞–º–∏ content/items/data/rows/result/shots
      - –±–∏–Ω–∞—Ä–Ω—ã–π ZIP (–≤ —ç—Ç–æ–º —Å–ª—É—á–∞–µ –≤–µ—Ä–Ω—ë–º –ø—É—Å—Ç–æ–π DF, –∞ –æ—Ç–ø—Ä–∞–≤–∫–∞ –¥–µ–ª–∞–µ—Ç—Å—è –≤—ã—à–µ)
    """
    if raw is None:
        return pd.DataFrame()

    if isinstance(raw, (bytes, bytearray)):
        # —ç—Ç–æ ZIP ‚Äî –Ω–µ –Ω–æ—Ä–º–∞–ª–∏–∑—É–µ–º –∑–¥–µ—Å—å
        return pd.DataFrame()

    items = _first_list_like(raw) if isinstance(raw, dict) else (raw if isinstance(raw, list) else [])
    if not items:
        # –∏–Ω–æ–≥–¥–∞ —à–æ—Ç—ã –ª–µ–∂–∞—Ç –≤ raw["data"]["content"] –∏–ª–∏ raw["data"]["items"]
        if isinstance(raw, dict) and "data" in raw:
            items = _first_list_like(raw["data"])
    if not items:
        return pd.DataFrame()

    rows = []
    for it in items:
        if not isinstance(it, dict):
            continue

        # –∏–Ω–≤–µ–Ω—Ç–∞—Ä—å
        inv = it.get("inventory") or it.get("screen") or {}
        # –∫—Ä–µ–∞—Ç–∏–≤
        cr  = it.get("creative") or it.get("ad") or {}
        # –∫–∞–º–ø–∞–Ω–∏—è
        camp = it.get("campaign") or {}

        # –±–∞–∑–æ–≤—ã–µ –ø–æ–ª—è (–ø—Ä–æ–±—É–µ–º —Ä–∞–∑–Ω—ã–µ —Å–∏–Ω–æ–Ω–∏–º—ã)
        screen_id = (
            inv.get("gid") or inv.get("id") or
            it.get("inventoryGid") or it.get("inventoryId") or
            it.get("screenId") or it.get("screenGid")
        )
        screen_name = (
            inv.get("name") or it.get("inventoryName") or it.get("screenName")
        )
        fmt = (
            inv.get("type") or inv.get("format") or
            it.get("format") or it.get("inventoryFormat")
        )
        owner = (
            _dig(inv, ["displayOwner", "name"]) or inv.get("owner") or
            it.get("owner") or it.get("inventoryOwner")
        )

        city = (
            _dig(inv, ["location", "city"]) or _dig(it, ["location", "city"]) or
            it.get("city")
        )
        address = (
            _dig(inv, ["location", "address"]) or _dig(it, ["location", "address"]) or
            it.get("address")
        )
        lat = (
            _dig(inv, ["location", "latitude"]) or it.get("lat") or it.get("latitude")
        )
        lon = (
            _dig(inv, ["location", "longitude"]) or it.get("lon") or it.get("longitude")
        )

        creative_id = cr.get("id") or it.get("creativeId")
        creative_name = cr.get("name") or it.get("creativeName")

        # —Å—Å—ã–ª–∫–∞ –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ/–∫–∞–¥—Ä
        image_url = (
            it.get("imageUrl") or it.get("url") or it.get("image") or
            _dig(it, ["image", "url"]) or
            _dig(it, ["images", 0, "url"])
        )

        # –≤—Ä–µ–º—è –∫–∞–¥—Ä–∞
        shot_ts = (
            it.get("createdAt") or it.get("timestamp") or it.get("dateTime") or
            it.get("time") or it.get("shotTime")
        )

        rows.append({
            "screen_id": screen_id,
            "name": screen_name,
            "format": fmt,
            "owner": owner,
            "city": city,
            "address": address,
            "lat": lat,
            "lon": lon,
            "creative_id": creative_id,
            "creative_name": creative_name,
            "image_url": image_url,
            "shot_ts": shot_ts,
        })

    df = pd.DataFrame(rows)
    # –ª—ë–≥–∫–∞—è —á–∏—Å—Ç–∫–∞
    if not df.empty:
        # –ø–µ—Ä–µ–∏–º–µ–Ω—É–µ–º NaN -> –ø—É—Å—Ç–æ –¥–ª—è —Ç–µ–∫—Å—Ç–æ–≤–æ–≥–æ –≤—ã–≤–æ–¥–∞
        df = df.replace({None: "", pd.NA: ""})
    return df

# --- Swagger discovery helpers ---

SWAGGER_CANDIDATES = [
    "/v3/api-docs",               # —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π springdoc
    "/v3/api-docs/main",          # –µ—Å–ª–∏ —Å—Ö–µ–º –Ω–µ—Å–∫–æ–ª—å–∫–æ, ¬´main¬ª —á–∞—Å—Ç–æ –µ—Å—Ç—å
    "/v3/api-docs/swagger-config" # –¥–∞—Å—Ç —Å—Å—ã–ª–∫–∏ –Ω–∞ –¥–æ—Å—Ç—É–ø–Ω—ã–µ —Å—Ö–µ–º—ã (urls)
]

async def _fetch_json(session, url, headers, ssl):
    async with session.get(url, headers=headers, ssl=ssl) as r:
        body = await r.read()
        if r.status >= 300:
            return None
        try:
            return await r.json(content_type=None)
        except Exception:
            import json as _json
            try:
                return _json.loads(body.decode("utf-8", errors="ignore"))
            except Exception:
                return None

async def _load_swagger_schema(m=None, dbg=False):
    """–ü—ã—Ç–∞–µ—Ç—Å—è –ø–æ–ª—É—á–∏—Ç—å swagger schema (JSON) —Å proddsp, –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç dict –∏–ª–∏ None."""
    base = (OBDSP_BASE or "https://proddsp.omniboard360.io").rstrip("/")
    token = (OBDSP_TOKEN or "").strip()
    hdr = {"Authorization": f"Bearer {token}"} if token else {}
    ssl_param = _make_ssl_param_for_aiohttp()
    import aiohttp
    async with aiohttp.ClientSession(timeout=aiohttp.ClientTimeout(total=60)) as s:
        # 1) –ø—Ä–æ–±—É–µ–º –ø—Ä—è–º—ã–µ —Å—Ö–µ–º—ã
        for suffix in SWAGGER_CANDIDATES:
            url = base + suffix
            if dbg and m: await m.answer(f"‚Ä¢ GET {url}")
            data = await _fetch_json(s, url, hdr, ssl_param)
            if data and isinstance(data, dict) and ("paths" in data or "urls" in data):
                return data
        # 2) –µ—Å–ª–∏ –≤–µ—Ä–Ω—É–ª—Å—è swagger-config —Å urls ‚Äî –¥–µ—Ä–Ω—ë–º –∫–∞–∂–¥—É—é
        cfg = await _fetch_json(s, base + "/v3/api-docs/swagger-config", hdr, ssl_param)
        if cfg and isinstance(cfg, dict) and isinstance(cfg.get("urls"), list):
            for item in cfg["urls"]:
                u = item.get("url")
                if not u:
                    continue
                url = u if u.startswith("http") else (base + u)
                if dbg and m: await m.answer(f"‚Ä¢ GET {url}")
                data = await _fetch_json(s, url, hdr, ssl_param)
                if data and isinstance(data, dict) and "paths" in data:
                    return data
    return None

@dp.message(Command("discover_api"))
async def cmd_discover_api(m: types.Message):
    """
    –°–∫–∞–Ω–∏—Ä—É–µ—Ç swagger –∏ –≤—ã–≤–æ–¥–∏—Ç –ø–æ–¥—Ö–æ–¥—è—â–∏–µ –ø—É—Ç–∏ (campaign/inventory/impression/shot/...).
    –ü—Ä–∏–º–µ—Ä: /discover_api q=campaign
    """
    # –ø–∞—Ä—Å–∏–º q=<substring>
    q = None
    for part in (m.text or "").split()[1:]:
        if part.startswith("q="):
            q = part.split("=", 1)[1].strip().lower() or None

    await m.answer("üîé –ß–∏—Ç–∞—é Swagger‚Ä¶")
    data = await _load_swagger_schema(m, dbg=True)
    if not data:
        await m.answer("–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å swagger-—Å—Ö–µ–º—É.")
        return

    paths = data.get("paths") or {}
    if not isinstance(paths, dict) or not paths:
        await m.answer("–í swagger –Ω–µ—Ç —Å–µ–∫—Ü–∏–∏ paths.")
        return

    # —Ñ–∏–ª—å—Ç—Ä—ã –ø–æ –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–∞–º
    needles = ["campaign", "impression", "shot", "inventory", "creative", "booking",
               "requirement", "export", "report"]
    if q:
        needles.insert(0, q)

    hits = []
    for p in paths.keys():
        low = p.lower()
        if any(k in low for k in needles):
            hits.append(p)

    if not hits:
        await m.answer("–ü–æ–¥—Ö–æ–¥—è—â–∏—Ö –ø—É—Ç–µ–π –Ω–µ –Ω–∞–π–¥–µ–Ω–æ. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –¥—Ä—É–≥–æ–π q=‚Ä¶")
        return

    hits = sorted(set(hits))
    # —Ä–µ–∂–µ–º –ø–∞—á–∫–∞–º–∏, —á—Ç–æ–±—ã –Ω–µ —É–ø–µ—Ä–µ—Ç—å—Å—è –≤ –ª–∏–º–∏—Ç —Ç–µ–ª–µ–≥—Ä–∞–º–∞
    CHUNK = 60
    head = f"–ù–∞—à—ë–ª {len(hits)} –ø—É—Ç–µ–π:\n" \
           f"(–∏—â–µ–º –ø–æ: {', '.join(needles[:6])}{'‚Ä¶' if len(needles)>6 else ''})"
    await m.answer(head)
    for i in range(0, len(hits), CHUNK):
        await m.answer("\n".join(hits[i:i+CHUNK]))

# ====== –•–≠–ù–î–õ–ï–†–´ ======
# ========= /ask: ‚Äú–ø–æ–Ω–∏–º–∞—é —á–µ–ª–æ–≤–µ–∫–∞ ‚Äî –¥–µ–ª–∞—é –¥–µ–ª–æ‚Äù =========
async def cmd_ask(m: types.Message):
    """
    –°–≤–æ–±–æ–¥–Ω–∞—è —Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∫–∞ ‚Üí –ø–ª–∞–Ω –æ—Ç LLM ‚Üí –Ω–µ–º–µ–¥–ª–µ–Ω–Ω–æ–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –Ω—É–∂–Ω–æ–π –∫–æ–º–∞–Ω–¥—ã.
    """
    # ----------------- –í–ê–ñ–ù–û: –≤—Å—ë –≤–Ω—É—Ç—Ä–∏ —Ñ—É–Ω–∫—Ü–∏–∏ -----------------
    q = (m.text or "").partition(" ")[2].strip()
    if not q:
        await m.answer("–ù–∞–ø–∏—à–∏—Ç–µ –∑–∞–ø—Ä–æ—Å –ø–æ—Å–ª–µ /ask, –Ω–∞–ø—Ä–∏–º–µ—Ä: /ask —Å–æ–±–µ—Ä–∏ 20 –±–∏–ª–±–æ—Ä–¥–æ–≤ –ø–æ –í–æ—Ä–æ–Ω–µ–∂—É —Ä–∞–≤–Ω–æ–º–µ—Ä–Ω–æ")
        return

    # –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è
    q = _pre_nlu_normalize(q)

    dbg = "dbg=1" in q.lower()

    # ---------- 1) –ú–∞—Ä—à—Ä—É—Ç–∏–∑–∞—Ü–∏—è (LLM ‚Üí intent/args) ----------
    try:
        plan = llm_route(q)
    except Exception as e:
        await m.answer(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–Ω—è—Ç—å –∑–∞–ø—Ä–æ—Å (LLM): {e}")
        return

    # ---- –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –ø–ª–∞–Ω–∞ ----
    KNOWN_KEYS = {
        "city","n","formats","owners","fields","allow_mix","seed","shuffle","fixed","mix",
        "lat","lon","radius_km",
        "campaign","per","limit","zip","value_km",
    }

    def _as_list(v):
        if v is None:
            return []
        if isinstance(v, list):
            return [str(x) for x in v]
        # –ø–æ–¥–¥–µ—Ä–∂–∏–º —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª–∏ , ; |
        return [s.strip() for s in str(v).replace(";", ",").replace("|", ",").split(",") if s.strip()]

    # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –Ω–∞–∑–≤–∞–Ω–∏–π —Ñ–æ—Ä–º–∞—Ç–æ–≤ –≤ UPPER_SNAKE_CASE + —á–∞—Å—Ç–Ω—ã–µ –º–∞–ø–ø–∏–Ω–≥–∏
    def _normalize_formats_list(vals):
        import re as _re
        out = []
        # —á–∞—Å—Ç—ã–µ alias ‚Üí –∫–∞–Ω–æ–Ω–∏—á–µ—Å–∫–æ–µ –∏–º—è
        ALIAS = {
            "MEDIAFACADE": "MEDIA_FACADE",
            "MEDIA-FACADE": "MEDIA_FACADE",
            "MEDIA FACADE": "MEDIA_FACADE",
            "CITYBOARD": "CITY_BOARD",
            "CITY-BOARD": "CITY_BOARD",
            "SUPERSITE": "SUPERSITE",  # –Ω–∞ –≤—Å—è–∫–∏–π
        }
        for v in vals:
            s = str(v).strip().upper()
            s = ALIAS.get(s, s)
            # –æ–±—â–µ–µ –ø—Ä–∞–≤–∏–ª–æ: –ª—é–±—ã–µ –Ω–µ-–±—É–∫–≤–µ–Ω–Ω–æ-—Ü–∏—Ñ—Ä–æ–≤—ã–µ ‚Üí _
            s = _re.sub(r"[^A-Z0-9]+", "_", s).strip("_")
            out.append(s)
        # —É–±–µ—Ä–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã, —Å–æ—Ö—Ä–∞–Ω—è—è –ø–æ—Ä—è–¥–æ–∫
        seen = set(); res = []
        for x in out:
            if x and x not in seen:
                res.append(x); seen.add(x)
        return res

    def _coerce_args(a: dict) -> dict:
        a = dict(a or {})
        # —Å–ø–∏—Å–∫–∏
        a["formats"] = _normalize_formats_list(_as_list(a.get("formats")))
        a["owners"]  = _as_list(a.get("owners"))
        a["fields"]  = _as_list(a.get("fields"))
        # –±—É–ª–µ–≤—ã
        for k in ("allow_mix","shuffle","fixed","zip"):
            if k in a and not isinstance(a[k], bool):
                a[k] = str(a[k]).lower() in {"1","true","yes","on"}
        # —Ü–µ–ª—ã–µ
        for k in ("n","per","limit","seed"):
            if k in a and a[k] is not None and not isinstance(a[k], int):
                try: a[k] = int(float(a[k]))
                except: a.pop(k, None)
        # —á–∏—Å–ª–∞ —Å –ø–ª–∞–≤–∞—é—â–µ–π —Ç–æ—á–∫–æ–π
        for k in ("lat","lon","radius_km","value_km"):
            if k in a and a[k] is not None and not isinstance(a[k], (int,float)):
                try: a[k] = float(a[k])
                except: a.pop(k, None)
        return a

    if not isinstance(plan, dict):
        plan = {"intent": "unknown", "args": {}}

    intent_raw = plan.get("intent") or plan.get("action") or "unknown"
    if isinstance(plan.get("args"), dict):
        args = plan["args"]
    else:
        # ¬´–ø–ª–æ—Å–∫–∏–π¬ª –æ—Ç–≤–µ—Ç ‚Äî —Å–æ–±–µ—Ä—ë–º –∏–∑–≤–µ—Å—Ç–Ω—ã–µ –∫–ª—é—á–∏
        args = {k: plan.get(k) for k in KNOWN_KEYS if k in plan}
    args = _coerce_args(args)
    plan = {"intent": intent_raw, "args": args}

    if dbg:
        try:
            pretty = json.dumps(plan, ensure_ascii=False, indent=2)
        except Exception:
            pretty = str(plan)
        await m.answer(f"LLM –ø–ª–∞–Ω:\n```json\n{pretty}\n```", parse_mode="Markdown")

    intent = plan["intent"]
    args   = plan["args"]

    # ---------- 2) –ò—Å–ø–æ–ª–Ω–µ–Ω–∏–µ –ø–æ intent ----------

    # ===== pick_any ‚Äî –≤—Å—è —Å—Ç—Ä–∞–Ω–∞, –±–µ–∑ –≥–æ—Ä–æ–¥–∞ =====
    if intent == "pick_any":
        if SCREENS is None or SCREENS.empty:
            await m.answer("–°–Ω–∞—á–∞–ª–∞ –∑–∞–≥—Ä—É–∑–∏—Ç–µ –∏–Ω–≤–µ–Ω—Ç–∞—Ä—å: /sync_api –∏–ª–∏ –ø—Ä–∏—à–ª–∏—Ç–µ CSV/XLSX.")
            return
        try:
            call_args = {
                "n":        int(args.get("n") or 20),
                "formats":  args.get("formats") or [],
                "owners":   args.get("owners")  or [],
                "fields":   args.get("fields")  or [],
                "allow_mix":bool(args.get("allow_mix") or False),
                "shuffle":  bool(args.get("shuffle")   or False),
                "fixed":    bool(args.get("fixed")     or False),
                "seed":     args.get("seed"),
                # "mix":   args.get("mix"),  # –µ—Å–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–µ—à—å –∫–≤–æ—Ç—ã —Ñ–æ—Ä–º–∞—Ç–æ–≤
            }
        except Exception:
            await m.answer("–ù–µ –ø–æ–Ω—è–ª –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –æ—Ç–±–æ—Ä–∞ –ø–æ —Å—Ç—Ä–∞–Ω–µ. –ü—Ä–∏–º–µ—Ä: ¬´–ø–æ–¥–±–µ—Ä–∏ 120 MEDIA_FACADE –ø–æ –≤—Å–µ–π —Å—Ç—Ä–∞–Ω–µ fixed seed=7¬ª.")
            return

        await pick_any(m, _call_args=call_args)
        return

     # pick_city
    if intent == "pick_city":
        if SCREENS is None or SCREENS.empty:
            await m.answer("–°–Ω–∞—á–∞–ª–∞ –∑–∞–≥—Ä—É–∑–∏—Ç–µ –∏–Ω–≤–µ–Ω—Ç–∞—Ä—å: –ø—Ä–∏—à–ª–∏—Ç–µ CSV/XLSX.")
            return

        city = (args.get("city") or "").strip()
        n    = int(args.get("n") or 20)

        fmts: list[str]   = args.get("formats") or []
        owners: list[str] = args.get("owners")  or []
        fields: list[str] = args.get("fields")  or []

    # –∞–∫–∫—É—Ä–∞—Ç–Ω–æ —Å–æ–±–∏—Ä–∞–µ–º echo-–∫–æ–º–∞–Ω–¥—É
        parts = ["/pick_city", f"city={city}", f"n={n}"]
        if fmts:
            parts.append("formats=" + ",".join(fmts))   # <-- –í–ê–ñ–ù–û: join —Å–ø–∏—Å–∫–∞, –∞ –Ω–µ –æ–¥–∏–Ω —ç–ª–µ–º–µ–Ω—Ç
        if owners:
            parts.append("owner=" + ",".join(owners))
        if args.get("shuffle"):
            parts.append("shuffle=1")
        if args.get("fixed"):
            parts.append("fixed=1")
        if args.get("seed") is not None:
            parts.append(f"seed={int(args['seed'])}")

        await m.answer("–°–¥–µ–ª–∞—é —Ç–∞–∫: " + " ".join(parts))

    # –ø–µ—Ä–µ–¥–∞—ë–º —Å–ø–∏—Å–æ–∫ —Ñ–æ—Ä–º–∞—Ç–æ–≤ –∫–∞–∫ –µ—Å—Ç—å
        call_args = {
            "city":    city,
            "n":       n,
            "formats": fmts,          # <-- —Å–ø–∏—Å–æ–∫
            "owners":  owners,
            "fields":  fields,
            "shuffle": bool(args.get("shuffle") or False),
            "fixed":   bool(args.get("fixed") or False),
            "seed":    args.get("seed"),
        }
        await pick_city(m, _call_args=call_args)
        return

    # ===== near ‚Äî –∫—Ä—É–≥ –≤–æ–∫—Ä—É–≥ —Ç–æ—á–∫–∏ (–±–µ–∑ —Ä–∞–≤–Ω–æ–º–µ—Ä–Ω–æ–≥–æ –ø–æ–¥–±–æ—Ä–∞) =====
    if intent == "near":
        if SCREENS is None or SCREENS.empty:
            await m.answer("–°–Ω–∞—á–∞–ª–∞ –∑–∞–≥—Ä—É–∑–∏—Ç–µ –∏–Ω–≤–µ–Ω—Ç–∞—Ä—å: /sync_api –∏–ª–∏ –ø—Ä–∏—à–ª–∏—Ç–µ CSV/XLSX.")
            return
        try:
            lat = float(args["lat"]); lon = float(args["lon"])
        except Exception:
            await m.answer("–ù–µ –ø–æ–Ω—è–ª –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã. –ü—Ä–∏–º–µ—Ä: ¬´—ç–∫—Ä–∞–Ω—ã –≤ —Ä–∞–¥–∏—É—Å–µ 3 –∫–º –æ—Ç 55.75 37.62¬ª.")
            return
        call_args = {
            "lat": lat,
            "lon": lon,
            "radius_km": float(args.get("radius_km") or 2),
            "formats": args.get("formats") or [],
            "owners":  args.get("owners")  or [],
            "fields":  args.get("fields")  or [],
        }
        await cmd_near(m, _call_args=call_args)
        return

    # ===== pick_at ‚Äî —Ä–∞–≤–Ω–æ–º–µ—Ä–Ω–æ –≤ —Ä–∞–¥–∏—É—Å–µ –≤–æ–∫—Ä—É–≥ —Ç–æ—á–∫–∏ =====
    if intent == "pick_at":
        try:
            call_args = {
                "lat": float(args["lat"]),
                "lon": float(args["lon"]),
                "n":   int(args.get("n") or 20),
                "radius_km": float(args.get("radius_km") or 10),
                "formats": args.get("formats") or [],
                "owners":  args.get("owners")  or [],
                "fields":  args.get("fields")  or [],
                "shuffle": bool(args.get("shuffle") or False),
                "fixed":   bool(args.get("fixed")   or False),
                "seed":    args.get("seed"),
                # "mix":  args.get("mix"),
            }
        except Exception:
            await m.answer("–ù–µ –ø–æ–Ω—è–ª –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è —Ä–∞–≤–Ω–æ–º–µ—Ä–Ω–æ–≥–æ –ø–æ–¥–±–æ—Ä–∞. –ü—Ä–∏–º–µ—Ä: ¬´–ø–æ–¥–±–µ—Ä–∏ 15 —ç–∫—Ä–∞–Ω–æ–≤ —Ä–∞–≤–Ω–æ–º–µ—Ä–Ω–æ –≤–æ–∫—Ä—É–≥ 55.75 37.62 —Ä–∞–¥–∏—É—Å 12 –∫–º¬ª.")
            return
        await pick_at(m, _call_args=call_args)
        return

    # ===== sync_api ‚Äî –ø–æ–∫–∞ —Ç–æ–ª—å–∫–æ –ø–æ–¥—Å–∫–∞–∑–∫–∞ —è–≤–Ω–æ–π –∫–æ–º–∞–Ω–¥—ã =====
    if intent == "sync_api":
        city    = (args.get("city") or "").strip()
        formats = args.get("formats") or []
        owners  = args.get("owners")  or []
        kv = []
        if city:    kv.append(f"city={city}")
        if formats: kv.append("format=" + ",".join(formats))
        if owners:  kv.append("owner=" + ",".join(owners))
        await m.answer("–°–¥–µ–ª–∞—é —Ç–∞–∫: " + " ".join(["/sync_api"] + kv))
        return

    # ===== shots ‚Äî –ø–æ–¥—Å–∫–∞–∑–∫–∞ —è–≤–Ω–æ–π –∫–æ–º–∞–Ω–¥—ã =====
    if intent == "shots":
        cid   = args.get("campaign")
        per   = args.get("per")
        limit = args.get("limit")
        z     = args.get("zip")
        fields= args.get("fields") or []
        if not cid:
            await m.answer("–£–∫–∞–∂–∏—Ç–µ –Ω–æ–º–µ—Ä –∫–∞–º–ø–∞–Ω–∏–∏. –ù–∞–ø—Ä–∏–º–µ—Ä: ¬´—Ñ–æ—Ç–æ–æ—Ç—á—ë—Ç—ã –ø–æ –∫–∞–º–ø–∞–Ω–∏–∏ 4791, –ø–æ 1 –∫–∞–¥—Ä—É –Ω–∞ —Å–≤—è–∑–∫—É¬ª.")
            return
        kv = [f"campaign={cid}"]
        if isinstance(per,(int,float)) and per>=0: kv.append(f"per={int(per)}")
        if isinstance(limit,int) and limit>0:      kv.append(f"limit={limit}")
        if z:                                      kv.append("zip=1")
        if fields:                                 kv.append("fields=" + ",".join(fields))
        await m.answer("–í—ã–ø–æ–ª–Ω—é —Ç–∞–∫: /shots " + " ".join(kv))
        return

    # ===== export_last =====
    if intent == "export_last":
        await export_last(m)
        return

    # ===== status =====
    if intent == "status":
        if SCREENS is None or SCREENS.empty:
            await m.answer("–≠–∫—Ä–∞–Ω–æ–≤ –µ—â—ë –Ω–µ—Ç ‚Äî /sync_api –∏–ª–∏ –∑–∞–≥—Ä—É–∑–∏—Ç–µ CSV/XLSX.")
        else:
            await m.answer(f"–≠–∫—Ä–∞–Ω–æ–≤ –∑–∞–≥—Ä—É–∂–µ–Ω–æ: {len(SCREENS)}. –ü–æ—Å–ª–µ–¥–Ω–∏–π –∫—ç—à: {LAST_SYNC_TS or '‚Äî'}.")
        return

    # ===== radius =====
    if intent == "radius":
        val = args.get("value_km")
        try:
            r = float(val)
        except Exception:
            await m.answer("–ù–µ –ø–æ–Ω—è–ª —Ä–∞–¥–∏—É—Å. –ü—Ä–∏–º–µ—Ä: ¬´—Ä–∞–¥–∏—É—Å –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 2 –∫–º¬ª.")
            return
        await m.answer(f"–û–∫, –ø–æ—Å—Ç–∞–≤–ª—é —Ä–∞–¥–∏—É—Å –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: /radius {r:g}")
        return

    # ===== help / fallback =====
    if intent == "help":
        await m.answer(HELP)
        return

    await m.answer("–Ø –Ω–µ –¥–æ –∫–æ–Ω—Ü–∞ –ø–æ–Ω—è–ª –∑–∞–ø—Ä–æ—Å. –ü—Ä–∏–º–µ—Ä: ¬´—Å–æ–±–µ—Ä–∏ 20 –±–∏–ª–±–æ—Ä–¥–æ–≤ –ø–æ –í–æ—Ä–æ–Ω–µ–∂—É —Ä–∞–≤–Ω–æ–º–µ—Ä–Ω–æ¬ª.")

from aiogram import F


# ================== NLU helpers (plan + pick_city) ==================
import re

# –ê–ª–∏–∞—Å—ã –≥–æ—Ä–æ–¥–æ–≤ ‚Üí –∫–∞–Ω–æ–Ω
_CITY_ALIASES = {
    "—Å–ø–±":"–°–∞–Ω–∫—Ç-–ü–µ—Ç–µ—Ä–±—É—Ä–≥","–ø–∏—Ç–µ—Ä":"–°–∞–Ω–∫—Ç-–ü–µ—Ç–µ—Ä–±—É—Ä–≥",
    "—Å–∞–Ω–∫—Ç-–ø–µ—Ç–µ—Ä–±—É—Ä–≥":"–°–∞–Ω–∫—Ç-–ü–µ—Ç–µ—Ä–±—É—Ä–≥","—Å–∞–Ω–∫—Ç –ø–µ—Ç–µ—Ä–±—É—Ä–≥":"–°–∞–Ω–∫—Ç-–ü–µ—Ç–µ—Ä–±—É—Ä–≥","–ø–µ—Ç–µ—Ä–±—É—Ä–≥":"–°–∞–Ω–∫—Ç-–ü–µ—Ç–µ—Ä–±—É—Ä–≥",
    "–º—Å–∫":"–ú–æ—Å–∫–≤–∞","–º–æ—Å–∫–≤–∞":"–ú–æ—Å–∫–≤–∞",
    "–º–æ—Å–∫–≤–µ": "–ú–æ—Å–∫–≤–∞",
    "–µ–∫–±":"–ï–∫–∞—Ç–µ—Ä–∏–Ω–±—É—Ä–≥","–µ–∫–∞—Ç–µ—Ä–∏–Ω–±—É—Ä–≥":"–ï–∫–∞—Ç–µ—Ä–∏–Ω–±—É—Ä–≥",
    "–Ω–∏–∂–Ω–∏–π":"–ù–∏–∂–Ω–∏–π –ù–æ–≤–≥–æ—Ä–æ–¥","–Ω–∏–∂–Ω–∏–π –Ω–æ–≤–≥–æ—Ä–æ–¥":"–ù–∏–∂–Ω–∏–π –ù–æ–≤–≥–æ—Ä–æ–¥",
    "–≤–µ–ª–∏–∫–∏–π –Ω–æ–≤–≥–æ—Ä–æ–¥":"–í–µ–ª–∏–∫–∏–π –ù–æ–≤–≥–æ—Ä–æ–¥","–Ω–æ–≤–≥–æ—Ä–æ–¥":"–í–µ–ª–∏–∫–∏–π –ù–æ–≤–≥–æ—Ä–æ–¥",
    "—Ä–æ—Å—Ç–æ–≤":"–†–æ—Å—Ç–æ–≤-–Ω–∞-–î–æ–Ω—É","—Ä–æ—Å—Ç–æ–≤-–Ω–∞-–¥–æ–Ω—É":"–†–æ—Å—Ç–æ–≤-–Ω–∞-–î–æ–Ω—É",
    "–∫–∞–∑–∞–Ω—å":"–ö–∞–∑–∞–Ω—å","—Å–∞–º–∞—Ä–∞":"–°–∞–º–∞—Ä–∞","–ø–µ—Ä–º—å":"–ü–µ—Ä–º—å","–≤–æ—Ä–æ–Ω–µ–∂":"–í–æ—Ä–æ–Ω–µ–∂",
}

# –ê–ª–∏–∞—Å—ã —Ñ–æ—Ä–º–∞—Ç–æ–≤ ‚Üí –∫–∞–Ω–æ–Ω
_FMT_ALIASES = {
    "–±–∏–ª–±–æ—Ä–¥":"BILLBOARD","–±–∏–ª–±–æ—Ä–¥—ã":"BILLBOARD",
    "—Å–∏—Ç–∏–±–æ—Ä–¥":"CITYBOARD","—Å–∏—Ç–∏–±–æ—Ä–¥—ã":"CITYBOARD",
    "—Å–∏—Ç–∏—Ñ–æ—Ä–º–∞—Ç":"CITYFORMAT","cityformat":"CITYFORMAT","city_format":"CITYFORMAT",
    "–º–µ–¥–∏–∞—Ñ–∞—Å–∞–¥":"MEDIA_FACADE","–º–µ–¥–∏–∞—Ñ–∞—Å–∞–¥—ã":"MEDIA_FACADE",
    "—Å—É–ø–µ—Ä—Å–∞–π—Ç":"SUPERSITE","—Å—É–ø–µ—Ä—Å–∞–π—Ç—ã":"SUPERSITE","—Å—É–ø–µ—Ä—Å–∞–π—Ç–æ–≤":"SUPERSITE",
    "billboard":"BILLBOARD","cityboard":"CITYBOARD","mediafacade":"MEDIA_FACADE","supersite":"SUPERSITE",
}

_WEEK_HINTS = ("–Ω–∞ –Ω–µ–¥–µ–ª—é", "–Ω–µ–¥–µ–ª—é", "–Ω–µ–¥–µ–ª–∏", "–Ω–µ–¥–µ–ª—è")

def _nrm(s: str) -> str:
    return (s or "").strip().lower().replace("—ë","–µ")

def _ru_stem_token(tok: str) -> str:
    t = _nrm(tok).replace(" –Ω–∞ –¥–æ–Ω—É", " –Ω–∞-–¥–æ–Ω—É")
    for suf in ("–∞–º–∏","—è–º–∏","–æ–≤","–µ–≤","–µ–π","–∞–º","—è–º","–∞—Ö","—è—Ö","–æ—é","–µ—é",
                "—ã–º","–∏–º","–æ–º","–µ–º","–æ–π","–µ–π","–∞—è","–æ–µ","—ã–µ","–∏–π","—ã–π",
                "—É","–µ","–∞","–æ","—ã","–∏","—å"):
        if t.endswith(suf) and len(t) - len(suf) >= 3:
            t = t[: -len(suf)]
            break
    return t

def _find_cities(text: str) -> list[str]:
    t = _nrm(text)
    tokens = re.findall(r"[a-z–∞-—è\-]+", t, flags=re.IGNORECASE)
    grams  = set(tokens)
    grams.update(" ".join(tokens[i:i+2]) for i in range(len(tokens)-1))
    city_stem_map = { _ru_stem_token(k): v for k, v in _CITY_ALIASES.items() }
    cities = []
    for g in grams:
        gs = _ru_stem_token(g)
        if gs in city_stem_map:
            canon = city_stem_map[gs]
            if canon not in cities:
                cities.append(canon)
    return cities

def _find_format(text: str) -> str | None:
    t = _nrm(text)
    tokens = re.findall(r"[a-z–∞-—è\-]+", t, flags=re.IGNORECASE)
    grams  = set(tokens)
    grams.update(" ".join(tokens[i:i+2]) for i in range(len(tokens)-1))
    fmt_stem_map = { _ru_stem_token(k): v for k, v in _FMT_ALIASES.items() }
    for g in grams:
        gs = _ru_stem_token(g)
        if gs in fmt_stem_map:
            return fmt_stem_map[gs]
    return None

def _extract_days_hours(text: str) -> tuple[int|None, int|None]:
    t = _nrm(text)
    days = 7 if any(h in t for h in _WEEK_HINTS) else None
    m_days = re.search(r"(\d+)\s*(?:–¥–Ω|–¥–Ω—è|–¥–Ω–µ–π)\b", t)
    if m_days:
        try: days = int(m_days.group(1))
        except: pass
    if days is None and "–º–µ—Å—è—Ü" in t:
        days = 30
    hours = None
    m_hours = re.search(r"(\d+)\s*—á–∞—Å", t)
    if m_hours:
        try: hours = int(m_hours.group(1))
        except: pass
    return days, hours

def _extract_n(text: str) -> int|None:
    t = _nrm(text)
    m = re.search(r"\b(\d+)\s*(?:—ç–∫—Ä–∞–Ω|—ç–∫—Ä–∞–Ω–∞|—ç–∫—Ä–∞–Ω–æ–≤)\b", t)
    if m:
        try:
            n = int(m.group(1))
            return n if n > 0 else None
        except:
            return None
    # —Ä–∞–∑—Ä–µ—à–∏–º ¬´—Å–æ–±–µ—Ä–∏ 20 –±–∏–ª–±–æ—Ä–¥–æ–≤¬ª
    m2 = re.search(r"\b(\d+)\s*(?:–±–∏–ª–±–æ—Ä–¥|–±–∏–ª–±–æ—Ä–¥–∞|–±–∏–ª–±–æ—Ä–¥–æ–≤|—Å–∏—Ç–∏–±–æ—Ä–¥\w*|–º–µ–¥–∏–∞—Ñ–∞—Å–∞–¥\w*|—Å—É–ø–µ—Ä—Å–∞–π—Ç\w*)\b", t)
    if m2:
        try:
            n = int(m2.group(1))
            return n if n > 0 else None
        except:
            return None
    return None

def parse_plan_nl(text: str) -> dict:
    """
    –ü–ª–∞–Ω: {cities, format, days, hours} –µ—Å–ª–∏ —è–≤–Ω–æ –ø—Ä–æ—Å–∏–ª–∏ –ø–µ—Ä–∏–æ–¥/—á–∞—Å—ã –∏–ª–∏ ¬´–ø–ª–∞–Ω¬ª.
    """
    t = _nrm(text)
    cities = _find_cities(t)
    fmt = _find_format(t)
    days, hours = _extract_days_hours(t)
    if "–ø–ª–∞–Ω" in t or days is not None or hours is not None:
        return {"cities": cities, "format": fmt, "days": days, "hours": hours}
    # –∏–Ω–∞—á–µ ‚Äî —ç—Ç–æ –Ω–µ –ø–ª–∞–Ω–æ–≤–∞—è —Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∫–∞
    return {"cities": [], "format": None, "days": None, "hours": None}

# ====== –ù–û–†–ú–ê–õ–ò–ó–ê–¶–ò–Ø –ì–û–†–û–î–û–í/–§–û–†–ú–ê–¢–û–í –î–õ–Ø "–ø–æ–¥–±–µ—Ä–∏ N ..." ======
import re
from typing import Dict, Any, List

_CITY_ALIASES = {
    # –ú–æ—Å–∫–≤–∞
    "–º–æ—Å–∫–≤–µ": "–ú–æ—Å–∫–≤–∞", "–º–æ—Å–∫–≤—ã": "–ú–æ—Å–∫–≤–∞", "–º–æ—Å–∫–æ–≤": "–ú–æ—Å–∫–≤–∞",
    "–º–æ—Å–∫–≤–∞": "–ú–æ—Å–∫–≤–∞",
    # –°–∞–Ω–∫—Ç-–ü–µ—Ç–µ—Ä–±—É—Ä–≥
    "–ø–µ—Ç–µ—Ä–±—É—Ä–≥—É": "–°–∞–Ω–∫—Ç-–ü–µ—Ç–µ—Ä–±—É—Ä–≥", "–ø–µ—Ç–µ—Ä–±—É—Ä–≥–∞": "–°–∞–Ω–∫—Ç-–ü–µ—Ç–µ—Ä–±—É—Ä–≥",
    "–ø–µ—Ç–µ—Ä–±—É—Ä–≥": "–°–∞–Ω–∫—Ç-–ü–µ—Ç–µ—Ä–±—É—Ä–≥", "—Å–ø–±": "–°–∞–Ω–∫—Ç-–ü–µ—Ç–µ—Ä–±—É—Ä–≥",
    "—Å–∞–Ω–∫—Ç-–ø–µ—Ç–µ—Ä–±—É—Ä–≥": "–°–∞–Ω–∫—Ç-–ü–µ—Ç–µ—Ä–±—É—Ä–≥", "—Å–∞–Ω–∫—Ç –ø–µ—Ç–µ—Ä–±—É—Ä–≥": "–°–∞–Ω–∫—Ç-–ü–µ—Ç–µ—Ä–±—É—Ä–≥",
    # –ß–∞—Å—Ç—ã–µ –≥–æ—Ä–æ–¥–∞ (–¥–æ–±–∞–≤–ª—è–π –ø–æ –º–µ—Ä–µ –Ω–∞–¥–æ–±–Ω–æ—Å—Ç–∏)
    "–∫–∞–∑–∞–Ω–∏": "–ö–∞–∑–∞–Ω—å", "–∫–∞–∑–∞–Ω—å": "–ö–∞–∑–∞–Ω—å",
    "—Ä–æ—Å—Ç–æ–≤—É": "–†–æ—Å—Ç–æ–≤-–Ω–∞-–î–æ–Ω—É", "—Ä–æ—Å—Ç–æ–≤–∞": "–†–æ—Å—Ç–æ–≤-–Ω–∞-–î–æ–Ω—É",
    "—Ä–æ—Å—Ç–æ–≤-–Ω–∞-–¥–æ–Ω—É": "–†–æ—Å—Ç–æ–≤-–Ω–∞-–î–æ–Ω—É", "—Ä–æ—Å—Ç–æ–≤ –Ω–∞ –¥–æ–Ω—É": "–†–æ—Å—Ç–æ–≤-–Ω–∞-–î–æ–Ω—É",
    "–Ω–∏–∂–Ω–µ–º—É –Ω–æ–≤–≥–æ—Ä–æ–¥—É": "–ù–∏–∂–Ω–∏–π –ù–æ–≤–≥–æ—Ä–æ–¥", "–Ω–∏–∂–Ω–µ–≥–æ –Ω–æ–≤–≥–æ—Ä–æ–¥–∞": "–ù–∏–∂–Ω–∏–π –ù–æ–≤–≥–æ—Ä–æ–¥",
    "–Ω–∏–∂–Ω–∏–π –Ω–æ–≤–≥–æ—Ä–æ–¥": "–ù–∏–∂–Ω–∏–π –ù–æ–≤–≥–æ—Ä–æ–¥",
}

_FORMAT_KEYWORDS = {
    "BILLBOARD":  [r"\b–±–∏–ª–±–æ—Ä–¥\w*\b", r"\b—â–∏—Ç\w*\b"],
    "SUPERSITE":  [r"\b—Å—É–ø–µ—Ä—Å–∞–π—Ç\w*\b", r"\b—Å—É–ø–µ—Ä–±–æ—Ä–¥\w*\b"],
    # –ø—Ä–∏ –∂–µ–ª–∞–Ω–∏–∏ –¥–æ–±–∞–≤—å: CITYBOARD, MEDIAFACADE, DIGITAL –∏ —Ç.–¥.
}

_CITY_RX = re.compile(
    r"""(?:
            \b–ø–æ(?:\s+–≥–æ—Ä–æ–¥—É)?\s+|
            \b–≤(?:\s+–≥–æ—Ä–æ–¥–µ)?\s+|
            \b–¥–ª—è\s+
        )
        (?P<city>[A-Za-z–ê-–Ø–∞-—è–Å—ë\-\s]+)
    """,
    re.IGNORECASE | re.VERBOSE
)

def _canon_city(raw: str) -> str | None:
    s = (raw or "").strip().lower().replace("—ë", "–µ")
    s = re.sub(r"\s+", " ", s)
    if s in _CITY_ALIASES:
        return _CITY_ALIASES[s]
    # –¥–ª—è —Å–æ—Å—Ç–∞–≤–Ω—ã—Ö –Ω–∞–∑–≤–∞–Ω–∏–π –ø–æ–ø—Ä–æ–±—É–µ–º —Ç–æ—á–Ω–æ–µ —Ç–∞–π—Ç–ª-–∫–µ–π—Å
    s_t = " ".join(w.capitalize() for w in s.split())
    # –±—ã—Å—Ç—Ä—ã–µ —ç–≤—Ä–∏—Å—Ç–∏–∫–∏: –ú–æ—Å–∫–≤–∞ / –°–∞–Ω–∫—Ç-–ü–µ—Ç–µ—Ä–±—É—Ä–≥
    if s_t in ("–ú–æ—Å–∫–≤–∞", "–°–∞–Ω–∫—Ç-–ø–µ—Ç–µ—Ä–±—É—Ä–≥", "–°–∞–Ω–∫—Ç-–ü–µ—Ç–µ—Ä–±—É—Ä–≥"):
        return "–ú–æ—Å–∫–≤–∞" if s_t == "–ú–æ—Å–∫–≤–∞" else "–°–∞–Ω–∫—Ç-–ü–µ—Ç–µ—Ä–±—É—Ä–≥"
    return s_t if len(s_t) >= 2 else None

def _extract_formats(text: str) -> List[str]:
    found = []
    for fmt, pats in _FORMAT_KEYWORDS.items():
        for p in pats:
            if re.search(p, text, flags=re.IGNORECASE):
                found.append(fmt); break
    return list(dict.fromkeys(found))  # —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ, –≤ –ø–æ—Ä—è–¥–∫–µ –Ω–∞—Ö–æ–¥–∫–∏


# ================== /ask + helpers (clean) ==================
import re
from aiogram import types
from aiogram.filters import Command

# ---- –ê–ª–∏–∞—Å—ã –≥–æ—Ä–æ–¥–æ–≤ (—Ä–µ–≥–µ–∫—Å—ã ‚Üí –∫–∞–Ω–æ–Ω–∏—á–µ—Å–∫–æ–µ –∏–º—è) ----
_CITY_ALIASES = {
    r"\b(—Å–ø–±|–ø–∏—Ç–µ—Ä|—Å–∞–Ω–∫—Ç[-\s]?–ø–µ—Ç–µ—Ä–±—É—Ä–≥\w*|–ø–µ—Ç–µ—Ä–±—É—Ä–≥\w*)\b": "–°–∞–Ω–∫—Ç-–ü–µ—Ç–µ—Ä–±—É—Ä–≥",
    r"\b(–º—Å–∫|–º–æ—Å–∫–≤–∞\w*)\b": "–ú–æ—Å–∫–≤–∞",
    r"\b(–µ–∫–±|–µ–∫–∞—Ç–µ—Ä–∏–Ω–±—É—Ä–≥\w*)\b": "–ï–∫–∞—Ç–µ—Ä–∏–Ω–±—É—Ä–≥",
    r"\b(–∫–∞–∑–∞–Ω—å\w*)\b": "–ö–∞–∑–∞–Ω—å",
    r"\b(—Ä–æ—Å—Ç–æ–≤(?:-–Ω–∞-–¥–æ–Ω—É)?\w*|—Ä–æ—Å—Ç–æ–≤–µ?\w*)\b": "–†–æ—Å—Ç–æ–≤-–Ω–∞-–î–æ–Ω—É",
    r"\b(–Ω–∏–∂–Ω–∏–π\s+–Ω–æ–≤–≥–æ—Ä–æ–¥\w*|–Ω–∏–∂–Ω–∏–π\w*)\b": "–ù–∏–∂–Ω–∏–π –ù–æ–≤–≥–æ—Ä–æ–¥",
    r"\b(–≤–µ–ª–∏–∫–∏–π\s+–Ω–æ–≤–≥–æ—Ä–æ–¥\w*|–Ω–æ–≤–≥–æ—Ä–æ–¥\w*)\b": "–í–µ–ª–∏–∫–∏–π –ù–æ–≤–≥–æ—Ä–æ–¥",
    r"\b(—Å–∞–º–∞—Ä–∞\w*)\b": "–°–∞–º–∞—Ä–∞",
    r"\b(–ø–µ—Ä–º—å\w*)\b": "–ü–µ—Ä–º—å",
    r"\b(–≤–æ—Ä–æ–Ω–µ–∂\w*)\b": "–í–æ—Ä–æ–Ω–µ–∂",
}

# ---- –î–æ–ø. —Å–ª–æ–≤–∞—Ä—å —Ñ–æ—Ä–º–∞—Ç–æ–≤ (–∞–ª–∏–∞—Å—ã ‚Üí –∫–∞–Ω–æ–Ω) ----
_FMT_ALIASES_LOCAL = {
    "–±–∏–ª–±–æ—Ä–¥": "BILLBOARD", "–±–∏–ª–±–æ—Ä–¥—ã": "BILLBOARD", "billboard": "BILLBOARD",
    "—Å—É–ø–µ—Ä—Å–∞–π—Ç": "SUPERSITE", "—Å—É–ø–µ—Ä—Å–∞–π—Ç—ã": "SUPERSITE", "supersite": "SUPERSITE",
    "—Å–∏—Ç–∏–±–æ—Ä–¥": "CITYBOARD", "—Å–∏—Ç–∏–±–æ—Ä–¥—ã": "CITYBOARD", "cityboard": "CITYBOARD",
    "—Å–∏—Ç–∏—Ñ–æ—Ä–º–∞—Ç": "CITYFORMAT", "city format": "CITYFORMAT", "cityformat": "CITYFORMAT",
    "–º–µ–¥–∏–∞—Ñ–∞—Å–∞–¥": "MEDIA_FACADE", "–º–µ–¥–∏–∞ —Ñ–∞—Å–∞–¥": "MEDIA_FACADE", "mediafacade": "MEDIA_FACADE", "media facade": "MEDIA_FACADE",
}

# ---- –°—Ç–µ–º-–ø–∞—Ç—Ç–µ—Ä–Ω—ã –¥–ª—è —Ñ–æ—Ä–º–∞—Ç–æ–≤ (–ª–æ–≤—è—Ç –ø–∞–¥–µ–∂–∏/–≤–∞—Ä–∏–∞—Ü–∏–∏) ----
_FORMAT_STEMS = (
    (r"\b–±–∏–ª–±–æ—Ä–¥\w*\b",        "BILLBOARD"),
    (r"\bbillboard\w*\b",      "BILLBOARD"),
    (r"\b—Å—É–ø–µ—Ä—Å–∞–π—Ç\w*\b",      "SUPERSITE"),
    (r"\bsupersite\w*\b",      "SUPERSITE"),
    (r"\b—Å–∏—Ç–∏–±–æ—Ä–¥\w*\b",       "CITYBOARD"),
    (r"\bcityboard\w*\b",      "CITYBOARD"),
    (r"\b—Å–∏—Ç–∏\s*—Ñ–æ—Ä–º–∞—Ç\w*\b",  "CITYFORMAT"),
    (r"\b—Å–∏—Ç–∏—Ñ–æ—Ä–º–∞—Ç\w*\b",     "CITYFORMAT"),
    (r"\bcity\s*format\w*\b",  "CITYFORMAT"),
    (r"\bcityformat\w*\b",     "CITYFORMAT"),
    (r"\b–º–µ–¥–∏–∞\s*—Ñ–∞—Å–∞–¥\w*\b",  "MEDIA_FACADE"),
    (r"\b–º–µ–¥–∏–∞—Ñ–∞—Å–∞–¥\w*\b",     "MEDIA_FACADE"),
    (r"\bmedia\s*facade\w*\b", "MEDIA_FACADE"),
    (r"\bmediafacade\w*\b",    "MEDIA_FACADE"),
)

def _nrm(s: str) -> str:
    return (s or "").strip().lower().replace("—ë", "–µ")

def _merge_city_aliases() -> dict:
    # –ø—Ä–∏ –Ω–∞–ª–∏—á–∏–∏ –≥–ª–æ–±–∞–ª—å–Ω–æ–≥–æ _CITY_ALIASES ¬´—Å–ª–∏–≤–∞–µ–º¬ª
    base = {}
    try:
        if isinstance(globals().get("_CITY_ALIASES"), dict):
            base.update(globals()["_CITY_ALIASES"])
    except Exception:
        pass
    # –≥–ª–æ–±–∞–ª—å–Ω—ã–µ –∑–¥–µ—Å—å ‚Äî –≤ —Ñ–æ—Ä–º–∞—Ç–µ {regex: canon}; –Ω–∞—à–∏ ‚Äî —Ç–æ–∂–µ —Ä–µ–≥–µ–∫—Å—ã, –∫–æ–Ω—Ñ–ª–∏–∫—Ç–æ–≤ –Ω–µ –±—É–¥–µ—Ç
    base.update(_CITY_ALIASES)
    return base

def _merge_fmt_aliases() -> dict:
    base = {}
    try:
        if isinstance(globals().get("_FMT_ALIASES"), dict):
            base.update({k.lower(): v for k, v in globals()["_FMT_ALIASES"].items()})
    except Exception:
        pass
    base.update(_FMT_ALIASES_LOCAL)
    return base

CITY_MAP_RE = _merge_city_aliases()
FMT_MAP = _merge_fmt_aliases()  # –∞–ª–∏–∞—Å—ã ‚Üí –∫–∞–Ω–æ–Ω

def extract_city(text: str) -> str | None:
    t = _nrm(text)
    # 1) —Ä–µ–≥–µ–∫—Å—ã-–∞–ª–∏–∞—Å—ã
    for pat, canon in CITY_MAP_RE.items():
        if re.search(pat, t, flags=re.IGNORECASE):
            return canon
    # 2) –∫–æ–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏ ¬´–≤/–ø–æ <–≥–æ—Ä–æ–¥>¬ª
    def _stem_ru(word: str) -> str:
        w = word
        for suf in ("—É","—é","–µ","–∞","—ã","–æ–π","–æ–º","–∞—Ö","—è—Ö","–∞–º","—è–º","–∏—é","—å—é"):
            if w.endswith(suf) and len(w) - len(suf) >= 3:
                w = w[:-len(suf)]
                break
        return w
    m = re.search(r"\b(?:–≤|–ø–æ)\s+([–∞-—èa-z\-\s\.]+?)(?=[\s,.;!?]|$)", t)
    if m:
        cand = _stem_ru(m.group(1).strip(" .,-"))
        for pat, canon in CITY_MAP_RE.items():
            if re.search(pat, cand, flags=re.IGNORECASE):
                return canon
    return None

def extract_formats(text: str) -> list[str]:
    t = _nrm(text)
    out, seen = [], set()
    # 1) —Å—Ç–µ–º-–ø–∞—Ç—Ç–µ—Ä–Ω—ã
    for pat, code in _FORMAT_STEMS:
        if re.search(pat, t, flags=re.IGNORECASE) and code not in seen:
            out.append(code); seen.add(code)
    # 2) –∞–ª–∏–∞—Å—ã-—Å–ª–æ–≤–∞
    # —Ä–∞–∑–Ω–µ—Å—ë–º –ø–æ —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—è–º (–∏/–∑–∞–ø—è—Ç—ã–µ/—Ç–æ—á–∫–∏ —Å –∑–∞–ø—è—Ç–æ–π)
    parts = re.split(r"[,\s]+–∏\s+|[,;]\s*|\s+–∏\s+", t)
    for part in parts:
        key = part.strip()
        if key in FMT_MAP:
            code = FMT_MAP[key]
            if code not in seen:
                out.append(code); seen.add(code)
    # 3) –ø—Ä—è–º–æ–π –ø–æ–∏—Å–∫ –ø–æ —Å–ª–æ–≤–∞–º-–∞–ª–∏–∞—Å–∞–º (–±–µ–∑ —Ä–∞–∑–±–∏–µ–Ω–∏—è)
    for k, v in FMT_MAP.items():
        if re.search(rf"\b{re.escape(k)}\b", t) and v not in seen:
            out.append(v); seen.add(v)
    return out

def extract_number(text: str) -> int | None:
    t = _nrm(text)
    m = re.search(r"\b(?:–ø–æ–¥–±–µ—Ä–∏|—Å–æ–±–µ—Ä–∏|–≤—ã–±–µ—Ä–∏|–Ω–∞–π–¥–∏)\s+(\d{1,6})\b", t)
    if m:
        try: return int(m.group(1))
        except: pass
    m = re.search(r"\b(\d{1,6})\b\s+(?:—ç–∫—Ä–∞–Ω\w*|–±–∏–ª–±–æ—Ä–¥\w*|—Å—É–ø–µ—Ä—Å–∞–π—Ç\w*|—Å–∏—Ç–∏—Ñ–æ—Ä–º–∞—Ç\w*|—Å–∏—Ç–∏–±–æ—Ä–¥\w*)", t)
    if m:
        try: return int(m.group(1))
        except: pass
    return None

def has_even_hint(text: str) -> bool:
    t = _nrm(text)
    return any(h in t for h in ("—Ä–∞–≤–Ω–æ–º–µ—Ä–Ω–æ", "—Ä–∞–≤–Ω–æ–º–µ—Ä–Ω—ã–π", "—Ä–∞–≤–Ω–æ–º–µ—Ä–Ω–∞—è", "—Ä–∞–≤–Ω–æ–º–µ—Ä–Ω–æ–µ", "—Ä–∞–≤–Ω–æ–º–µ—Ä–Ω–æ –ø–æ"))

# --- —Ç–≤–æ–π —É–ø—Ä–æ—â—ë–Ω–Ω—ã–π –ø–∞—Ä—Å–µ—Ä –ø–ª–∞–Ω–∞ (–æ—Å—Ç–∞–≤–ª—è–µ–º —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å —Å _plan_core) ---
def parse_plan_nl(text: str) -> dict:
    t = _nrm(text)
    cities = []
    c = extract_city(t)
    if c: cities.append(c)
    fmts = extract_formats(t)
    fmt  = fmts[0] if fmts else None
    days = 7 if re.search(r"\b–Ω–∞\s+–Ω–µ–¥–µ–ª", t) else None
    m_days = re.search(r"(\d+)\s*(?:–¥–Ω|–¥–Ω—è|–¥–Ω–µ–π)", t)
    if m_days:
        try: days = int(m_days.group(1))
        except: pass
    if days is None and "–º–µ—Å—è—Ü" in t:
        days = 30
    hours = None
    m_hours = re.search(r"(\d+)\s*—á–∞—Å", t)
    if m_hours:
        try: hours = int(m_hours.group(1))
        except: pass
    return {"cities": cities, "format": fmt, "days": days, "hours": hours}

# --- –ø–∞—Ä—Å–µ—Ä ¬´–ø–æ–¥–±–æ—Ä –ø–æ –≥–æ—Ä–æ–¥—É¬ª ---
import re

# –ö–∞–Ω–æ–Ω–∏–∑–∞—Ü–∏—è –≥–æ—Ä–æ–¥–æ–≤ –∏ —Å–∏–Ω–æ–Ω–∏–º–æ–≤
CITY_ALIASES = {
    "–º—Å–∫": "–ú–æ—Å–∫–≤–∞", "–º–æ—Å–∫–≤–∞": "–ú–æ—Å–∫–≤–∞",
    "—Å–ø–±": "–°–∞–Ω–∫—Ç-–ü–µ—Ç–µ—Ä–±—É—Ä–≥", "–ø–∏—Ç–µ—Ä": "–°–∞–Ω–∫—Ç-–ü–µ—Ç–µ—Ä–±—É—Ä–≥",
    "—Å–∞–Ω–∫—Ç-–ø–µ—Ç–µ—Ä–±—É—Ä–≥": "–°–∞–Ω–∫—Ç-–ü–µ—Ç–µ—Ä–±—É—Ä–≥", "—Å–∞–Ω–∫—Ç –ø–µ—Ç–µ—Ä–±—É—Ä–≥": "–°–∞–Ω–∫—Ç-–ü–µ—Ç–µ—Ä–±—É—Ä–≥",
    "–∫–∞–∑–∞–Ω—å": "–ö–∞–∑–∞–Ω—å",
    # –ø—Ä–∏ –∂–µ–ª–∞–Ω–∏–∏ ‚Äî –¥–æ–ø–æ–ª–Ω–∏:
    "—Ä–æ—Å—Ç–æ–≤": "–†–æ—Å—Ç–æ–≤-–Ω–∞-–î–æ–Ω—É", "—Ä–æ—Å—Ç–æ–≤-–Ω–∞-–¥–æ–Ω—É": "–†–æ—Å—Ç–æ–≤-–Ω–∞-–î–æ–Ω—É",
    "–µ–∫–∞—Ç–µ—Ä–∏–Ω–±—É—Ä–≥": "–ï–∫–∞—Ç–µ—Ä–∏–Ω–±—É—Ä–≥", "–Ω–æ–≤–æ—Å–∏–±–∏—Ä—Å–∫": "–ù–æ–≤–æ—Å–∏–±–∏—Ä—Å–∫",
    "–Ω–∏–∂–Ω–∏–π –Ω–æ–≤–≥–æ—Ä–æ–¥": "–ù–∏–∂–Ω–∏–π –ù–æ–≤–≥–æ—Ä–æ–¥", "—Å–∞–º–∞—Ä–∞": "–°–∞–º–∞—Ä–∞",
}

KNOWN_CITIES = set(CITY_ALIASES.values()) | {
    "–í–æ—Ä–æ–Ω–µ–∂","–ü–µ—Ä–º—å","–í–æ–ª–≥–æ–≥—Ä–∞–¥","–ö—Ä–∞—Å–Ω–æ—è—Ä—Å–∫","–û–º—Å–∫","–£—Ñ–∞","–ß–µ–ª—è–±–∏–Ω—Å–∫"
}

# –°–ª–æ–≤–∞—Ä—å —Ä—É—Å—Å–∫–∏—Ö —Å–ª–æ–≤ —Ñ–æ—Ä–º–∞—Ç–æ–≤ -> –≤–Ω—É—Ç—Ä–µ–Ω–Ω–∏–µ –∫–æ–¥—ã
FORMAT_MAP = {
    r"–±–∏–ª–±–æ—Ä–¥\w*": "BILLBOARD",
    r"—Å—É–ø–µ—Ä—Å–∞–π—Ç\w*": "SUPERSITE",
    r"—Å–∏—Ç–∏–±–æ—Ä–¥\w*": "CITYBOARD",
    r"—Å–∏—Ç–∏-?–±–æ—Ä–¥\w*": "CITYBOARD",
    r"–º–µ–¥–∏–∞—Ñ–∞—Å–∞–¥\w*": "MEDIAFACADE",
    r"—ç–∫—Ä–∞(–Ω|–Ω—ã)\w*": "DIGITAL",
    r"digital|–¥–∏–¥–∂–∏—Ç–∞–ª": "DIGITAL",
}

EVEN_PAT = re.compile(r"—Ä–∞–≤–Ω–æ–º–µ—Ä–Ω", re.IGNORECASE)

def _norm_city(raw: str) -> str | None:
    s = re.sub(r"[^\w\s\-]+", " ", raw.lower()).strip()
    s = re.sub(r"\s+", " ", s)
    if s in CITY_ALIASES:
        return CITY_ALIASES[s]
    # –ø—Ä–æ–±—É–µ–º –∫–∞–Ω–æ–Ω–∏–∑–∏—Ä–æ–≤–∞—Ç—å ‚Äú–ú–æ—Å–∫–≤–∞‚Äù, ‚Äú–ö–∞–∑–∞–Ω—å‚Äù, ‚Ä¶
    c = s.title()
    return c if c in KNOWN_CITIES else None

def _find_city(q: str) -> str | None:
    ql = q.lower()

    # "–ø–æ –≤—Å–µ–π —Å—Ç—Ä–∞–Ω–µ" / "*" ‚Äî —Å–ø–µ—Ü. —Å–ª—É—á–∞–π
    if any(k in ql for k in ["–ø–æ –≤—Å–µ–π —Å—Ç—Ä–∞–Ω–µ","–ø–æ —Ä–æ—Å—Å–∏–∏","–≤—Å—è —Å—Ç—Ä–∞–Ω–∞","–ø–æ —Ä—Ñ","–≤—Å–µ –≥–æ—Ä–æ–¥–∞"]) or "*" in ql:
        return "*"

    # –®–∞–±–ª–æ–Ω—ã –ø–æ –∫–æ—Ä–Ω—è–º/—Å–∏–Ω–æ–Ω–∏–º–∞–º (–ª–æ–≤—è—Ç –ø–∞–¥–µ–∂–∏: –º–æ—Å–∫–≤*, –∫–∞–∑–∞–Ω*, –ø–µ—Ç–µ—Ä–±—É—Ä–≥*, ‚Ä¶)
    CITY_PATTERNS = [
        (r"\b–º–æ—Å–∫–≤\w*\b", "–ú–æ—Å–∫–≤–∞"),
        (r"\b—Å–ø–±\b", "–°–∞–Ω–∫—Ç-–ü–µ—Ç–µ—Ä–±—É—Ä–≥"),
        (r"\b–ø–∏—Ç–µ—Ä\w*\b", "–°–∞–Ω–∫—Ç-–ü–µ—Ç–µ—Ä–±—É—Ä–≥"),
        (r"\b—Å–∞–Ω–∫—Ç[\s-]?–ø–µ—Ç–µ—Ä–±—É—Ä–≥\w*\b", "–°–∞–Ω–∫—Ç-–ü–µ—Ç–µ—Ä–±—É—Ä–≥"),
        (r"\b–ø–µ—Ç–µ—Ä–±—É—Ä–≥\w*\b", "–°–∞–Ω–∫—Ç-–ü–µ—Ç–µ—Ä–±—É—Ä–≥"),
        (r"\b–∫–∞–∑–∞–Ω\w*\b", "–ö–∞–∑–∞–Ω—å"),
        (r"\b—Ä–æ—Å—Ç–æ–≤(?:-–Ω–∞-–¥–æ–Ω—É)?\w*\b", "–†–æ—Å—Ç–æ–≤-–Ω–∞-–î–æ–Ω—É"),
        (r"\b–µ–∫–∞—Ç–µ—Ä–∏–Ω–±—É—Ä–≥\w*\b", "–ï–∫–∞—Ç–µ—Ä–∏–Ω–±—É—Ä–≥"),
        (r"\b–Ω–æ–≤–æ—Å–∏–±–∏—Ä—Å–∫\w*\b", "–ù–æ–≤–æ—Å–∏–±–∏—Ä—Å–∫"),
        (r"\b–Ω–∏–∂–Ω\w*\s+–Ω–æ–≤–≥–æ—Ä–æ–¥\w*\b", "–ù–∏–∂–Ω–∏–π –ù–æ–≤–≥–æ—Ä–æ–¥"),
        (r"\b—Å–∞–º–∞—Ä\w*\b", "–°–∞–º–∞—Ä–∞"),
        (r"\b–≤–æ—Ä–æ–Ω–µ–∂\w*\b", "–í–æ—Ä–æ–Ω–µ–∂"),
        (r"\b–ø–µ—Ä–º\w*\b", "–ü–µ—Ä–º—å"),
        (r"\b–≤–æ–ª–≥–æ–≥—Ä–∞–¥\w*\b", "–í–æ–ª–≥–æ–≥—Ä–∞–¥"),
        (r"\b–∫—Ä–∞—Å–Ω–æ—è—Ä—Å–∫\w*\b", "–ö—Ä–∞—Å–Ω–æ—è—Ä—Å–∫"),
        (r"\b–æ–º—Å–∫\w*\b", "–û–º—Å–∫"),
        (r"\b—É—Ñ–∞\w*\b", "–£—Ñ–∞"),
        (r"\b—á–µ–ª—è–±–∏–Ω—Å–∫\w*\b", "–ß–µ–ª—è–±–∏–Ω—Å–∫"),
    ]
    for pat, canon in CITY_PATTERNS:
        if re.search(pat, ql, re.IGNORECASE):
            return canon

    # –î–æ–ø. –ø–æ–ø—ã—Ç–∫–∞: –ø–æ—Å–ª–µ –ø—Ä–µ–¥–ª–æ–≥–æ–≤ –±–µ—Ä—ë–º —Å–ª–æ–≤–æ –∏ —Å–Ω–∏–º–∞–µ–º –æ–¥–Ω—É –±—É–∫–≤—É –ø–∞–¥–µ–∂–∞ (‚Ä¶–µ/‚Ä¶–∏/‚Ä¶—É)
    m = re.search(r"(?:–ø–æ|–≤|–¥–ª—è|–ø–æ –≥–æ—Ä–æ–¥—É|–≤ –≥–æ—Ä–æ–¥–µ)\s+([A-Za-z–ê-–Ø–∞-—è—ë–Å\-\s]+)", ql, re.IGNORECASE)
    if m:
        cand = m.group(1).strip()
        # –æ–±—Ä–µ–∑–∞–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—É—é –ø–∞–¥–µ–∂–Ω—É—é –±—É–∫–≤—É ‚Äî "–º–æ—Å–∫–≤–µ"->"–º–æ—Å–∫–≤", "–∫–∞–∑–∞–Ω–∏"->"–∫–∞–∑–∞–Ω"
        cand_root = re.sub(r"[–µ–∏—É–∞–æ]$", "", cand)
        for pat, canon in CITY_PATTERNS:
            if re.search(pat, cand_root, re.IGNORECASE):
                return canon

    return None

def _find_n(q: str) -> int | None:
    m = re.search(r"(\d+)\s*(?:—à—Ç|—à—Ç—É–∫)?", q)
    return int(m.group(1)) if m else None

def _find_formats(q: str) -> list[str]:
    res = []
    for pat, code in FORMAT_MAP.items():
        if re.search(pat, q, re.IGNORECASE):
            res.append(code)
    # –µ—Å–ª–∏ —è–≤–Ω–æ —Å–∫–∞–∑–∞–ª–∏ ‚Äú—Å—É–ø–µ—Ä—Å–∞–π—Ç—ã –∏ –±–∏–ª–±–æ—Ä–¥—ã‚Äù ‚Äî –ø–æ—Ä—è–¥–æ–∫ –Ω–µ –≤–∞–∂–µ–Ω
    return list(dict.fromkeys(res))  # —É–Ω–∏–∫–∞–ª–∏–∑–∞—Ü–∏—è —Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º –ø–æ—Ä—è–¥–∫–∞


# ================== /ask –∏ –±–æ–ª—Ç–∞–ª–∫–∞ ==================
from aiogram import Router, F, types
from aiogram.types import Message

ux_router = Router(name="humanize")
ux_router.message.filter(F.chat.type == "private")


# ==== –æ–±—â–µ–µ —è–¥—Ä–æ –¥–ª—è /ask –∏ –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö —Ñ—Ä–∞–∑ ====
async def _handle_ask_like_text(m: types.Message, raw_text: str):
    text  = (raw_text or "").strip()
    query = text  # –±–µ–∑ –æ—Ç—Ä–µ–∑–∞–Ω–∏—è –∫–æ–º–∞–Ω–¥—ã ‚Äî —Å—é–¥–∞ –º–æ–∂–Ω–æ –ø–æ–¥–∞–≤–∞—Ç—å –≤—Å—ë

    # –ü—Ä–æ—Å—Ç–∞—è –ø–æ–¥–¥–µ—Ä–∂–∫–∞ "–ø–æ –≤—Å–µ–π —Å—Ç—Ä–∞–Ω–µ"
    ql = query.lower()
    if any(kw in ql for kw in ["–ø–æ –≤—Å–µ–π —Å—Ç—Ä–∞–Ω–µ", "–ø–æ —Ä–æ—Å—Å–∏–∏", "–≤—Å–µ –≥–æ—Ä–æ–¥–∞", "–ø–æ —Ä—Ñ", "–ø–æ —Å—Ç—Ä–∞–Ω–µ", "* –≤—Å—è —Å—Ç—Ä–∞–Ω–∞"]):
        if "*" not in query:
            query = (query
                     .replace("–ø–æ –≤—Å–µ–π —Å—Ç—Ä–∞–Ω–µ", "*")
                     .replace("–ø–æ —Ä–æ—Å—Å–∏–∏", "*")
                     .replace("–≤—Å–µ –≥–æ—Ä–æ–¥–∞", "*")
                     .replace("–ø–æ —Ä—Ñ", "*")
                     .replace("–ø–æ —Å—Ç—Ä–∞–Ω–µ", "*"))

    # --- 1) –ü–æ–¥–±–æ—Ä (pick_city) ---
    nl_pick = parse_pick_city_nl(query)
    if nl_pick.get("city") and nl_pick.get("n"):
        city    = nl_pick["city"]
        n       = nl_pick["n"]
        # –¥–µ—Ñ–æ–ª—Ç—ã —Ñ–æ—Ä–º–∞—Ç–æ–≤
        formats = (nl_pick.get("formats") or ["BILLBOARD", "SUPERSITE"])
        even    = bool(nl_pick.get("even"))

        preview = ["/pick_city", city, str(n)]
        if formats:
            preview.append("format=" + ",".join(formats))
        if even:
            preview.append("fixed=1")
        await m.answer("–°–¥–µ–ª–∞—é —Ç–∞–∫: " + " ".join(preview))

        return await pick_city(m, _call_args={
            "city":    city,
            "n":       n,
            "formats": formats,
            "owners":  [],
            "fields":  [],
            "shuffle": False,
            "fixed":   even,
            "seed":    42 if even else None,
        })

    # --- 2) –ü–ª–∞–Ω (plan) ---
    nl_plan = parse_plan_nl(query)
    if nl_plan.get("cities"):
        fmt   = nl_plan.get("format")
        days  = nl_plan.get("days")  or 7
        hours = nl_plan.get("hours") or 12
        formats_req = [fmt] if fmt else []
        parts = ["/plan", "–≥–æ—Ä–æ–¥–∞=" + ";".join(nl_plan["cities"])]
        if formats_req: parts.append("format=" + ",".join(formats_req))
        parts += [f"days={days}", f"hours={hours}", "mode=even", "rank=ots"]
        await m.answer("–ü–æ–Ω—è–ª–∞ –∑–∞–ø—Ä–æ—Å –∫–∞–∫: " + " ".join(parts))
        return await _plan_core(
            m,
            cities=nl_plan["cities"],
            days=days,
            hours=hours,
            formats_req=formats_req,
            max_per_city=None,
            max_total=None,
            budget_total=None,
            mode="even",
            rank="ots",
        )

    # --- 3) –§–æ–ª–±—ç–∫ ---
    await m.answer(
        "–ü–æ–∫–∞ –ø–æ–Ω–∏–º–∞—é –¥–≤–∞ —Ç–∏–ø–∞ –∑–∞–ø—Ä–æ—Å–æ–≤:\n"
        "‚Ä¢ –ü–æ–¥–±–æ—Ä: ¬´–ø–æ–¥–±–µ—Ä–∏ 100 –±–∏–ª–±–æ—Ä–¥–æ–≤ –∏ —Å—É–ø–µ—Ä—Å–∞–π—Ç–æ–≤ –ø–æ –ü–µ—Ç–µ—Ä–±—É—Ä–≥—É¬ª\n"
        "‚Ä¢ –ü–ª–∞–Ω: ¬´–ø–ª–∞–Ω –Ω–∞ –Ω–µ–¥–µ–ª—é –ø–æ —Å–∏—Ç–∏–±–æ—Ä–¥–∞–º –≤ –†–æ—Å—Ç–æ–≤–µ, 12 —á–∞—Å–æ–≤ –≤ –¥–µ–Ω—å¬ª"
    )

async def _maybe_handle_intent(m: types.Message, raw_text: str) -> bool:
    text  = (raw_text or "").strip()
    query = text

    ql = query.lower()
    if any(kw in ql for kw in ["–ø–æ –≤—Å–µ–π —Å—Ç—Ä–∞–Ω–µ","–ø–æ —Ä–æ—Å—Å–∏–∏","–≤—Å–µ –≥–æ—Ä–æ–¥–∞","–ø–æ —Ä—Ñ","–ø–æ —Å—Ç—Ä–∞–Ω–µ"]) or "*" in ql:
        if "*" not in query:
            query = (query
                .replace("–ø–æ –≤—Å–µ–π —Å—Ç—Ä–∞–Ω–µ", "*")
                .replace("–ø–æ —Ä–æ—Å—Å–∏–∏", "*")
                .replace("–≤—Å–µ –≥–æ—Ä–æ–¥–∞", "*")
                .replace("–ø–æ —Ä—Ñ", "*")
                .replace("–ø–æ —Å—Ç—Ä–∞–Ω–µ", "*"))

    # 1) –ü–æ–¥–±–æ—Ä
    nl_pick = parse_pick_city_nl(query)
    if nl_pick.get("city") and nl_pick.get("n"):
        city    = nl_pick["city"]
        n       = nl_pick["n"]
        formats = nl_pick.get("formats") or []
        even    = bool(nl_pick.get("even"))

        preview = ["/pick_city", city, str(n)]
        if formats: preview.append("format=" + ",".join(formats))
        if even:    preview.append("fixed=1")
        await m.answer("–°–¥–µ–ª–∞—é —Ç–∞–∫: " + " ".join(preview))

        await pick_city(m, _call_args={
            "city":    city,
            "n":       n,
            "formats": formats,
            "owners":  [],
            "fields":  [],
            "shuffle": False,
            "fixed":   even,
            "seed":    42 if even else None,
        })
        return True

    # 2) –ü–ª–∞–Ω
    nl_plan = parse_plan_nl(query)
    if nl_plan.get("cities"):
        fmt   = nl_plan.get("format")
        days  = nl_plan.get("days")  or 7
        hours = nl_plan.get("hours") or 12
        formats_req = [fmt] if fmt else []
        parts = ["/plan", "–≥–æ—Ä–æ–¥–∞=" + ";".join(nl_plan["cities"])]
        if formats_req: parts.append("format=" + ",".join(formats_req))
        parts += [f"days={days}", f"hours={hours}", "mode=even", "rank=ots"]
        await m.answer("–ü–æ–Ω—è–ª–∞ –∑–∞–ø—Ä–æ—Å –∫–∞–∫: " + " ".join(parts))

        await _plan_core(
            m,
            cities=nl_plan["cities"],
            days=days,
            hours=hours,
            formats_req=formats_req,
            max_per_city=None,
            max_total=None,
            budget_total=None,
            mode="even",
            rank="ots",
        )
        return True
        # --- 3) –ù–µ —Ä–∞—Å–ø–æ–∑–Ω–∞–ª–∏, –Ω–æ –æ—á–µ–Ω—å –ø–æ—Ö–æ–∂–µ –Ω–∞ –∑–∞–¥–∞—á—É ‚Äî –ø–æ–¥—Å–∫–∞–∂–µ–º /ask ---
    if _looks_like_pick_or_plan(query):
        await m.answer(f"–î–∞–≤–∞–π –∑–∞–ø—É—Å—Ç–∏–º —ç—Ç–æ –∫–∞–∫ –∫–æ–º–∞–Ω–¥—É:\n/ask {query}")
        return True

    return False

# ================== /ask ==================
@dp.message(Command("ask"))
async def cmd_ask(m: types.Message):
    text  = (m.text or "")
    query = text.partition(" ")[2].strip() or text
    return await _handle_ask_like_text(m, query)

# --- –µ—Å–ª–∏ —Ñ—Ä–∞–∑–∞ –ø–æ—Ö–æ–∂–∞ –Ω–∞ "–ø–æ–¥–±–æ—Ä/–ø–ª–∞–Ω", –º—è–≥–∫–æ –ø—Ä–æ—Å–∏–º –∑–∞–ø—É—Å—Ç–∏—Ç—å /ask ---
@ux_router.message(
    F.text.regexp(re.compile(r'(?iu)\b(–ø–æ–¥–±–µ—Ä–∏|–ø–æ–¥–±–æ—Ä|–≤—ã–±–µ—Ä–∏|—Å–æ–±–µ—Ä–∏|–ø–ª–∞–Ω|—Ä–∞—Å–ø–∏—Å–∞–Ω–∏–µ|–≥—Ä–∞—Ñ–∏–∫)\b'))
)


async def nudge_to_ask(message: Message):
    # –Ω–∏—á–µ–≥–æ –Ω–µ –ø–∞—Ä—Å–∏–º ‚Äî –ø—Ä–æ—Å—Ç–æ –ø—Ä–µ–¥–ª–∞–≥–∞–µ–º —Ç—É –∂–µ —Ñ—Ä–∞–∑—É —á–µ—Ä–µ–∑ /ask
    await message.answer(f"–ó–∞–ø—É—â—É —ç—Ç–æ —á–µ—Ä–µ–∑ –∫–æ–º–∞–Ω–¥—É:\n/ask {message.text}")

# –æ–±—â–∏–π ¬´–±–æ–ª—Ç–∞–ª–∫–∞¬ª-–æ–±—Ä–∞–±–æ—Ç—á–∏–∫ (–ø–æ—Å–ª–µ–¥–Ω–∏–π –ø–æ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç—É)
@ux_router.message(F.text)
async def human_text(message: Message, bot: Bot):
    handled = await _maybe_handle_intent(message, message.text)  # <- —Å–Ω–∞—á–∞–ª–∞ –ø—ã—Ç–∞–µ–º—Å—è –ø–æ–Ω—è—Ç—å –Ω–∞–º–µ—Ä–µ–Ω–∏–µ
    if handled:
        return
    prefs = get_user_prefs(message.from_user.id)
    await typing(message.chat.id, bot, min(1.0, 0.2 + len(message.text)/100))
    text = await smart_reply(message.text, prefs.get("name"), prefs.get("style"))
    await message.answer(style_wrap(text, prefs.get("style")))


dp.include_router(ux_router) 

# ==== –æ–±—â–µ–µ —è–¥—Ä–æ –¥–ª—è /ask –∏ –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö —Ñ—Ä–∞–∑ ====
async def _handle_ask_like_text(m: types.Message, raw_text: str):
    text  = (raw_text or "").strip()
    query = text  # –±–µ–∑ –æ—Ç—Ä–µ–∑–∞–Ω–∏—è –∫–æ–º–∞–Ω–¥—ã ‚Äî —Å—é–¥–∞ –º–æ–∂–Ω–æ –ø–æ–¥–∞–≤–∞—Ç—å –≤—Å—ë

    # –ü—Ä–æ—Å—Ç–∞—è –ø–æ–¥–¥–µ—Ä–∂–∫–∞ "–ø–æ –≤—Å–µ–π —Å—Ç—Ä–∞–Ω–µ"
    ql = query.lower()
    if any(kw in ql for kw in ["–ø–æ –≤—Å–µ–π —Å—Ç—Ä–∞–Ω–µ", "–ø–æ —Ä–æ—Å—Å–∏–∏", "–≤—Å–µ –≥–æ—Ä–æ–¥–∞", "–ø–æ —Ä—Ñ", "–ø–æ —Å—Ç—Ä–∞–Ω–µ", "* –≤—Å—è —Å—Ç—Ä–∞–Ω–∞"]):
        # –ª—ë–≥–∫–∏–π —Ö–∞–∫: –µ—Å–ª–∏ –≥–æ—Ä–æ–¥ –Ω–µ —É–∫–∞–∑–∞–Ω, –ø–æ–¥—Å—Ç–∞–≤–∏–º '*'
        if " * " not in query and " *" not in query and "*" not in query:
            query = query.replace("–ø–æ –≤—Å–µ–π —Å—Ç—Ä–∞–Ω–µ", "*").replace("–ø–æ —Ä–æ—Å—Å–∏–∏", "*").replace("–≤—Å–µ –≥–æ—Ä–æ–¥–∞", "*").replace("–ø–æ —Ä—Ñ", "*").replace("–ø–æ —Å—Ç—Ä–∞–Ω–µ", "*")

    # --- 1) –ü–æ–¥–±–æ—Ä (pick_city) ---
    nl_pick = parse_pick_city_nl(query)
    if nl_pick.get("city") and nl_pick.get("n"):
        city    = nl_pick["city"]
        n       = nl_pick["n"]
        formats = nl_pick.get("formats") or []
        even    = bool(nl_pick.get("even"))

        preview = ["/pick_city", city, str(n)]
        if formats:
            preview.append("format=" + ",".join(formats))
        if even:
            preview.append("fixed=1")
        await m.answer("–°–¥–µ–ª–∞—é —Ç–∞–∫: " + " ".join(preview))

        return await pick_city(m, _call_args={
            "city":    city,
            "n":       n,
            "formats": formats,
            "owners":  [],
            "fields":  [],
            "shuffle": False,
            "fixed":   even,
            "seed":    42 if even else None,
        })

    # --- 2) –ü–ª–∞–Ω (plan) ---
    nl_plan = parse_plan_nl(query)
    if nl_plan.get("cities"):
        fmt   = nl_plan.get("format")
        days  = nl_plan.get("days")  or 7
        hours = nl_plan.get("hours") or 12
        formats_req = [fmt] if fmt else []
        parts = ["/plan", "–≥–æ—Ä–æ–¥–∞=" + ";".join(nl_plan["cities"])]
        if formats_req: parts.append("format=" + ",".join(formats_req))
        parts += [f"days={days}", f"hours={hours}", "mode=even", "rank=ots"]
        await m.answer("–ü–æ–Ω—è–ª–∞ –∑–∞–ø—Ä–æ—Å –∫–∞–∫: " + " ".join(parts))
        return await _plan_core(
            m,
            cities=nl_plan["cities"],
            days=days,
            hours=hours,
            formats_req=formats_req,
            max_per_city=None,
            max_total=None,
            budget_total=None,
            mode="even",
            rank="ots",
        )

    # --- 3) –§–æ–ª–±—ç–∫ ---
    await m.answer(
        "–ü–æ–∫–∞ –ø–æ–Ω–∏–º–∞—é –¥–≤–∞ —Ç–∏–ø–∞ –∑–∞–ø—Ä–æ—Å–æ–≤:\n"
        "‚Ä¢ –ü–æ–¥–±–æ—Ä: ¬´–ø–æ–¥–±–µ—Ä–∏ 100 –±–∏–ª–±–æ—Ä–¥–æ–≤ –∏ —Å—É–ø–µ—Ä—Å–∞–π—Ç–æ–≤ –ø–æ –ü–µ—Ç–µ—Ä–±—É—Ä–≥—É¬ª\n"
        "‚Ä¢ –ü–ª–∞–Ω: ¬´–ø–ª–∞–Ω –Ω–∞ –Ω–µ–¥–µ–ª—é –ø–æ —Å–∏—Ç–∏–±–æ—Ä–¥–∞–º –≤ –†–æ—Å—Ç–æ–≤–µ, 12 —á–∞—Å–æ–≤ –≤ –¥–µ–Ω—å¬ª"
    )
# ======== –§–æ—Ç–æ–æ—Ç—á—ë—Ç—ã –ø–æ –∫–∞–º–ø–∞–Ω–∏–∏ ========

def _normalize_shots(data) -> pd.DataFrame:
    """
    –ü—Ä–∏–≤–æ–¥–∏—Ç –æ—Ç–≤–µ—Ç API —Å —Ñ–æ—Ç–æ–æ—Ç—á—ë—Ç–∞–º–∏ –∫ —É–¥–æ–±–Ω–æ–º—É DataFrame.
    –û–∂–∏–¥–∞–µ–º—ã–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã –≤—Ö–æ–¥–∞:
      - —Å–ø–∏—Å–æ–∫ dict'–æ–≤
      - dict c –∫–ª—é—á–æ–º "items" –∏–ª–∏ –ø–æ—Ö–æ–∂–µ–π —Å—Ç—Ä—É–∫—Ç—É—Ä–æ–π
      - —É–∂–µ –≥–æ—Ç–æ–≤—ã–π DataFrame
    –ù–∞ bytes –ù–ï —Ä–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º –∑–¥–µ—Å—å ‚Äî –±–∞–π—Ç—ã –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—é—Ç—Å—è –≤ cmd_shots (–ø–æ–ø—ã—Ç–∫–∞ –∫–∞–∫ XLSX, –∏–Ω–∞—á–µ ZIP).
    """
    if data is None:
        return pd.DataFrame()

    # –£–∂–µ DataFrame
    if isinstance(data, pd.DataFrame):
        return data

    # –ï—Å–ª–∏ –ø—Ä–∏—à—ë–ª —Ç–µ–∫—Å—Ç JSON–æ–º ‚Äî –ø–æ–ø—Ä–æ–±—É–µ–º —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å
    if isinstance(data, str):
        try:
            import json as _json
            data = _json.loads(data)
        except Exception:
            return pd.DataFrame()

    # –ï—Å–ª–∏ dict ‚Äî –ø–æ–ø—Ä–æ–±—É–µ–º –≤–∑—è—Ç—å —Å–ø–∏—Å–∫–∏ –∏–∑ —Ç–∏–ø–∏—á–Ω—ã—Ö –∫–ª—é—á–µ–π
    if isinstance(data, dict):
        for key in ("items", "data", "list", "content", "result", "results"):
            v = data.get(key)
            if isinstance(v, list):
                data = v
                break

    if not isinstance(data, list):
        return pd.DataFrame()

    def g(obj, path, default=None):
        cur = obj
        try:
            for k in path:
                if cur is None:
                    return default
                if isinstance(k, int):
                    if isinstance(cur, list) and len(cur) > k:
                        cur = cur[k]
                    else:
                        return default
                else:
                    if isinstance(cur, dict):
                        cur = cur.get(k)
                    else:
                        return default
            return cur if cur is not None else default
        except Exception:
            return default

    rows = []
    for it in data:
        if not isinstance(it, dict):
            continue
        inv   = it.get("inventory") or {}
        camp  = it.get("campaign") or {}
        media = it.get("media") or {}
        img   = it.get("image") or it.get("snapshot") or {}

        rows.append({
            "campaign_id": camp.get("id") or it.get("campaignId"),
            "campaign_name": camp.get("name"),
            "inventory_id": inv.get("id") or it.get("inventoryId") or it.get("screenId"),
            "inventory_gid": inv.get("gid") or it.get("gid"),
            "inventory_name": inv.get("name") or it.get("inventoryName"),
            "city": g(inv, ["location", "city"]) or it.get("city"),
            "address": g(inv, ["location", "address"]) or it.get("address"),
            "format": inv.get("type") or it.get("format"),
            "owner": g(inv, ["displayOwner", "name"]) or it.get("owner"),

            "creative_id": media.get("id") or it.get("creativeId"),
            "creative_name": media.get("name") or it.get("creativeName"),

            "shot_id": it.get("id"),
            "shot_time": it.get("timestamp") or it.get("time") or it.get("createdAt"),

            "image_url": img.get("url") or it.get("imageUrl") or it.get("url"),
            "image_preview": img.get("preview") or it.get("previewUrl"),
        })

    return pd.DataFrame(rows)


import typing

import typing
from typing import Optional
import asyncio, json
import aiohttp

# ==== SHOTS (–∫–æ—Ä–Ω–µ–≤—ã–µ –º–∞—Ä—à—Ä—É—Ç—ã) =============================================

async def _fetch_impression_shots(
    campaign_id: int,
    per: int | None = None,
    m: types.Message | None = None,
    dbg: bool = False,
) -> typing.Union[list[dict], dict, bytes]:
    """
    –ü—ã—Ç–∞–µ–º—Å—è –ø–æ ¬´–Ω–æ–≤–æ–π¬ª —Å—Ö–µ–º–µ (–±–µ–∑ /api/...):
      1) GET /impression-shots?campaignId=...
      2) POST /impression-shots  JSON {"campaignId": ..., "shotCountPerInventoryCreative": per}
      3) GET /impression-shots/export?campaignId=...   (ZIP)
      4) POST /impression-shots/export  JSON {...}     (ZIP)
    –ó–∞—Ç–µ–º –ø—Ä–æ–±—É–µ–º ¬´—Å—Ç–∞—Ä—ã–µ¬ª –∫–ª–∏–µ–Ω—Ç–æ-—ç–Ω–¥–ø–æ–π–Ω—Ç—ã –∫–∞–∫ –∑–∞–ø–∞—Å–Ω–æ–π –ø–ª–∞–Ω.
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç list[dict] | dict | bytes(ZIP).
    """
    base = (OBDSP_BASE or "https://proddsp.omniboard360.io").rstrip("/")
    token = (OBDSP_TOKEN or "").strip()
    if not token:
        raise RuntimeError("–ù–µ—Ç OBDSP_TOKEN")

    headers_json = {"Authorization": f"Bearer {token}", "Accept": "application/json", "Content-Type": "application/json"}
    headers_any  = {"Authorization": f"Bearer {token}", "Accept": "*/*"}
    ssl_param = _make_ssl_param_for_aiohttp()
    timeout = aiohttp.ClientTimeout(total=300)

    q = {"campaignId": campaign_id}
    if per is not None:
        q["shotCountPerInventoryCreative"] = per

    candidates = [
        # –Ω–æ–≤—ã–µ (–±–µ–∑ –ø—Ä–µ—Ñ–∏–∫—Å–∞)
        ("GET",  f"{base}/impression-shots", False, True),   # params
        ("POST", f"{base}/impression-shots", True,  False),  # json
        ("GET",  f"{base}/impression-shots/export", False, True),
        ("POST", f"{base}/impression-shots/export", True,  False),

        # ¬´—Å—Ç–∞—Ä—ã–µ¬ª –∑–∞–ø–∞—Å–Ω—ã–µ
        ("GET",  f"{base}/api/v1.0/clients/campaigns/{campaign_id}/impression-shots", False, True),
        ("POST", f"{base}/api/v1.0/clients/campaigns/{campaign_id}/impression-shots", True,  False),
        ("GET",  f"{base}/api/v1.0/clients/campaigns/{campaign_id}/impression-shots/export", False, True),
        ("POST", f"{base}/api/v1.0/clients/campaigns/{campaign_id}/impression-shots/export", True,  False),
    ]

    async with aiohttp.ClientSession(timeout=timeout) as session:
        last_err = ""
        for method, url, send_json, use_params in candidates:
            try:
                if dbg and m:
                    await m.answer(f"¬∑ –ø—Ä–æ–±—É—é {method} {url}")

                params = q if use_params else None
                json_body = q if send_json else None
                headers = headers_json if send_json else headers_any

                if method == "GET":
                    async with session.get(url, headers=headers, params=params, ssl=ssl_param) as r:
                        ct = r.headers.get("Content-Type", "")
                        body = await r.read()
                        if r.status == 404:
                            last_err = body.decode("utf-8", errors="ignore")
                            continue
                        if r.status >= 300:
                            last_err = body.decode("utf-8", errors="ignore")
                            continue
                        if "application/zip" in ct or "application/octet-stream" in ct:
                            return body
                        try:
                            return await r.json(content_type=None)
                        except Exception:
                            import json as _json
                            return _json.loads(body.decode("utf-8", errors="ignore"))

                else:
                    async with session.post(url, headers=headers, params=None, json=json_body, ssl=ssl_param) as r:
                        ct = r.headers.get("Content-Type", "")
                        body = await r.read()
                        if r.status == 404:
                            last_err = body.decode("utf-8", errors="ignore")
                            continue
                        if r.status >= 300:
                            last_err = body.decode("utf-8", errors="ignore")
                            continue
                        if "application/zip" in ct or "application/octet-stream" in ct:
                            return body
                        try:
                            return await r.json(content_type=None)
                        except Exception:
                            import json as _json
                            return _json.loads(body.decode("utf-8", errors="ignore"))

            except Exception as e:
                last_err = str(e)
                continue

    raise RuntimeError(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —à–æ—Ç—ã (–ø–æ—Å–ª–µ–¥–Ω–∏–π –æ—Ç–≤–µ—Ç: {last_err[:300]})")


# ==== TECH REQUIREMENTS (–∫–æ—Ä–Ω–µ–≤—ã–µ –º–∞—Ä—à—Ä—É—Ç—ã) =================================

async def _fetch_tech_requirements(
    campaign_id: int,
    m: types.Message | None = None,
    dbg: bool = False,
) -> typing.Union[list[dict], dict, bytes]:
    """
    –ü—Ä–æ–±—É–µ–º:
      1) GET /technical-requirements?campaignId=...
      2) POST /technical-requirements              JSON {campaignId}
      3) GET/POST /display-owners/technical-requirements/export  (–≤–æ–∑–≤—Ä–∞—Ç ZIP/—Ñ–∞–π–ª)
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç list[dict] | dict | bytes(ZIP).
    """
    base = (OBDSP_BASE or "https://proddsp.omniboard360.io").rstrip("/")
    token = (OBDSP_TOKEN or "").strip()
    if not token:
        raise RuntimeError("–ù–µ—Ç OBDSP_TOKEN")

    headers_json = {"Authorization": f"Bearer {token}", "Accept": "application/json", "Content-Type": "application/json"}
    headers_any  = {"Authorization": f"Bearer {token}", "Accept": "*/*"}
    ssl_param = _make_ssl_param_for_aiohttp()
    timeout = aiohttp.ClientTimeout(total=300)

    q = {"campaignId": campaign_id}

    candidates = [
        ("GET",  f"{base}/technical-requirements", False, True),
        ("POST", f"{base}/technical-requirements", True,  False),
        ("GET",  f"{base}/display-owners/technical-requirements/export", False, True),
        ("POST", f"{base}/display-owners/technical-requirements/export", True,  False),
    ]

    async with aiohttp.ClientSession(timeout=timeout) as session:
        last_err = ""
        for method, url, send_json, use_params in candidates:
            try:
                if dbg and m:
                    await m.answer(f"¬∑ –ø—Ä–æ–±—É—é {method} {url}")

                params = q if use_params else None
                json_body = q if send_json else None
                headers = headers_json if send_json else headers_any

                if method == "GET":
                    async with session.get(url, headers=headers, params=params, ssl=ssl_param) as r:
                        ct = r.headers.get("Content-Type", "")
                        body = await r.read()
                        if r.status == 404:
                            last_err = body.decode("utf-8", errors="ignore"); continue
                        if r.status >= 300:
                            last_err = body.decode("utf-8", errors="ignore"); continue
                        if "application/zip" in ct or "application/octet-stream" in ct:
                            return body
                        try:
                            return await r.json(content_type=None)
                        except Exception:
                            import json as _json
                            return _json.loads(body.decode("utf-8", errors="ignore"))

                else:
                    async with session.post(url, headers=headers, json=json_body, ssl=ssl_param) as r:
                        ct = r.headers.get("Content-Type", "")
                        body = await r.read()
                        if r.status == 404:
                            last_err = body.decode("utf-8", errors="ignore"); continue
                        if r.status >= 300:
                            last_err = body.decode("utf-8", errors="ignore"); continue
                        if "application/zip" in ct or "application/octet-stream" in ct:
                            return body
                        try:
                            return await r.json(content_type=None)
                        except Exception:
                            import json as _json
                            return _json.loads(body.decode("utf-8", errors="ignore"))

            except Exception as e:
                last_err = str(e); continue

    raise RuntimeError(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è (–ø–æ—Å–ª–µ–¥–Ω–∏–π –æ—Ç–≤–µ—Ç: {last_err[:300]})")


@dp.message(Command("shots"))
async def cmd_shots(m: types.Message):
    """–ö–æ–º–∞–Ω–¥–∞ /shots ‚Äî —Å–æ–±—Ä–∞—Ç—å —Ñ–æ—Ç–æ–æ—Ç—á—ë—Ç –ø–æ –∫–∞–º–ø–∞–Ω–∏–∏"""
    if not _owner_only(m.from_user.id):
        await m.answer("‚õîÔ∏è –¢–æ–ª—å–∫–æ –≤–ª–∞–¥–µ–ª–µ—Ü –±–æ—Ç–∞ –º–æ–∂–µ—Ç –≤—ã–ø–æ–ª–Ω—è—Ç—å —ç—Ç—É –∫–æ–º–∞–Ω–¥—É.")
        return

    # --- –ø–∞—Ä—Å–∏–Ω–≥ –∞—Ä–≥—É–º–µ–Ω—Ç–æ–≤ ---
    text = (m.text or "").strip()
    parts = text.split()[1:]

    def _get_opt(name, cast, default):
        for p in parts:
            if p.startswith(name + "="):
                v = p.split("=", 1)[1]
                try:
                    return cast(v)
                except Exception:
                    return default
        return default

    def _get_str(name, default=""):
        for p in parts:
            if p.startswith(name + "="):
                return p.split("=", 1)[1]
        return default

    campaign_id = _get_opt("campaign", int, None)
    per = _get_opt("per", int, None)
    limit = _get_opt("limit", int, None)
    want_zip = str(_get_str("zip", "0")).lower() in {"1", "true", "yes", "on"}
    fields_req = _get_str("fields", "").strip()
    dbg = str(_get_str("dbg", "0")).lower() in {"1", "true", "yes", "on"}

    if not campaign_id:
        await m.answer("–§–æ—Ä–º–∞—Ç: /shots campaign=<ID> [per=0] [limit=100] [zip=1] [fields=...] [dbg=1]")
        return

    await m.answer(f"‚è≥ –°–æ–±–∏—Ä–∞—é —Ñ–æ—Ç–æ–æ—Ç—á—ë—Ç –ø–æ –∫–∞–º–ø–∞–Ω–∏–∏ {campaign_id}‚Ä¶")

    # --- –∑–∞–ø—Ä–æ—Å ---
    try:
        data = await _fetch_impression_shots(
            campaign_id,
            per=per,
            m=(m if dbg else None),
            dbg=dbg
        )
    except Exception as e:
        await m.answer(f"üö´ –û—à–∏–±–∫–∞ API: {e}")
        return

    # --- –µ—Å–ª–∏ –ø—Ä–∏–ª–µ—Ç–µ–ª ZIP ---
    if isinstance(data, (bytes, bytearray)):
        fname = f"shots_{campaign_id}.zip"
        await bot.send_document(
            m.chat.id,
            BufferedInputFile(data, filename=fname),
            caption="ZIP —Å —Ñ–æ—Ç–æ–æ—Ç—á—ë—Ç–æ–º"
        )
        return

    # --- –µ—Å–ª–∏ —ç—Ç–æ JSON —Å–æ —Å—Å—ã–ª–∫–æ–π –Ω–∞ ZIP ---
    if isinstance(data, dict):
        file_url = data.get("file") or data.get("url") or data.get("href")
        if file_url and file_url.startswith("http"):
            try:
                import aiohttp
                ssl_param = _make_ssl_param_for_aiohttp()
                async with aiohttp.ClientSession(timeout=aiohttp.ClientTimeout(total=300)) as s:
                    async with s.get(file_url, ssl=ssl_param) as r:
                        body = await r.read()
                await bot.send_document(
                    m.chat.id,
                    BufferedInputFile(body, filename=f"shots_{campaign_id}.zip"),
                    caption="ZIP —Å —Ñ–æ—Ç–æ–æ—Ç—á—ë—Ç–æ–º (–ø–æ —Å—Å—ã–ª–∫–µ –∏–∑ JSON)"
                )
                return
            except Exception:
                pass  # –Ω–µ —É–¥–∞–ª–æ—Å—å —Å–∫–∞—á–∞—Ç—å ‚Äî –ø—Ä–æ–¥–æ–ª–∂–∞–µ–º

    # --- –µ—Å–ª–∏ API –≤–µ—Ä–Ω—É–ª –æ—à–∏–±–∫—É {message, status} ---
    if isinstance(data, dict) and "message" in data and "status" in data and not isinstance(data.get("message"), (list, dict)):
        await m.answer(f"‚ö†Ô∏è API –≤–µ—Ä–Ω—É–ª —Å–æ–æ–±—â–µ–Ω–∏–µ: {data.get('message')} (status={data.get('status')})")

    # --- –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö ---
    df = _normalize_shots(data)
    if limit and not df.empty and len(df) > limit:
        df = df.head(limit)

    if df.empty:
        try:
            if isinstance(data, dict):
                keys = list(data.keys())
                await m.answer(f"–§–æ—Ç–æ–æ—Ç—á—ë—Ç—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã. (dbg: dict keys={keys[:10]})")
            elif isinstance(data, list):
                head_keys = (list(data[0].keys())[:12] if data and isinstance(data[0], dict) else '‚Äî')
                await m.answer(f"–§–æ—Ç–æ–æ—Ç—á—ë—Ç—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã. (dbg: list len={len(data)}, first keys={head_keys})")
            else:
                await m.answer(f"–§–æ—Ç–æ–æ—Ç—á—ë—Ç—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã. (dbg: type={type(data).__name__})")
        except Exception:
            await m.answer("–§–æ—Ç–æ–æ—Ç—á—ë—Ç—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã.")
        return

    # --- –≤—ã–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö ---
    if fields_req:
        cols = [c.strip() for c in fields_req.split(",") if c.strip()]
        cols = [c for c in cols if c in df.columns]
        if not cols:
            await m.answer("–ü–æ–ª—è –Ω–µ —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω—ã. –î–æ—Å—Ç—É–ø–Ω—ã–µ: " + ", ".join(df.columns))
            return
        view = df[cols].copy()
        csv_bytes = view.to_csv(index=False).encode("utf-8-sig")
        await bot.send_document(
            m.chat.id,
            BufferedInputFile(csv_bytes, filename=f"shots_{campaign_id}.csv"),
            caption=f"–ö–∞–¥—Ä—ã –∫–∞–º–ø–∞–Ω–∏–∏ {campaign_id} (–ø–æ–ª—è: {', '.join(cols)})"
        )
    else:
        # --- CSV ---
        try:
            csv_bytes = df.to_csv(index=False).encode("utf-8-sig")
            await bot.send_document(
                m.chat.id,
                BufferedInputFile(csv_bytes, filename=f"shots_{campaign_id}.csv"),
                caption=f"–§–æ—Ç–æ–æ—Ç—á—ë—Ç –∫–∞–º–ø–∞–Ω–∏–∏ {campaign_id}: {len(df)} —Å—Ç—Ä–æ–∫ (CSV)"
            )
        except Exception as e:
            await m.answer(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –æ—Ç–ø—Ä–∞–≤–∏—Ç—å CSV: {e}")

        # --- XLSX ---
        try:
            import io
            xbuf = io.BytesIO()
            with pd.ExcelWriter(xbuf, engine="openpyxl") as w:
                df.to_excel(w, index=False, sheet_name="shots")
            xbuf.seek(0)
            await bot.send_document(
                m.chat.id,
                BufferedInputFile(xbuf.getvalue(), filename=f"shots_{campaign_id}.xlsx"),
                caption=f"–§–æ—Ç–æ–æ—Ç—á—ë—Ç –∫–∞–º–ø–∞–Ω–∏–∏ {campaign_id}: {len(df)} —Å—Ç—Ä–æ–∫ (XLSX)"
            )
        except Exception as e:
            await m.answer(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –æ—Ç–ø—Ä–∞–≤–∏—Ç—å XLSX: {e}")

    wait_secs  = _get_opt("wait", int, 240)  # <‚Äî –ù–û–í–û–ï

    ...

    data = await _fetch_impression_shots(
        campaign_id,
        per=per,
        m=(m if dbg else None),
        dbg=dbg,
        wait_secs=wait_secs,   # <‚Äî –ù–û–í–û–ï
    )
            
@dp.message(Command("status"))
async def cmd_status(m: types.Message):
    global SCREENS

    base = (OBDSP_BASE or "").strip()
    tok  = (OBDSP_TOKEN or "").strip()
    screens_count = len(SCREENS) if SCREENS is not None else 0

    text = [
        "üìä *OmniDSP Bot Status*",
        f"‚Ä¢ API Base: `{base or '‚Äî'}`",
        f"‚Ä¢ Token: {'‚úÖ' if tok else '‚ùå –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç'}",
        f"‚Ä¢ –ó–∞–≥—Ä—É–∂–µ–Ω–æ —ç–∫—Ä–∞–Ω–æ–≤: *{screens_count}*",
    ]

    if screens_count:
        text.append(f"‚Ä¢ –ü—Ä–∏–º–µ—Ä –≥–æ—Ä–æ–¥–æ–≤: {', '.join(SCREENS['city'].dropna().astype(str).unique()[:5])}")

    await m.answer("\n".join(text), parse_mode="Markdown")

@dp.message(Command("reload_cache"))
async def cmd_reload_cache(m: types.Message):
    if not _owner_only(m.from_user.id):
        return
    ok = load_screens_cache()
    if ok:
        await m.answer(f"üîÑ –ö—ç—à –ø–æ–¥–≥—Ä—É–∂–µ–Ω: {len(SCREENS)} —Å—Ç—Ä–æ–∫.")
    else:
        await m.answer("‚ùå –ö—ç—à –Ω–µ –Ω–∞–π–¥–µ–Ω –∏–ª–∏ –ø—É—Å—Ç.")

@dp.message(Command("clear_cache"))
async def cmd_clear_cache(m: types.Message):
    if not _owner_only(m.from_user.id):
        return
    removed = []
    for p in (CACHE_PARQUET, CACHE_CSV, CACHE_META):
        try:
            if p.exists():
                p.unlink()
                removed.append(p.name)
        except Exception:
            pass
    await m.answer("üóë –ö—ç—à –æ—á–∏—â–µ–Ω: " + (", ".join(removed) if removed else "–Ω–∏—á–µ–≥–æ –Ω–µ –±—ã–ª–æ"))


@dp.message(Command("diag_whoami"))
async def diag_whoami(m: types.Message):
    import aiohttp, json
    try:
        base = (OBDSP_BASE or "https://proddsp.omniboard360.io").strip().rstrip("/")
        tok  = (OBDSP_TOKEN or "").strip().strip('"').strip("'")
        if not tok:
            await m.answer("OBDSP_TOKEN –ø—É—Å—Ç. –ó–∞–¥–∞–π –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é –æ–∫—Ä—É–∂–µ–Ω–∏—è.")
            return

        url = f"{base}/api/v1.0/users/current"
        headers = {
            "Authorization": f"Bearer {tok}",
            "Accept": "application/json",
        }
        ssl_param = _make_ssl_param_for_aiohttp()
        timeout = aiohttp.ClientTimeout(total=30)
        async with aiohttp.ClientSession(timeout=timeout) as session:
            async with session.get(url, headers=headers, ssl=_make_ssl_param_for_aiohttp()) as resp:
                text = await resp.text()
                await m.answer(f"GET {url}\nstatus={resp.status}\nbody={text[:800]}")
    except Exception as e:
        await m.answer(f"–û—à–∏–±–∫–∞: {e}")

@dp.message(Command("diag_env"))
async def diag_env(m: types.Message):
    tok = (OBDSP_TOKEN or "").strip()
    base = (OBDSP_BASE or "").strip()
    sslv = (os.getenv("OBDSP_SSL_VERIFY","") or "").strip()
    shown = f"{tok[:6]}‚Ä¶{tok[-6:]}" if tok else "(empty)"
    await m.answer(
        "ENV:\n"
        f"BASE={base}\n"
        f"TOKEN_LEN={len(tok)} TOKEN={shown}\n"
        f"OBDSP_SSL_VERIFY={sslv}\n"
    )

@dp.message(Command("pick_any"))
async def pick_any(m: types.Message, _call_args: dict | None = None):
    """
    –†–∞–≤–Ω–æ–º–µ—Ä–Ω–∞—è –≤—ã–±–æ—Ä–∫–∞ –ø–æ –≤—Å–µ–π –±–∞–∑–µ –±–µ–∑ —Ñ–∏–ª—å—Ç—Ä–∞ –ø–æ –≥–æ—Ä–æ–¥—É.
    –§–æ—Ä–º–∞—Ç –∫–æ–º–∞–Ω–¥—ã:
      /pick_any N [format=...] [owner=...] [fields=...] [shuffle=1] [fixed=1] [seed=42] [allow_mix=1]
    –¢–∞–∫–∂–µ –≤—ã–∑—ã–≤–∞–µ—Ç—Å—è –∏–∑ /ask —á–µ—Ä–µ–∑ _call_args.
    –í—ã–≤–æ–¥–∏—Ç –¢–û–õ–¨–ö–û —Ñ–∞–π–ª—ã (CSV/XLSX), –±–µ–∑ –¥–ª–∏–Ω–Ω—ã—Ö —Å–ø–∏—Å–∫–æ–≤ –≤ —á–∞—Ç.
    """
    global LAST_RESULT, SCREENS
    if SCREENS is None or SCREENS.empty:
        await m.answer("–°–Ω–∞—á–∞–ª–∞ –∑–∞–≥—Ä—É–∑–∏—Ç–µ –∏–Ω–≤–µ–Ω—Ç–∞—Ä—å (CSV/XLSX –∏–ª–∏ /sync_api).")
        return

    # ---------- –ø–∞—Ä—Å–∏–Ω–≥ –∞—Ä–≥—É–º–µ–Ω—Ç–æ–≤ ----------
    if _call_args is not None:
        try:
            n = int(_call_args.get("n") or 20)
        except Exception:
            n = 20
        # formats –º–æ–∂–Ω–æ –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞—Ç—å, –µ—Å–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–µ—à—å —Å–≤–æ–π –º–∞–ø–ø–µ—Ä:
        formats = [str(x).upper().strip() for x in (_call_args.get("formats") or []) if str(x).strip()]
        owners  = [str(x).strip() for x in (_call_args.get("owners")  or []) if str(x).strip()]
        fields  = [str(x).strip() for x in (_call_args.get("fields")  or []) if str(x).strip()]
        shuffle_flag = bool(_call_args.get("shuffle") or False)
        fixed        = bool(_call_args.get("fixed")   or False)
        seed         = _call_args.get("seed", None)
        allow_mix    = bool(_call_args.get("allow_mix") or False)
    else:
        parts = (m.text or "").strip().split()
        if len(parts) < 2:
            await m.answer("–§–æ—Ä–º–∞—Ç: /pick_any N [format=...] [owner=...] [fields=...] [shuffle=1] [fixed=1] [seed=42]")
            return
        try:
            n = int(parts[1])
        except Exception:
            await m.answer("–ü—Ä–∏–º–µ—Ä: /pick_any 50 format=MEDIA_FACADE")
            return

        # key=value
        kv = {}
        for p in parts[2:]:
            if "=" in p:
                k, v = p.split("=", 1)
                kv[k.strip().lower()] = v.strip().strip('"').strip("'")

        def _as_list(v):
            return [s.strip() for s in str(v).replace(";", ",").replace("|", ",").split(",") if s.strip()]

        formats      = [s.upper() for s in _as_list(kv.get("format", kv.get("formats","")))]
        owners       = _as_list(kv.get("owner", kv.get("owners","")))
        fields       = _as_list(kv.get("fields",""))
        shuffle_flag = str(kv.get("shuffle","0")).lower() in {"1","true","yes","on"}
        fixed        = str(kv.get("fixed","0")).lower()   in {"1","true","yes","on"}
        seed         = int(kv["seed"]) if str(kv.get("seed","")).isdigit() else None
        allow_mix    = str(kv.get("allow_mix","0")).lower() in {"1","true","yes","on"}

    subset = SCREENS.copy()

    # ---------- —Ñ–∏–ª—å—Ç—Ä—ã ----------
    if formats and "format" in subset.columns:
        subset = subset[subset["format"].astype(str).str.upper().isin(set(formats))]
    if owners and "owner" in subset.columns:
        import re as _re
        pat = "|".join(_re.escape(o) for o in owners)
        subset = subset[subset["owner"].astype(str).str.contains(pat, case=False, na=False)]

    if subset.empty:
        await m.answer("–ü–æ –∑–∞–¥–∞–Ω–Ω—ã–º —Ñ–∏–ª—å—Ç—Ä–∞–º –Ω–∏—á–µ–≥–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ.")
        return

    if shuffle_flag:
        subset = subset.sample(frac=1, random_state=None).reset_index(drop=True)

    # –¥–æ–±–æ—Ä –ø—Ä–∏ allow_mix
    if len(subset) < n and allow_mix and "format" in SCREENS.columns:
        want = n - len(subset)
        other = SCREENS.copy()
        if formats:
            other = other[~other["format"].astype(str).str.upper().isin(set(formats))]
        subset = pd.concat([subset, other.head(want)], ignore_index=True)

    # ---------- —Ä–∞–≤–Ω–æ–º–µ—Ä–Ω—ã–π –≤—ã–±–æ—Ä ----------
    try:
        res = spread_select(subset.reset_index(drop=True), n, random_start=not fixed, seed=seed)
    except Exception:
        res = subset.reset_index(drop=True).head(n)

    if res is None or res.empty:
        await m.answer("–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–±—Ä–∞—Ç—å –≤—ã–±–æ—Ä–∫—É (–≤–æ–∑–º–æ–∂–Ω–æ, —Å–ª–∏—à–∫–æ–º –º–∞–ª–æ –∏–Ω–≤–µ–Ω—Ç–∞—Ä—è).")
        return

    LAST_RESULT = res

    # ---------- —Ç–æ–ª—å–∫–æ —Ñ–∞–π–ª—ã ----------
    caption = f"–í—ã–±—Ä–∞–Ω–æ {len(res)} —ç–∫—Ä–∞–Ω–æ–≤ –ø–æ –≤—Å–µ–π –±–∞–∑–µ"
    if formats:
        caption += f" (—Ñ–æ—Ä–º–∞—Ç—ã: {', '.join(formats)})"
    
    exp = _ensure_gid(res)

# —Ö–æ—Ç–∏–º, —á—Ç–æ–±—ã –≤ —Ñ–∞–π–ª–µ –æ—Å—Ç–∞–ª—Å—è —Ç–æ–ª—å–∫–æ GID (–±–µ–∑ –¥—É–±–ª–µ–π –∏—Å—Ö–æ–¥–Ω—ã—Ö ID-–ø–æ–ª–µ–π)
    for _c in ("screen_id", "code", "uid", "id"):
        if _c in exp.columns:
            exp = exp.drop(columns=[_c])

    await send_selection_files(
        m,
        res,
        basename="any_selection",
        caption_prefix=caption,
        fields=(fields if fields else None)
)
    
@dp.message(Command("diag_whoami_force"))
async def diag_whoami_force(m: types.Message):
    import aiohttp
    try:
        base = (OBDSP_BASE or "https://proddsp.omniboard360.io").rstrip("/")
        tok  = (OBDSP_TOKEN or "").strip().strip('"').strip("'")
        if not tok:
            await m.answer("OBDSP_TOKEN –ø—É—Å—Ç –≤–Ω—É—Ç—Ä–∏ –ø—Ä–æ—Ü–µ—Å—Å–∞.")
            return
        url = f"{base}/api/v1.0/users/current"
        headers = {
            "Authorization": f"Bearer {tok}",
            "Accept": "application/json",
        }
        ssl_param = _make_ssl_param_for_aiohttp()
        timeout = aiohttp.ClientTimeout(total=20)
        async with aiohttp.ClientSession(timeout=timeout) as session:
            async with session.get(url, headers=headers, ssl=_make_ssl_param_for_aiohttp()) as resp:
                text = await resp.text()
                await m.answer(
                    f"GET {url}\n"
                    f"sent_header=Authorization: Bearer <{len(tok)} chars>\n"
                    f"status={resp.status}\n"
                    f"body={text[:900]}"
                )
    except Exception as e:
        await m.answer(f"–û—à–∏–±–∫–∞: {e}")

from aiogram import types
import html

# —É–Ω–∏–≤–µ—Ä—Å–∞–ª–∫–∞, —á—Ç–æ–±—ã –±–µ–∑–æ–ø–∞—Å–Ω–æ –æ—Ç–ø—Ä–∞–≤–ª—è—Ç—å –¥–ª–∏–Ω–Ω—ã–µ —Ç–µ–∫—Å—Ç—ã
async def _send_long_html(m: types.Message, html_text: str):
    # Telegram –æ–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ—Ç ~4096 —Å–∏–º–≤–æ–ª–æ–≤ –Ω–∞ —Å–æ–æ–±—â–µ–Ω–∏–µ
    MAX = 4000
    for i in range(0, len(html_text), MAX):
        chunk = html_text[i:i+MAX]
        await m.answer(chunk, parse_mode="HTML", disable_web_page_preview=True)

@dp.message(Command("start"))
async def cmd_start(m: types.Message):
    """
    –ë–µ–∑–æ–ø–∞—Å–Ω–∞—è HTML-—Ä–∞–∑–º–µ—Ç–∫–∞ (–Ω–µ Markdown), –ø—Ä–∏–º–µ—Ä—ã –∫–æ–¥–∞ –≤ <pre><code>.
    –ü–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å: –∑–∞–≥—Ä—É–∑–∫–∞ –∏–Ω–≤–µ–Ω—Ç–∞—Ä—è ‚Üí /ask ‚Üí –ø—Ä—è–º—ã–µ –∫–æ–º–∞–Ω–¥—ã.
    """
    t = []

    # 0) –í—Å—Ç—É–ø–ª–µ–Ω–∏–µ
    t.append(
        "<b>–ü—Ä–∏–≤–µ—Ç! –Ø ‚Äî Omni Helper</b>\n"
        "–ü–æ–º–æ–≥–∞—é –ø–æ–¥–±–∏—Ä–∞—Ç—å —ç–∫—Ä–∞–Ω—ã (DOOH), —Å—Ç—Ä–æ–∏—Ç—å –º–µ–¥–∏–∞–ø–ª–∞–Ω—ã –∏ —Å—á–∏—Ç–∞—Ç—å –ø—Ä–æ–≥–Ω–æ–∑—ã.\n"
    )

    # 1) –û—Ç–∫—É–¥–∞ –±–µ—Ä—É—Ç—Å—è —ç–∫—Ä–∞–Ω—ã
    t.append(
        "üìÇ <b>–° —á–µ–≥–æ –Ω–∞—á–∞—Ç—å</b>\n"
        "‚Ä¢ –ü—Ä–∏—à–ª–∏—Ç–µ —Ñ–∞–π–ª —Å –∏–Ω–≤–µ–Ω—Ç–∞—Ä—ë–º (CSV/XLSX) ‚Äî —è –∑–∞–≥—Ä—É–∂—É –µ–≥–æ –∏ –±—É–¥—É —Ä–∞–±–æ—Ç–∞—Ç—å —Å —ç–∫—Ä–∞–Ω–∞–º–∏.\n"
        "‚Ä¢ –ò–ª–∏, –µ—Å–ª–∏ —É –≤–∞—Å –µ—Å—Ç—å –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ API, –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ <code>/sync_api</code> (—Å —Ñ–∏–ª—å—Ç—Ä–∞–º–∏, –µ—Å–ª–∏ –Ω—É–∂–Ω–æ).\n"
    )

    # 2) –ë—ã—Å—Ç—Ä—ã–π —Å—Ç–∞—Ä—Ç —á–µ—Ä–µ–∑ /ask
    t.append(
        "üí¨ <b>–ë—ã—Å—Ç—Ä—ã–π —Å—Ç–∞—Ä—Ç (–µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω—ã–π —è–∑—ã–∫)</b>\n"
        "–ü–∏—à–∏—Ç–µ –∑–∞–¥–∞—á—É —á–µ—Ä–µ–∑ <code>/ask</code> ‚Äî —è —Å–∞–º–∞ –ø–µ—Ä–µ–≤–µ–¥—É –µ—ë –≤ –∫–æ–º–∞–Ω–¥—ã.\n"
        "–ü—Ä–∏–º–µ—Ä—ã:\n"
        "<pre><code>"
        "/ask –ø–æ–¥–±–µ—Ä–∏ 30 –±–∏–ª–±–æ—Ä–¥–æ–≤ –ø–æ –ú–æ—Å–∫–≤–µ —Ä–∞–≤–Ω–æ–º–µ—Ä–Ω–æ\n"
        "/ask —Å–æ–±–µ—Ä–∏ 100 –±–∏–ª–±–æ—Ä–¥–æ–≤ –∏ —Å—É–ø–µ—Ä—Å–∞–π—Ç–æ–≤ –ø–æ –ü–µ—Ç–µ—Ä–±—É—Ä–≥—É\n"
        "/ask –ø–ª–∞–Ω –Ω–∞ –Ω–µ–¥–µ–ª—é –ø–æ —Å–∏—Ç–∏–±–æ—Ä–¥–∞–º –≤ –†–æ—Å—Ç–æ–≤–µ, 12 —á–∞—Å–æ–≤ –≤ –¥–µ–Ω—å\n"
        "/ask –ø—Ä–æ–≥–Ω–æ–∑ –Ω–∞ 7 –¥–Ω–µ–π –ø–æ –ø–æ—Å–ª–µ–¥–Ω–µ–π –≤—ã–±–æ—Ä–∫–µ, 10 —á–∞—Å–æ–≤ –≤ –¥–µ–Ω—å, –±—é–¥–∂–µ—Ç 300–∫\n"
        "</code></pre>"
    )

    # 3) –ü—Ä—è–º—ã–µ –∫–æ–º–∞–Ω–¥—ã ‚Äî –≤—ã–±–æ—Ä–∫–∏
    t.append(
        "üß≠ <b>–ü—Ä—è–º—ã–µ –∫–æ–º–∞–Ω–¥—ã: –≤—ã–±–æ—Ä–∫–∏ —ç–∫—Ä–∞–Ω–æ–≤</b>\n"
        "‚Ä¢ <code>/pick_city &lt;–ì–æ—Ä–æ–¥|*&gt; N [format=...] [owner=...] [fields=...] [shuffle=1] [fixed=1] [seed=42]</code>\n"
        "  –†–∞–≤–Ω–æ–º–µ—Ä–Ω–∞—è –≤—ã–±–æ—Ä–∫–∞ –ø–æ –≥–æ—Ä–æ–¥—É (–∏–ª–∏ –ø–æ –≤—Å–µ–π —Å—Ç—Ä–∞–Ω–µ, –µ—Å–ª–∏ <code>*</code>).\n"
        "  –ü—Ä–∏–º–µ—Ä—ã:\n"
        "<pre><code>"
        "/pick_city –ú–æ—Å–∫–≤–∞ 20 format=BILLBOARD\n"
        "/pick_city –°–∞–Ω–∫—Ç-–ü–µ—Ç–µ—Ä–±—É—Ä–≥ 100 format=BILLBOARD,SUPERSITE\n"
        "/pick_city –ú–æ—Å–∫–≤–∞ 50 owner=\"Russ Outdoor\" format=CITYFORMAT fixed=1\n"
        "</code></pre>"
        "‚Ä¢ <code>/pick_any N [format=...] [owner=...] [fixed=1] [seed=42]</code> ‚Äî –ø–æ –≤—Å–µ–π —Å—Ç—Ä–∞–Ω–µ.\n"
        "‚Ä¢ <code>/near &lt;lat&gt; &lt;lon&gt; [radius_km=...] [format=...]</code> ‚Äî –≤—Å–µ —ç–∫—Ä–∞–Ω—ã —Ä—è–¥–æ–º —Å —Ç–æ—á–∫–∏.\n"
        "‚Ä¢ <code>/pick_at &lt;lat&gt; &lt;lon&gt; N [radius_km=...] [format=...] [fixed=1]</code> ‚Äî —Ä–∞–≤–Ω–æ–º–µ—Ä–Ω–æ –≤ —Ä–∞–¥–∏—É—Å–µ.\n"
    )

    # 4) –ü—Ä–æ–≥–Ω–æ–∑—ã
    t.append(
        "üìà <b>–ü—Ä–æ–≥–Ω–æ–∑—ã –ø–æ –ø–æ—Å–ª–µ–¥–Ω–µ–π –≤—ã–±–æ—Ä–∫–µ</b>\n"
        "‚Ä¢ <code>/forecast [budget=...] [days=7] [hours_per_day=8] [hours=07-10,17-21]</code>\n"
        "  ‚Äî —Å—á–∏—Ç–∞–µ—Ç –≤—ã—Ö–æ–¥—ã –∏ –±—é–¥–∂–µ—Ç –ø–æ <i>–º–∏–Ω–∏–º–∞–ª—å–Ω—ã–º —Å—Ç–∞–≤–∫–∞–º</i> (minBid) –Ω–∞ –æ—Å–Ω–æ–≤–µ –≤–∞—à–µ–π <i>–ø–æ—Å–ª–µ–¥–Ω–µ–π –≤—ã–±–æ—Ä–∫–∏</i>.\n"
        "–ü—Ä–∏–º–µ—Ä—ã:\n"
        "<pre><code>"
        "/forecast days=7 hours_per_day=10 budget=250000\n"
        "/forecast days=14 hours=07-10,17-21\n"
        "/forecast budget=1.2m days=30 hours_per_day=12\n"
        "</code></pre>"
        "–ü–æ–¥—Å–∫–∞–∑–∫–∏:\n"
        "‚Ä¢ –ï—Å–ª–∏ —É–∫–∞–∑–∞–Ω—ã –æ–∫–Ω–∞ <code>hours=07-10,17-21</code>, —Ç–æ <code>hours_per_day</code> –±–µ—Ä—ë—Ç—Å—è –ø–æ —Ñ–∞–∫—Ç—É –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ —á–∞—Å–æ–≤ –≤ –æ–∫–Ω–∞—Ö.\n"
        "‚Ä¢ –ë—é–¥–∂–µ—Ç –º–æ–∂–Ω–æ –∑–∞–¥–∞–≤–∞—Ç—å –∫–∞–∫ <code>250000</code>, <code>250k</code>, <code>1.2m</code>.\n"
    )

    # 5) –ú–µ–¥–∏–∞–ø–ª–∞–Ω –ø–æ –≥–æ—Ä–æ–¥–∞–º (–±–µ–∑ ¬´–ø–æ—Å–ª–µ–¥–Ω–µ–π –≤—ã–±–æ—Ä–∫–∏¬ª)
    t.append(
        "üßÆ <b>–ú–µ–¥–∏–∞–ø–ª–∞–Ω –ø–æ –≥–æ—Ä–æ–¥–∞–º</b>\n"
        "‚Ä¢ <code>/plan –≥–æ—Ä–æ–¥–∞=–ö–∞–∑–∞–Ω—å;–û—Ä–µ–Ω–±—É—Ä–≥ [format=...] [days=30] [hours=10] [max_per_city=...] [max_total=...] [budget=...] [mode=even|top] [rank=ots|reach]</code>\n"
        "  –ò—Å—Ç–æ—á–Ω–∏–∫ ‚Äî –ª–æ–∫–∞–ª—å–Ω—ã–π –∫—ç—à –∏–Ω–≤–µ–Ω—Ç–∞—Ä—è (CSV/XLSX –∏–ª–∏ <code>/sync_api</code> —Ä–∞–Ω–µ–µ). –í—ã–≥—Ä—É–∂–∞–µ—Ç XLSX —Å–æ —Å–≤–æ–¥–∫–æ–π –∏ –¥–µ—Ç–∞–ª—è–º–∏.\n"
        "–ü—Ä–∏–º–µ—Ä—ã:\n"
        "<pre><code>"
        "/plan –≥–æ—Ä–æ–¥–∞=–ú–æ—Å–∫–≤–∞;–°–∞–Ω–∫—Ç-–ü–µ—Ç–µ—Ä–±—É—Ä–≥ format=BILLBOARD,SUPERSITE days=7 hours=12 budget=2.5m mode=even rank=ots\n"
        "/plan –≥–æ—Ä–æ–¥–∞=–ï–∫–∞—Ç–µ—Ä–∏–Ω–±—É—Ä–≥ max_per_city=30 days=30 hours=10 mode=top rank=reach\n"
        "</code></pre>"
    )

    # 6) –û–±—â–∏–µ –ø–æ–¥—Å–∫–∞–∑–∫–∏
    t.append(
        "üí° <b>–û–±—â–∏–µ –ø–æ–¥—Å–∫–∞–∑–∫–∏</b>\n"
        "‚Ä¢ –£–∫–∞–∑—ã–≤–∞–π—Ç–µ –Ω–µ—Å–∫–æ–ª—å–∫–æ —Ñ–æ—Ä–º–∞—Ç–æ–≤ —á–µ—Ä–µ–∑ –∑–∞–ø—è—Ç—É—é: <code>format=BILLBOARD,SUPERSITE</code>\n"
        "‚Ä¢ –î–ª—è —Å—Ç–∞–±–∏–ª—å–Ω–æ–π –≤—ã–±–æ—Ä–∫–∏ –¥–æ–±–∞–≤—å—Ç–µ <code>fixed=1</code>; –ø–µ—Ä–µ–º–µ—à–∏–≤–∞–Ω–∏–µ ‚Äî <code>shuffle=1</code> (–ø—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏ <code>seed=42</code>).\n"
        "‚Ä¢ –ü–æ—Å–ª–µ –ª—é–±–æ–π –≤—ã–±–æ—Ä–∫–∏ –º–æ–∂–Ω–æ —Å—Ä–∞–∑—É –≤—ã–∑–≤–∞—Ç—å <code>/forecast</code>.\n"
        "‚Ä¢ –í –≤—ã–≥—Ä—É–∑–∫–∞—Ö —è —Å—Ç–∞—Ä–∞—é—Å—å –æ—Ç–¥–∞–≤–∞—Ç—å —Å—Ç–æ–ª–±–µ—Ü <code>GID</code> –≤ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–µ –ø–µ—Ä–µ–¥ <code>screen_id/code/uid/id</code>.\n"
    )

    # 7) –ë—ã—Å—Ç—Ä–∞—è –Ω–∞–≤–∏–≥–∞—Ü–∏—è
    t.append(
        "üÜò <b>–°–ø—Ä–∞–≤–∫–∞</b>\n"
        "–ö–æ–º–∞–Ω–¥–∞ <code>/help</code> –ø–æ–∫–∞–∂–µ—Ç –∫—Ä–∞—Ç–∫–∏–π —Å–ø–∏—Å–æ–∫ –∫–æ–º–∞–Ω–¥ —Å –ø—Ä–∏–º–µ—Ä–∞–º–∏."
    )

    await _send_long_html(m, "\n\n".join(t))

@dp.message(Command("help"))
async def cmd_help(m: types.Message):
    text = (
        "üëã –ü—Ä–∏–≤–µ—Ç! –Ø ‚Äî Omni Helper. –ü–æ–º–æ–≥–∞—é –ø–æ–¥–±–∏—Ä–∞—Ç—å —ç–∫—Ä–∞–Ω—ã, —Å—Ç—Ä–æ–∏—Ç—å –º–µ–¥–∏–∞–ø–ª–∞–Ω—ã –∏ —Å—á–∏—Ç–∞—Ç—å –ø—Ä–æ–≥–Ω–æ–∑—ã.\n\n"
        "üìÇ **–° —á–µ–≥–æ –Ω–∞—á–∞—Ç—å:**\n"
        "–ü—Ä–∏—à–ª–∏ –º–Ω–µ —Ñ–∞–π–ª —Å –∏–Ω–≤–µ–Ω—Ç–∞—Ä—ë–º –≤ —Ñ–æ—Ä–º–∞—Ç–µ CSV –∏–ª–∏ XLSX ‚Äî —è –∑–∞–≥—Ä—É–∂—É –µ–≥–æ –∏ —Å–º–æ–≥—É —Ä–∞–±–æ—Ç–∞—Ç—å —Å —ç–∫—Ä–∞–Ω–∞–º–∏.\n"
        "_–ü—Ä–∏–º–µ—Ä:_ –ø—Ä–æ—Å—Ç–æ –ø–µ—Ä–µ—Ç–∞—â–∏ —Ñ–∞–π–ª –≤ —á–∞—Ç (–∏–ª–∏ –æ—Ç–ø—Ä–∞–≤—å –µ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏–µ–º).\n\n"
        "–ü–æ—Å–ª–µ –∑–∞–≥—Ä—É–∑–∫–∏ —Ñ–∞–π–ª–∞ –º–æ–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –∫–æ–º–∞–Ω–¥—ã –Ω–∏–∂–µ üëá\n\n"
        "üì¶ **–û—Å–Ω–æ–≤–Ω—ã–µ –∫–æ–º–∞–Ω–¥—ã:**\n\n"
        "‚Ä¢ `/pick_city <–≥–æ—Ä–æ–¥> <N> [format=...] [owner=...] [fixed=1]` ‚Äî —Ä–∞–≤–Ω–æ–º–µ—Ä–Ω–∞—è –≤—ã–±–æ—Ä–∫–∞ –ø–æ –≥–æ—Ä–æ–¥—É.\n"
        "  _–ü—Ä–∏–º–µ—Ä:_ `/pick_city –ú–æ—Å–∫–≤–∞ 20 format=BILLBOARD`\n\n"
        "‚Ä¢ `/pick_any <N> [format=...] [fixed=1] [seed=...]` ‚Äî –≤—ã–±–æ—Ä–∫–∞ –ø–æ –≤—Å–µ–π —Å—Ç—Ä–∞–Ω–µ (–±–µ–∑ —É–∫–∞–∑–∞–Ω–∏—è –≥–æ—Ä–æ–¥–∞).\n"
        "  _–ü—Ä–∏–º–µ—Ä:_ `/pick_any 100 format=MEDIAFACADE`\n\n"
        "‚Ä¢ `/pick_at <lat> <lon> <N> [radius_km=...]` ‚Äî –≤—ã–±–æ—Ä–∫–∞ –ø–æ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç–∞–º –∏ —Ä–∞–¥–∏—É—Å—É.\n"
        "  _–ü—Ä–∏–º–µ—Ä:_ `/pick_at 55.751 37.618 15 10 format=BILLBOARD`\n\n"
        "‚Ä¢ `/near <lat> <lon> [radius_km=...]` ‚Äî –ø–æ–∫–∞–∑–∞—Ç—å –≤—Å–µ —ç–∫—Ä–∞–Ω—ã –ø–æ–±–ª–∏–∑–æ—Å—Ç–∏.\n"
        "  _–ü—Ä–∏–º–µ—Ä:_ `/near 59.93 30.33 5`\n\n"
        "üìä **/forecast** ‚Äî –ø—Ä–æ–≥–Ω–æ–∑ –ø–æ–∫–∞–∑–æ–≤ –∏ –±—é–¥–∂–µ—Ç–∞ –ø–æ –ø–æ—Å–ª–µ–¥–Ω–µ–π –≤—ã–±–æ—Ä–∫–µ —ç–∫—Ä–∞–Ω–æ–≤.\n"
        "  –†–∞–±–æ—Ç–∞–µ—Ç –Ω–∞ –æ—Å–Ω–æ–≤–µ minBid –∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –∫–∞–º–ø–∞–Ω–∏–∏.\n\n"
        "  –ü—Ä–∏–º–µ—Ä—ã:\n"
        "  ‚Ä¢ `/forecast budget=2.5m days=7 hours_per_day=10`\n"
        "    ‚Üí –ü—Ä–æ–≥–Ω–æ–∑ –Ω–∞ –Ω–µ–¥–µ–ª—é, 10 —á/–¥–µ–Ω—å, –±—é–¥–∂–µ—Ç 2.5 –º–ª–Ω ‚ÇΩ\n"
        "  ‚Ä¢ `/forecast budget=800k days=14 hours=07-10,17-21`\n"
        "    ‚Üí –ü—Ä–∞–π–º-–æ–∫–Ω–∞, 14 –¥–Ω–µ–π, –±—é–¥–∂–µ—Ç 800 —Ç—ã—Å ‚ÇΩ\n"
        "  ‚Ä¢ `/forecast days=10 hours_per_day=12`\n"
        "    ‚Üí –ë–µ–∑ –±—é–¥–∂–µ—Ç–∞: —Ä–∞—Å—Å—á–∏—Ç–∞—Ç—å –º–∞–∫—Å–∏–º—É–º –ø–æ–∫–∞–∑–æ–≤ –∏ –æ—Ä–∏–µ–Ω—Ç–∏—Ä–æ–≤–æ—á–Ω—É—é —Å—Ç–æ–∏–º–æ—Å—Ç—å\n"
        "  ‚Ä¢ `/forecast hours=9,10,11,18,19`\n"
        "    ‚Üí –£–∫–∞–∑–∞—Ç—å –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ —á–∞—Å—ã –ø–æ–∫–∞–∑–∞\n\n"
        "  üí° –ü–æ–¥—Å–∫–∞–∑–∫–∏:\n"
        "  ‚Ä¢ –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—Ç—Å—è —Å—É—Ñ—Ñ–∏–∫—Å—ã: `m` ‚Äî –º–∏–ª–ª–∏–æ–Ω—ã, `k`/`–∫` ‚Äî —Ç—ã—Å—è—á–∏\n"
        "    (–Ω–∞–ø—Ä–∏–º–µ—Ä, `1.2m` = 1 200 000, `800k` = 800 000)\n"
        "  ‚Ä¢ `hours` –º–æ–∂–Ω–æ –∑–∞–¥–∞–≤–∞—Ç—å –¥–∏–∞–ø–∞–∑–æ–Ω–∞–º–∏ (`07-10`) –∏–ª–∏ —Å–ø–∏—Å–∫–æ–º (`8,9,10`)\n"
        "  ‚Ä¢ –ü–µ—Ä–µ–¥ –≤—ã–∑–æ–≤–æ–º `/forecast` –Ω—É–∂–Ω–æ —Å–Ω–∞—á–∞–ª–∞ –≤—ã–±—Ä–∞—Ç—å —ç–∫—Ä–∞–Ω—ã —á–µ—Ä–µ–∑ `/ask` –∏–ª–∏ `/pick_city`\n\n"
        "üí¨ **/ask** ‚Äî —Å–≤–æ–±–æ–¥–Ω—ã–π –∑–∞–ø—Ä–æ—Å, –±–µ–∑ —Å—Ç—Ä–æ–≥–æ–≥–æ —Å–∏–Ω—Ç–∞–∫—Å–∏—Å–∞.\n"
        "  –Ø —Å–∞–º–∞ –ø–æ–π–º—É, —á—Ç–æ —Ç—ã —Ö–æ—á–µ—à—å —Å–¥–µ–ª–∞—Ç—å (–ø–æ–¥–±–æ—Ä, –ø–ª–∞–Ω –∏–ª–∏ –ø—Ä–æ–≥–Ω–æ–∑).\n\n"
        "  –ü—Ä–∏–º–µ—Ä—ã:\n"
        "  ‚Ä¢ `/ask —Å–æ–±–µ—Ä–∏ 20 –±–∏–ª–±–æ—Ä–¥–æ–≤ —Ä–∞–≤–Ω–æ–º–µ—Ä–Ω–æ –ø–æ –ö–∞–∑–∞–Ω–∏`\n"
        "  ‚Ä¢ `/ask –ø–ª–∞–Ω –Ω–∞ –Ω–µ–¥–µ–ª—é –ø–æ —Å–∏—Ç–∏–±–æ—Ä–¥–∞–º –≤ –†–æ—Å—Ç–æ–≤–µ, 12 —á–∞—Å–æ–≤ –≤ –¥–µ–Ω—å`\n"
        "  ‚Ä¢ `/ask –ø—Ä–æ–≥–Ω–æ–∑ –ø–æ –ø–æ—Å–ª–µ–¥–Ω–µ–π –≤—ã–±–æ—Ä–∫–µ –Ω–∞ 10 –¥–Ω–µ–π, 8 —á–∞—Å–æ–≤ –≤ –¥–µ–Ω—å`\n\n"
        "üßæ **–ß—Ç–æ —è —É–º–µ—é:**\n"
        "‚Äî –ü–æ–¥–±–∏—Ä–∞—Ç—å —ç–∫—Ä–∞–Ω—ã –ø–æ —Ñ–∏–ª—å—Ç—Ä–∞–º (–≥–æ—Ä–æ–¥, —Ñ–æ—Ä–º–∞—Ç, –æ–ø–µ—Ä–∞—Ç–æ—Ä, –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã)\n"
        "‚Äî –§–æ—Ä–º–∏—Ä–æ–≤–∞—Ç—å XLSX-—Ñ–∞–π–ª—ã —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏\n"
        "‚Äî –°—á–∏—Ç–∞—Ç—å –ø—Ä–æ–≥–Ω–æ–∑ –ø–æ minBid –∏ –±—é–¥–∂–µ—Ç—É\n"
        "‚Äî –û—Ç–≤–µ—á–∞—Ç—å –Ω–∞ –∑–∞–ø—Ä–æ—Å—ã –≤ –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ–π —Ñ–æ—Ä–º–µ —á–µ—Ä–µ–∑ `/ask`\n\n"
        "üìò **–ü–æ–¥—Å–∫–∞–∑–∫–∏:**\n"
        "‚Äî –£–∫–∞–∂–∏ `fixed=1`, —á—Ç–æ–±—ã –≤—ã–±–æ—Ä–∫–∞ –±—ã–ª–∞ —Å—Ç–∞–±–∏–ª—å–Ω–æ–π (–æ–¥–∏–Ω–∞–∫–æ–≤–æ–π –ø—Ä–∏ –ø–æ–≤—Ç–æ—Ä–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–∞—Ö)\n"
        "‚Äî –ú–æ–∂–Ω–æ —É–∫–∞–∑–∞—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ —Ñ–æ—Ä–º–∞—Ç–æ–≤ —á–µ—Ä–µ–∑ –∑–∞–ø—è—Ç—É—é: `format=BILLBOARD,MEDIAFACADE`\n"
        "‚Äî –ü–æ—Å–ª–µ –ª—é–±–æ–π –≤—ã–±–æ—Ä–∫–∏ –º–æ–∂–Ω–æ —Å—Ä–∞–∑—É –≤—ã–∑–≤–∞—Ç—å `/forecast`\n\n"
        "üí° _–ü–æ–ø—Ä–æ–±—É–π:_ `/ask –ø–æ–¥–±–µ—Ä–∏ 10 MEDIAFACADE –ø–æ –≤—Å–µ–π —Å—Ç—Ä–∞–Ω–µ`\n"
        "–∏–ª–∏ `/ask –ø—Ä–æ–≥–Ω–æ–∑ –Ω–∞ –Ω–µ–¥–µ–ª—é –ø–æ –ø–æ—Å–ª–µ–¥–Ω–µ–π –≤—ã–±–æ—Ä–∫–µ`"
    )
    await m.answer(text, parse_mode="Markdown")

@dp.message(Command("diag_url"))
async def cmd_diag_url(m: types.Message):
    base = (OBDSP_BASE or "").strip().rstrip("/")
    # –í–ê–ñ–ù–û: –±–µ–∑ clientId –≤ –ø—É—Ç–∏
    root = f"{base}/api/v1.0/clients/inventories"
    await m.answer(f"GET {root}\n(–ø—Ä–∏–º–µ—Ä —Å—Ç—Ä–∞–Ω–∏—Ü—ã) {root}?page=0&size=1")

@dp.message(Command("examples"))
async def cmd_examples(m: types.Message):
    text = (
        "üîç –ü—Ä–∏–º–µ—Ä—ã:\n"
        "‚Ä¢ /near 55.714349 37.553834 2\n"
        "‚Ä¢ /near 55.714349 37.553834 2 fields=screen_id\n"
        "‚Ä¢ /pick_city –ú–æ—Å–∫–≤–∞ 20 fields=screen_id\n"
        "‚Ä¢ /pick_city –ú–æ—Å–∫–≤–∞ 20 format=city fields=screen_id\n"
        "‚Ä¢ /pick_city –ú–æ—Å–∫–≤–∞ 20 format=billboard,supersite mix=billboard:70%,supersite:30% fields=screen_id\n"
        "‚Ä¢ /pick_at 55.75 37.62 25 15\n"
    )
    await m.answer(text, reply_markup=kb_loaded())


@dp.message(Command("sync_api"))
async def cmd_sync_api(m: types.Message):
    if not _owner_only(m.from_user.id):
        await m.answer("‚õîÔ∏è –¢–æ–ª—å–∫–æ –≤–ª–∞–¥–µ–ª–µ—Ü –±–æ—Ç–∞ –º–æ–∂–µ—Ç –≤—ã–ø–æ–ª–Ω—è—Ç—å —ç—Ç—É –∫–æ–º–∞–Ω–¥—É.")
        return

    # --- –ø–∞—Ä—Å–∏–º –æ–ø—Ü–∏–∏ ---
    text = (m.text or "").strip()
    parts = text.split()[1:]

    def _get_opt(name, cast, default):
        for p in parts:
            if p.startswith(name + "="):
                val = p.split("=", 1)[1]
                try:
                    return cast(val)
                except:
                    return default
        return default

    def _as_list(s):
        return [x.strip() for x in str(s).split(",") if x.strip()] if s else []

    pages_limit = _get_opt("pages", int, None)
    page_size   = _get_opt("size", int, 500)
    total_limit = _get_opt("limit", int, None)

    # —Ñ–∏–ª—å—Ç—Ä—ã –≤—ã—Å–æ–∫–æ–≥–æ —É—Ä–æ–≤–Ω—è
    city     = _get_opt("city", str, "").strip()
    formats  = _as_list(_get_opt("formats", str, "") or _get_opt("format", str, ""))
    owners   = _as_list(_get_opt("owners", str, "")  or _get_opt("owner", str, ""))

    # –ª—é–±—ã–µ –¥–æ–ø. api.* -> –ø—Ä—è–º–æ –≤ query
    raw_api = {}
    for p in parts:
        if p.startswith("api.") and "=" in p:
            k, v = p.split("=", 1)
            raw_api[k[4:]] = v

    filters = {
        "city": city,
        "formats": formats,
        "owners": owners,
        "api_params": raw_api,
    }

    pretty = []
    if city:    pretty.append(f"city={city}")
    if formats: pretty.append(f"formats={','.join(formats)}")
    if owners:  pretty.append(f"owners={','.join(owners)}")
    if raw_api: pretty.append("+" + "&".join(f"{k}={v}" for k, v in raw_api.items()))
    hint = (" (—Ñ–∏–ª—å—Ç—Ä—ã: " + ", ".join(pretty) + ")") if pretty else ""
    await m.answer("‚è≥ –¢—è–Ω—É –∏–Ω–≤–µ–Ω—Ç–∞—Ä—å –∏–∑ –≤–Ω–µ—à–Ω–µ–≥–æ API‚Ä¶" + hint)

    # --- —Ç—è–Ω–µ–º, –Ω–æ—Ä–º–∞–ª–∏–∑—É–µ–º, —Å–æ—Ö—Ä–∞–Ω—è–µ–º ---
    try:
        items = await _fetch_inventories(
            pages_limit=pages_limit,
            page_size=page_size,
            total_limit=total_limit,
            m=m,
            filters=filters,   # –í–ê–ñ–ù–û: —Ñ–∏–ª—å—Ç—Ä—ã —É–µ–¥—É—Ç –ø—Ä—è–º–æ –≤ –∑–∞–ø—Ä–æ—Å
        )
    except Exception as e:
        logging.exception("sync_api failed")
        await m.answer(f"üö´ –ù–µ —É–¥–∞–ª–æ—Å—å —Å–∏–Ω–∫–Ω—É—Ç—å: {e}")
        return

    if not items:
        await m.answer("API –≤–µ—Ä–Ω—É–ª –ø—É—Å—Ç–æ–π —Å–ø–∏—Å–æ–∫.")
        return

    # –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è -> DataFrame
    df = _normalize_api_to_df(items)   # <--- –ø—Ä–∞–≤–∏–ª—å–Ω–æ–µ –∏–º—è —Ñ—É–Ω–∫—Ü–∏–∏
    if df.empty:
        await m.answer("–°–ø–∏—Å–æ–∫ –ø—Ä–∏—à—ë–ª, –Ω–æ –ø–æ—Å–ª–µ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏ –ø—É—Å—Ç–æ (–ø—Ä–æ–≤–µ—Ä—å –º–∞–ø–ø–∏–Ω–≥ –ø–æ–ª–µ–π).")
        return

    # –≤ –ø–∞–º—è—Ç—å
    global SCREENS
    SCREENS = df

    # —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –∫—ç—à –Ω–∞ –¥–∏—Å–∫
    try:
        if save_screens_cache(df):
            await m.answer(f"üíæ –ö—ç—à —Å–æ—Ö—Ä–∞–Ω—ë–Ω –Ω–∞ –¥–∏—Å–∫: {len(df)} —Å—Ç—Ä–æ–∫.")
        else:
            await m.answer("‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –∫—ç—à –Ω–∞ –¥–∏—Å–∫.")
    except Exception as e:
        await m.answer(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ –∫—ç—à–∞: {e}")

    # --- –æ—Ç–ø—Ä–∞–≤–∫–∞ CSV ---
    try:
        csv_bytes = df.to_csv(index=False).encode("utf-8-sig")
        await bot.send_document(
            m.chat.id,
            BufferedInputFile(csv_bytes, filename="inventories_sync.csv"),
            caption=f"–ò–Ω–≤–µ–Ω—Ç–∞—Ä—å –∏–∑ API: {len(df)} —Å—Ç—Ä–æ–∫ (CSV)"
        )
    except Exception as e:
        await m.answer(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –æ—Ç–ø—Ä–∞–≤–∏—Ç—å CSV: {e}")

    # --- –æ—Ç–ø—Ä–∞–≤–∫–∞ XLSX ---
    try:
        xlsx_buf = io.BytesIO()
        with pd.ExcelWriter(xlsx_buf, engine="openpyxl") as writer:
            df.to_excel(writer, index=False, sheet_name="inventories")
        xlsx_buf.seek(0)
        await bot.send_document(
            m.chat.id,
            BufferedInputFile(xlsx_buf.getvalue(), filename="inventories_sync.xlsx"),
            caption=f"–ò–Ω–≤–µ–Ω—Ç–∞—Ä—å –∏–∑ API: {len(df)} —Å—Ç—Ä–æ–∫ (XLSX)"
        )
    except Exception as e:
        await m.answer(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –æ—Ç–ø—Ä–∞–≤–∏—Ç—å XLSX: {e} (–ø—Ä–æ–≤–µ—Ä—å, —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –ª–∏ openpyxl)")

    await m.answer(f"‚úÖ –°–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è –æ–∫: {len(df)} —ç–∫—Ä–∞–Ω–æ–≤.")

# === –§–£–ù–ö–¶–ò–Ø –ü–û–î–¢–Ø–ì–ò–í–ê–ù–ò–Ø –î–ê–ù–ù–´–• –ò–ó API ===
import aiohttp
import pandas as pd
import os

INVENTORY_API_URL = os.getenv("INVENTORY_API_URL", "").strip()
INVENTORY_API_TOKEN = os.getenv("OBDSP_TOKEN", "").strip()

async def _sync_api_pull(city=None, formats=None, owners=None):
    """
    –ó–∞–≥—Ä—É–∂–∞–µ—Ç –∏–Ω–≤–µ–Ω—Ç–∞—Ä—å –∏–∑ –≤–Ω–µ—à–Ω–µ–≥–æ API Omni360 / DSP.
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç pandas.DataFrame —Å –∫–æ–ª–æ–Ω–∫–∞–º–∏: screen_id, name, lat, lon, city, format, owner.
    """
    if not INVENTORY_API_URL:
        raise RuntimeError("INVENTORY_API_URL –Ω–µ –∑–∞–¥–∞–Ω –≤ .env")

    params = {}
    if city:
        params["city"] = city
    if formats:
        params["formats"] = ",".join(formats)
    if owners:
        params["owners"] = ",".join(owners)

    headers = {}
    if INVENTORY_API_TOKEN:
        headers["Authorization"] = f"Bearer {INVENTORY_API_TOKEN}"  # –µ—Å–ª–∏ —Ç—Ä–µ–±—É–µ—Ç—Å—è –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏—è

    async with aiohttp.ClientSession() as session:
        async with session.get(INVENTORY_API_URL, params=params, headers=headers, timeout=aiohttp.ClientTimeout(total=60)) as resp:
            if resp.status != 200:
                raise RuntimeError(f"API –≤–µ—Ä–Ω—É–ª —Å—Ç–∞—Ç—É—Å {resp.status}")
            data = await resp.json()

    # API –º–æ–∂–µ—Ç –≤–µ—Ä–Ω—É—Ç—å —Å–ø–∏—Å–æ–∫ –∏–ª–∏ {"items": [...]} ‚Äî –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –æ–±–∞ –≤–∞—Ä–∏–∞–Ω—Ç–∞
    items = data.get("items") if isinstance(data, dict) and "items" in data else data
    if not items:
        return pd.DataFrame()

    # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º —Å–ø–∏—Å–æ–∫ —Å–ª–æ–≤–∞—Ä–µ–π –≤ DataFrame
    df = pd.DataFrame(items)

    # –£–Ω–∏—Ñ–∏–∫–∞—Ü–∏—è –Ω–∞–∑–≤–∞–Ω–∏–π –∫–æ–ª–æ–Ω–æ–∫
    rename_map = {
        "id": "screen_id",
        "screenId": "screen_id",
        "title": "name",
        "latitude": "lat",
        "longitude": "lon",
    }
    df = df.rename(columns={k: v for k, v in rename_map.items() if k in df.columns})

    # –î–æ–±–∞–≤–ª—è–µ–º –Ω–µ–¥–æ—Å—Ç–∞—é—â–∏–µ –ø–æ–ª—è
    for col in ["screen_id", "name", "lat", "lon", "city", "format", "owner"]:
        if col not in df.columns:
            df[col] = None

    # –ß–∏—Å—Ç–∏–º –∏ –ø—Ä–∏–≤–æ–¥–∏–º —Ç–∏–ø—ã
    try:
        df["lat"] = df["lat"].astype(float)
        df["lon"] = df["lon"].astype(float)
    except Exception:
        pass

    return df[["screen_id", "name", "lat", "lon", "city", "format", "owner"]]


@dp.message(Command("pick_city"))
async def pick_city(m: types.Message, _call_args: dict | None = None):
    """
    –†–∞–≤–Ω–æ–º–µ—Ä–Ω–∞—è –≤—ã–±–æ—Ä–∫–∞ –ø–æ –≥–æ—Ä–æ–¥—É (–∏–ª–∏ –ø–æ –≤—Å–µ–π —Å—Ç—Ä–∞–Ω–µ, –µ—Å–ª–∏ city='*' –∏–ª–∏ –ø—É—Å—Ç–æ).

    –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º –î–í–ê —Å–∏–Ω—Ç–∞–∫—Å–∏—Å–∞:
      1) –ø–æ–∑–∏—Ü–∏–æ–Ω–Ω—ã–π: /pick_city <–ì–æ—Ä–æ–¥|*> <N> [format=...] [owner=...] [fields=...] [shuffle=1] [fixed=1] [seed=42]
      2) key=value:   /pick_city city=<–ì–æ—Ä–æ–¥|*> n=<N> [formats=...] [owner=...] [fields=...] [shuffle=1] [fixed=1] [seed=42]
    """
    import re as _re
    import numpy as np
    import pandas as pd

    global LAST_RESULT, LAST_SELECTION_NAME, SCREENS

    if SCREENS is None or SCREENS.empty:
        await m.answer("–°–Ω–∞—á–∞–ª–∞ –∑–∞–≥—Ä—É–∑–∏—Ç–µ –∏–Ω–≤–µ–Ω—Ç–∞—Ä—å (CSV/XLSX –∏–ª–∏ /sync_api).")
        return

    # ---------------- helpers ----------------
    CITY_ALIASES = {
        "—Å–ø–±": "–°–∞–Ω–∫—Ç-–ü–µ—Ç–µ—Ä–±—É—Ä–≥",
        "–ø–∏—Ç–µ—Ä": "–°–∞–Ω–∫—Ç-–ü–µ—Ç–µ—Ä–±—É—Ä–≥",
        "—Å–∞–Ω–∫—Ç –ø–µ—Ç–µ—Ä–±—É—Ä–≥": "–°–∞–Ω–∫—Ç-–ü–µ—Ç–µ—Ä–±—É—Ä–≥",
        "—Å–∞–Ω–∫—Ç-–ø–µ—Ç–µ—Ä–±—É—Ä–≥": "–°–∞–Ω–∫—Ç-–ü–µ—Ç–µ—Ä–±—É—Ä–≥",
        "–ø–µ—Ç–µ—Ä–±—É—Ä–≥": "–°–∞–Ω–∫—Ç-–ü–µ—Ç–µ—Ä–±—É—Ä–≥",
        "–º–æ—Å–∫–≤–∞": "–ú–æ—Å–∫–≤–∞",   
        "–º–æ—Å–∫–≤–µ": "–ú–æ—Å–∫–≤–∞",
    }

    def _parse_kwargs(tokens: list[str]) -> dict:
        out = {}
        for x in tokens:
            if "=" in x:
                k, v = x.split("=", 1)
                out[k.strip().lower()] = v.strip().strip('"').strip("'")
        return out

    def _as_list(val) -> list[str]:
        if val is None:
            return []
        return [s.strip() for s in str(val).replace(";", ",").replace("|", ",").split(",") if s.strip()]

    def _norm_city(s: str) -> str:
        # –ø—Ä–∏–≤–æ–¥–∏–º –∫ –Ω–∏–∂–Ω–µ–º—É, —É–±–∏—Ä–∞–µ–º —ë, –¥–µ—Ñ–∏—Å—ã -> –ø—Ä–æ–±–µ–ª, —Å—Ö–ª–æ–ø—ã–≤–∞–µ–º –ø—Ä–æ–±–µ–ª—ã
        ss = str(s or "").lower().replace("—ë", "–µ").replace("-", " ")
        ss = " ".join(ss.split())
        return ss

    def _canon_city(user_city: str) -> str:
        cn = _norm_city(user_city)
        # –∞–ª–∏–∞—Å—ã —Å–Ω–∞—á–∞–ª–∞
        if cn in CITY_ALIASES:
            return CITY_ALIASES[cn]
        # –ø—Ä–æ—Å—Ç—ã–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã "—Å–ø–±." –∏ —Ç.–ø. –±–µ–∑ —Ç–æ—á–∫–∏
        cn_nopunct = cn.replace(".", "")
        if cn_nopunct in CITY_ALIASES:
            return CITY_ALIASES[cn_nopunct]
        # –∏–Ω–∞—á–µ –≤–µ—Ä–Ω—ë–º –∏—Å—Ö–æ–¥–Ω—ã–π –≤–≤–æ–¥ (–ø—É—Å—Ç—å –º–∞—Ç—á–∏—Ç—Å—è –ø–æ –ø–æ–¥—Å—Ç—Ä–æ–∫–µ)
        return user_city

    def _norm_format_val(s: str) -> str:
        return (s or "").strip().upper().replace(" ", "_").replace("-", "_")

    # ---------------- parse ----------------
    if _call_args is not None:
        try:
            raw_city = str(_call_args.get("city", "")).strip()
            n        = int(_call_args.get("n", 20))
        except Exception:
            await m.answer("–ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞–∑–æ–±—Ä–∞—Ç—å –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è /pick_city (city/n).")
            return

        kwargs: dict[str, str] = {}
        if _call_args.get("formats"):
            kwargs["formats"] = ",".join(str(x).strip() for x in _call_args["formats"] if str(x).strip())
        if _call_args.get("owners"):
            kwargs["owner"] = ",".join(str(x).strip() for x in _call_args["owners"] if str(x).strip())
        if _call_args.get("fields"):
            kwargs["fields"] = ",".join(str(x).strip() for x in _call_args["fields"] if str(x).strip())

        shuffle_flag = bool(_call_args.get("shuffle") or False)
        fixed        = bool(_call_args.get("fixed")   or False)
        seed_val     = _call_args.get("seed", None)
        seed         = int(seed_val) if seed_val is not None and str(seed_val).isdigit() else None
    else:
        parts = (m.text or "").strip().split()
        if len(parts) < 2:
            await m.answer(
                "–§–æ—Ä–º–∞—Ç—ã:\n"
                "‚Ä¢ `/pick_city <–ì–æ—Ä–æ–¥|*> <N> [format=...] [owner=...] [fields=...] [shuffle=1] [fixed=1] [seed=42]`\n"
                "‚Ä¢ `/pick_city city=<–ì–æ—Ä–æ–¥|*> n=<N> [formats=...] [owner=...] [fields=...] [shuffle=1] [fixed=1] [seed=42]`",
                parse_mode="Markdown",
            )
            return

        tokens = parts[1:]

        # --- –ì–ò–ë–†–ò–î–ù–´–ô –ü–ê–†–°–ò–ù–ì ---
        # –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º: /pick_city <city> <n> formats=...
        # –∏:           /pick_city city=<...> n=<...> formats=...
        head = []
        tail = []
        met_eq = False
        for t in tokens:
            if not met_eq and "=" not in t:
                head.append(t)
            else:
                met_eq = True
                tail.append(t)

        kwargs = _parse_kwargs(tail) if tail else {}

        city_from_head = None
        n_from_head = None
        if len(head) >= 2:
            # –ø–æ–∑–∏—Ü–∏–æ–Ω–Ω—ã–π —Å–∏–Ω—Ç–∞–∫—Å–∏—Å –≤ –≥–æ–ª–æ–≤–µ
            try:
                n_from_head = int(head[-1])
                city_from_head = " ".join(head[:-1]).strip()
            except Exception:
                pass

        if city_from_head is not None and n_from_head is not None:
            raw_city = city_from_head
            n = n_from_head
        else:
            # –ø—Ä–æ–±—É–µ–º key=value
            raw_city = str(kwargs.get("city", "")).strip()
            try:
                n = int(float(kwargs.get("n", 20)))
            except Exception:
                await m.answer("–£–∫–∞–∂–∏ `n=<—á–∏—Å–ª–æ>` –∏–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–π –ø–æ–∑–∏—Ü–∏–æ–Ω–Ω—ã–π —Å–∏–Ω—Ç–∞–∫—Å–∏—Å: `/pick_city –°–∞–Ω–∫—Ç-–ü–µ—Ç–µ—Ä–±—É—Ä–≥ 100`.")
                return

        shuffle_flag = str(kwargs.get("shuffle", "0")).lower() in {"1", "true", "yes", "on", "y"}
        fixed        = str(kwargs.get("fixed",   "0")).lower() in {"1", "true", "yes", "on", "y"}
        seed         = kwargs.get("seed", None)
        seed         = int(seed) if seed is not None and str(seed).isdigit() else None

    # —Å–ø–∏—Å–∫–∏-–∞—Ä–≥—É–º–µ–Ω—Ç—ã
    fmt_raw = kwargs.get("formats", kwargs.get("format"))
    formats = [_norm_format_val(s) for s in _as_list(fmt_raw)]
    owners  = _as_list(kwargs.get("owner", kwargs.get("owners", "")))
    fields  = _as_list(kwargs.get("fields", ""))

    # ---------------- data prep ----------------
    df = SCREENS.copy()

    if "city" not in df.columns:
        await m.answer("–í –¥–∞–Ω–Ω—ã—Ö –Ω–µ—Ç —Å—Ç–æ–ª–±—Ü–∞ city. –î–ª—è –æ—Ç–±–æ—Ä–∞ –ø–æ –≥–æ—Ä–æ–¥—É –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ /near –∏–ª–∏ /sync_api —Å –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–µ–π.")
        return
    if "format" not in df.columns:
        df["format"] = ""

    # –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è
    df["format_norm"] = (
        df.get("format", "")
          .astype(str)
          .str.upper()
          .str.replace(" ", "_", regex=False)
          .str.replace("-", "_", regex=False)
    )

    # –Ω–æ—Ä–º–∞–ª–∏–∑—É–µ–º –≥–æ—Ä–æ–¥ –≤ —Ç–∞–±–ª–∏—Ü–µ
    df["_city_norm"] = (
        df["city"].astype(str)
        .str.lower()
        .str.replace("—ë", "–µ", regex=False)
        .str.replace("-", " ", regex=False)
        .map(lambda s: " ".join(s.split()))
    )

    # ---------------- filters ----------------
    # –∫–∞–Ω–æ–Ω–∏–∑–∏—Ä—É–µ–º –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–π –≤–≤–æ–¥ (–°–ü–±, –ü–∏—Ç–µ—Ä ‚Üí –°–∞–Ω–∫—Ç-–ü–µ—Ç–µ—Ä–±—É—Ä–≥)
    city_canon = _canon_city(raw_city)
    city_norm_input = _norm_city(city_canon)
    all_cities = (city_norm_input == "" or city_norm_input == "*")

    if not all_cities:
        # –º–∞—Ç—á–∏–º ¬´—É–º–Ω–æ¬ª: –ø–æ–ª–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ, –ø–æ–¥—Å—Ç—Ä–æ–∫–∞, –∏ –±–µ–∑ –ø—Ä–æ–±–µ–ª–æ–≤
        inp_nowh = city_norm_input.replace(" ", "")
        def _city_match(x: str) -> bool:
            x = str(x or "")
            if not x:
                return False
            x_nowh = x.replace(" ", "")
            return (
                x == city_norm_input
                or city_norm_input in x
                or x in city_norm_input
                or inp_nowh in x_nowh
                or x_nowh in inp_nowh
            )
        mask_city = df["_city_norm"].apply(_city_match)
        subset = df[mask_city].copy()
    else:
        subset = df.copy()

    # —Ñ–æ—Ä–º–∞—Ç—ã
    if formats:
        subset = subset[subset["format_norm"].isin(set(formats))].copy()

    # –ø–æ–¥—Ä—è–¥—á–∏–∫–∏ (–∏—â–µ–º –≤ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –∫–æ–ª–æ–Ω–∫–∞—Ö –ø–æ –ø–æ–¥—Å—Ç—Ä–æ–∫–µ)
    if owners:
        owner_cols = [c for c in ["owner", "vendor", "operator", "company"] if c in subset.columns]
        if owner_cols:
            pat = _re.compile("|".join(_re.escape(o) for o in owners), _re.IGNORECASE)
            def _own_hit(row) -> bool:
                for c in owner_cols:
                    v = str(row.get(c, "") or "")
                    if pat.search(v):
                        return True
                return False
            subset = subset[subset[owner_cols].apply(lambda r: _own_hit(r), axis=1)].copy()

    if subset.empty:
        where = "–ø–æ –≤—Å–µ–π —Å—Ç—Ä–∞–Ω–µ" if all_cities else f"–≤ –≥–æ—Ä–æ–¥–µ: {city_canon or raw_city}"
        await m.answer(f"–ù–µ –Ω–∞—à—ë–ª —ç–∫—Ä–∞–Ω–æ–≤ {where} (—Å —É—á—ë—Ç–æ–º —Ñ–∏–ª—å—Ç—Ä–æ–≤).")
        return

    # ---------------- shuffle / determinism ----------------
    if shuffle_flag:
        subset = subset.sample(
            frac=1,
            random_state=(None if seed is None else np.random.RandomState(seed))
        ).reset_index(drop=True)

    # ---------------- even selection ----------------
    try:
        res = spread_select(
            subset.reset_index(drop=True),
            int(max(0, n)),
            random_start=not bool(fixed),
            seed=seed
        )
    except Exception:
        res = subset.reset_index(drop=True).head(int(max(0, n)))

    if res is None or res.empty:
        await m.answer("–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–±—Ä–∞—Ç—å –≤—ã–±–æ—Ä–∫—É (–≤–æ–∑–º–æ–∂–Ω–æ, —Å–ª–∏—à–∫–æ–º –º–∞–ª–æ –ø–æ–¥—Ö–æ–¥—è—â–∏—Ö —ç–∫—Ä–∞–Ω–æ–≤).")
        return

    # ---------------- persist last selection ----------------
    LAST_RESULT = res
    sel_city = "*" if all_cities else (city_canon or raw_city)
    fmttag   = ",".join(formats) if formats else "ALL"
    owner_tag = ",".join(owners) if owners else "ANY"
    LAST_SELECTION_NAME = f"city={sel_city}|n={len(res)}|fmt={fmttag}|owner={owner_tag}"

    # ---------------- files ----------------
    where_caption = "–ø–æ –≤—Å–µ–π —Å—Ç—Ä–∞–Ω–µ" if all_cities else f"–ø–æ –≥–æ—Ä–æ–¥—É ¬´{sel_city}¬ª"
    cap_filters = []
    if formats: cap_filters.append(f"format={','.join(formats)}")
    if owners:  cap_filters.append(f"owner~{owner_tag}")
    filters_str = (", " + ", ".join(cap_filters)) if cap_filters else ""
    caption = f"–í—ã–±—Ä–∞–Ω–æ {len(res)} —ç–∫—Ä–∞–Ω–æ–≤ {where_caption}{filters_str}"

    await send_selection_files(
        m,
        res,  # GID/–ø–µ—Ä–µ–∏–º–µ–Ω–æ–≤–∞–Ω–∏—è ‚Äî –≤–Ω—É—Ç—Ä–∏ send_selection_files
        basename="city_selection",
        caption_prefix=caption,
        fields=(fields if fields else None)
    )
    
@dp.message(Command("pick_at"))
async def pick_at(m: types.Message, _call_args: Optional[Dict[str, Any]] = None):
    """
    –†–∞–≤–Ω–æ–º–µ—Ä–Ω–∞—è –≤—ã–±–æ—Ä–∫–∞ N —ç–∫—Ä–∞–Ω–æ–≤ –≤ –∫—Ä—É–≥–µ —Å —Ü–µ–Ω—Ç—Ä–æ–º lat/lon –∏ —Ä–∞–¥–∏—É—Å–æ–º radius_km.

    –†–µ–∂–∏–º—ã:
      1) /pick_at <lat> <lon> <N> [radius_km] [format=...] [owner=...] [fields=...] [shuffle=1] [fixed=1] [seed=42]
      2) –í—ã–∑–æ–≤ –∏–∑ /ask: pick_at(m, _call_args={lat, lon, n, radius_km?, formats?, owners?, fields?, shuffle?, fixed?, seed?, mix?})

    –í—ã–≤–æ–¥: —Ç–æ–ª—å–∫–æ —Ñ–∞–π–ª—ã (CSV/XLSX) —á–µ—Ä–µ–∑ send_selection_files, –±–µ–∑ –¥–ª–∏–Ω–Ω—ã—Ö —Å–ø–∏—Å–∫–æ–≤ –≤ —á–∞—Ç.
    """
    global LAST_RESULT, SCREENS

    if SCREENS is None or SCREENS.empty:
        await m.answer("–°–Ω–∞—á–∞–ª–∞ –∑–∞–≥—Ä—É–∑–∏—Ç–µ –∏–Ω–≤–µ–Ω—Ç–∞—Ä—å (CSV/XLSX –∏–ª–∏ /sync_api).")
        return

    # ---- —Ä–µ–∂–∏–º 1: –ø—Ä—è–º–æ–π –≤—ã–∑–æ–≤ –∏–∑ /ask ----
    if _call_args:
        try:
            lat    = float(_call_args["lat"])
            lon    = float(_call_args["lon"])
            n      = int(_call_args.get("n", 20))
            radius = float(_call_args.get("radius_km", 20.0))
        except Exception:
            await m.answer("–ù–µ –ø–æ–Ω—è–ª –ø–∞—Ä–∞–º–µ—Ç—Ä—ã pick_at (lat/lon/n/radius).")
            return

        formats      = [str(x).upper().strip() for x in (_call_args.get("formats") or []) if str(x).strip()]
        owners       = [str(x).strip()         for x in (_call_args.get("owners")  or []) if str(x).strip()]
        fields       = [str(x).strip()         for x in (_call_args.get("fields")  or []) if str(x).strip()]
        shuffle_flag = bool(_call_args.get("shuffle") or False)
        fixed        = bool(_call_args.get("fixed")   or False)
        seed         = _call_args.get("seed", None)
        mix_arg      = _call_args.get("mix", None)

    # ---- —Ä–µ–∂–∏–º 2: –ø–∞—Ä—Å–∏–º —Ç–µ–∫—Å—Ç /pick_at ----
    else:
        parts = (m.text or "").strip().split()
        if len(parts) < 4:
            await m.answer("–§–æ—Ä–º–∞—Ç: /pick_at <lat> <lon> <N> [radius_km] [format=...] [owner=...] [fields=...]")
            return
        try:
            lat = float(parts[1]); lon = float(parts[2]); n = int(parts[3])
            if len(parts) >= 5 and "=" not in parts[4]:
                radius = float(parts[4].strip("[](){}"))
                tail_from = 5
            else:
                radius = 20.0
                tail_from = 4
        except Exception:
            await m.answer("–ü—Ä–∏–º–µ—Ä: /pick_at 55.75 37.62 30 15")
            return

        def _parse_kwargs(lst):
            out = {}
            for p in lst:
                if "=" in p:
                    k, v = p.split("=", 1)
                    out[k.strip().lower()] = v.strip().strip('"').strip("'")
            return out

        raw = _parse_kwargs(parts[tail_from:])

        def _as_list(val):
            return [s.strip() for s in str(val).replace(";", ",").replace("|", ",").split(",") if s.strip()]

        formats      = [s.upper() for s in _as_list(raw.get("format", raw.get("formats", "")))]
        owners       = _as_list(raw.get("owner", raw.get("owners", "")))
        fields       = _as_list(raw.get("fields", ""))
        shuffle_flag = str(raw.get("shuffle", "0")).lower() in {"1", "true", "yes", "on"}
        fixed        = str(raw.get("fixed",   "0")).lower() in {"1", "true", "yes", "on"}
        seed         = int(raw["seed"]) if str(raw.get("seed","")).isdigit() else None
        mix_arg      = raw.get("mix") or raw.get("mix_formats")

    # --- –≤—ã–±–æ—Ä–∫–∞ –ø–æ —Ä–∞–¥–∏—É—Å—É ---
    subset = find_within_radius(SCREENS, (lat, lon), radius)
    if subset is None or subset.empty:
        await m.answer(f"–í —Ä–∞–¥–∏—É—Å–µ {radius:g} –∫–º –Ω–∏—á–µ–≥–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ.")
        return

    # --- —Ñ–∏–ª—å—Ç—Ä—ã —Ñ–æ—Ä–º–∞—Ç–∞/–≤–ª–∞–¥–µ–ª—å—Ü–∞ ---
    if formats and "format" in subset.columns:
        subset = subset[subset["format"].astype(str).str.upper().isin(set(formats))]
    if owners and "owner" in subset.columns:
        import re as _re
        pat = "|".join(_re.escape(o) for o in owners)
        subset = subset[subset["owner"].astype(str).str.contains(pat, case=False, na=False)]

    if subset.empty:
        await m.answer("–ü–æ—Å–ª–µ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è —Ñ–∏–ª—å—Ç—Ä–æ–≤ ‚Äî –ø—É—Å—Ç–æ.")
        return

    # –ª—ë–≥–∫–∞—è –≤–∞—Ä–∏–∞—Ç–∏–≤–Ω–æ—Å—Ç—å
    if shuffle_flag:
        subset = subset.sample(frac=1, random_state=None).reset_index(drop=True)

    # --- —Ä–∞–≤–Ω–æ–º–µ—Ä–Ω—ã–π –≤—ã–±–æ—Ä (–∏–ª–∏ —Å mix) ---
    try:
        if mix_arg and "_select_with_mix" in globals() and callable(globals()["_select_with_mix"]):
            res = _select_with_mix(
                subset.reset_index(drop=True),
                n,
                mix_arg,
                random_start=not fixed,
                seed=seed
            )
        else:
            res = spread_select(
                subset.reset_index(drop=True),
                n,
                random_start=not fixed,
                seed=seed
            )
    except Exception:
        res = subset.reset_index(drop=True).head(n)

    if res is None or res.empty:
        await m.answer("–ù–µ –ø–æ–ª—É—á–∏–ª–æ—Å—å –ø–æ–¥–æ–±—Ä–∞—Ç—å —ç–∫—Ä–∞–Ω—ã (—Å–ª–∏—à–∫–æ–º —Å—Ç—Ä–æ–≥–∏–µ —Ñ–∏–ª—å—Ç—Ä—ã?).")
        return

    LAST_RESULT = res

    # --- —Ç–æ–ª—å–∫–æ —Ñ–∞–π–ª—ã (CSV/XLSX), –±–µ–∑ –¥–ª–∏–Ω–Ω—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π ---
    caption = f"–í—ã–±—Ä–∞–Ω–æ {len(res)} —ç–∫—Ä–∞–Ω–æ–≤ –≤ —Ä–∞–¥–∏—É—Å–µ {radius:g} –∫–º –≤–æ–∫—Ä—É–≥ [{lat:.5f}, {lon:.5f}]"
    await send_selection_files(
        m,
        res,
        basename="pick_at_selection",
        caption_prefix=caption,
        fields=(fields if fields else None)
    )

@dp.message(Command("diag_env"))
async def cmd_diag_env(m: types.Message):
    base = OBDSP_BASE
    cid  = OBDSP_CLIENT_ID
    tok_len = len(OBDSP_TOKEN or "")
    await m.answer(f"BASE={base}\nCLIENT_ID={cid}\nTOKEN_LEN={tok_len}")

@dp.message(F.content_type.in_({"document"}))
async def on_file(m: types.Message):
    """–ü—Ä–∏–Ω–∏–º–∞–µ–º CSV/XLSX –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –ø–∞–º—è—Ç—å."""
    try:
        file = await bot.get_file(m.document.file_id)
        file_bytes = await bot.download_file(file.file_path)
        data = file_bytes.read()

        # —á–∏—Ç–∞–µ–º CSV/XLSX
        if m.document.file_name.lower().endswith(".xlsx"):
            df = pd.read_excel(io.BytesIO(data))
        else:
            try:
                df = pd.read_csv(io.BytesIO(data), encoding="utf-8-sig")
            except:
                df = pd.read_csv(io.BytesIO(data))

        # –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –∫–æ–ª–æ–Ω–æ–∫
        rename_map = {
            "Screen_ID": "screen_id", "ScreenId": "screen_id", "id": "screen_id", "ID": "screen_id",
            "Name": "name", "–ù–∞–∑–≤–∞–Ω–∏–µ": "name",
            "Latitude": "lat", "Lat": "lat", "–®–∏—Ä–æ—Ç–∞": "lat",
            "Longitude": "lon", "Lon": "lon", "–î–æ–ª–≥–æ—Ç–∞": "lon",
            "City": "city", "–ì–æ—Ä–æ–¥": "city",
            "Format": "format", "–§–æ—Ä–º–∞—Ç": "format",
            "Owner": "owner", "–í–ª–∞–¥–µ–ª–µ—Ü": "owner", "–û–ø–µ—Ä–∞—Ç–æ—Ä": "owner"
        }
        df = df.rename(columns=rename_map)

        if not {"lat","lon"}.issubset(df.columns):
            await m.answer("–ù—É–∂–Ω—ã –∫–æ–ª–æ–Ω–∫–∏ –º–∏–Ω–∏–º—É–º: lat, lon. (–û–ø—Ü.: screen_id, name, city, format, owner)")
            return

        # –ø—Ä–∏–≤–µ–¥–µ–Ω–∏–µ —Ç–∏–ø–æ–≤
        df["lat"] = pd.to_numeric(df["lat"], errors="coerce")
        df["lon"] = pd.to_numeric(df["lon"], errors="coerce")
        df = df.dropna(subset=["lat","lon"])

        # –∑–∞–ø–æ–ª–Ω—è–µ–º –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∏–µ
        for col in ["screen_id","name","city","format","owner"]:
            if col not in df.columns:
                df[col] = ""

        global SCREENS
        SCREENS = df[["screen_id","name","lat","lon","city","format","owner"]].reset_index(drop=True)
        await m.answer(
            f"–ó–∞–≥—Ä—É–∂–µ–Ω–æ —ç–∫—Ä–∞–Ω–æ–≤: {len(SCREENS)}.\n"
            "–¢–µ–ø–µ—Ä—å –º–æ–∂–Ω–æ: –æ—Ç–ø—Ä–∞–≤–∏—Ç—å –≥–µ–æ–ª–æ–∫–∞—Ü–∏—é üìç, /near lat lon [R], /pick_city –ì–æ—Ä–æ–¥ N, /pick_at lat lon N [R]."
        )
    except Exception as e:
        await m.answer(f"–ù–µ —É–¥–∞–ª–æ—Å—å –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å —Ñ–∞–π–ª: {e}")

@dp.message(F.text)
async def fallback_text(m: types.Message):
    t = (m.text or "").strip()
    if t.startswith("/"):
        # –Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –∫–æ–º–∞–Ω–¥–∞ ‚Äî –ø–æ–∫–∞–∂–µ–º help
        await m.answer("–Ø –Ω–µ —Å–æ–≤—Å–µ–º –ø–æ–Ω—è–ª–∞, –ø—Ä–æ—Å—Ç–∏—Ç–µ. –ù–∞–∂–º–∏—Ç–µ /help –¥–ª—è —Å–ø–∏—Å–∫–∞ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–µ–π.", reply_markup=kb_loaded())
    else:
        # —Å–≤–æ–±–æ–¥–Ω—ã–π —Ç–µ–∫—Å—Ç ‚Äî –º—è–≥–∫–æ –Ω–∞–ø—Ä–∞–≤–∏–º
        await m.answer(
            "–ß—Ç–æ–±—ã –Ω–∞—á–∞—Ç—å, –º–æ–∂–µ—Ç–µ –∑–∞–¥–∞—Ç—å –≤–æ–ø—Ä–æ—Å, –Ω–∞–ø—Ä–∏–º–µ—Ä /ask –ø–æ–¥–±–µ—Ä–∏ 30 –±–∏–ª–±–æ—Ä–¥–æ–≤ –∏ —Å—É–ø–µ—Ä—Å–∞–π—Ç–æ–≤ –ø–æ –ú–æ—Å–∫–≤–µ —Ä–∞–≤–Ω–æ–º–µ—Ä–Ω–æ –∏–ª–∏ /ask –ø—Ä–æ–≥–Ω–æ–∑ –Ω–∞ –Ω–µ–¥–µ–ª—é –ø–æ –ø–æ—Å–ª–µ–¥–Ω–µ–π –≤—ã–±–æ—Ä–∫–µ",
            reply_markup=kb_loaded()
        )


# ====== –ó–ê–ü–£–°–ö ======
import asyncio
import threading
import logging
from flask import Flask
import os
from aiogram.filters import Command

logging.basicConfig(level=logging.INFO)

app = Flask(__name__)

@app.route("/")
def home():
    return "Bot is running!"

def run_flask():
    port = int(os.environ.get("PORT", 10000))
    app.run(host="0.0.0.0", port=port, threaded=True)

async def run_bot():
    logging.info("run_bot(): —Å—Ç–∞—Ä—Ç")
    bot_token = os.getenv("BOT_TOKEN")
    if not bot_token:
        logging.error("‚ùå BOT_TOKEN –ø—É—Å—Ç. –ü—Ä–æ–≤–µ—Ä—å .env –∏–ª–∏ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è.")
        return

    @dp.message(Command("start"))
    async def start(message: Message):
        await message.answer("–ü—Ä–∏–≤–µ—Ç! –û–º–Ω–∏–∫–∞ –æ–Ω–ª–∞–π–Ω üöÄ")

    await bot.delete_webhook(drop_pending_updates=True)
    logging.info("‚úÖ Aiogram polling –∑–∞–ø—É—Å–∫–∞–µ—Ç—Å—è...")
    await dp.start_polling(bot)

if __name__ == "__main__":
    threading.Thread(target=run_flask, daemon=True).start()
    asyncio.run(run_bot())